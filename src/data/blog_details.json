[
  {
    "title": "MCP의 모든 것을 알아봅시다.",
    "description": "개발자인데 mcp 원리 계속 모른상태로 있을건가요?",
    "link": "https://velog.io/@k-svelte-master/what-is-mcp",
    "author": "k-svelte-master.log",
    "date": "2025년 3월 31일",
    "comments": "19개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/k-svelte-master/post/617871f4-f309-42e3-8fa5-75afd665ce79/image.png",
    "content": "k-svelte-master.log\n로그인\nk-svelte-master.log\n로그인\nMCP의 모든 것을 알아봅시다.\n타락한스벨트전도사·2025년 3월 31일\n팔로우\n170\nAIAgenticaBackendLLMMCPfrontendweb\nMCP 하나면 다 된다고요? 정말일까요?\n\n여러분은 이런 광고 문구를 본 적 있을 겁니다. \"이 제품 하나면 다 됩니다!\", \"단 한 번의 클릭으로 해결!\", \"더 이상 고민하지 마세요!\"... 그리고 대부분의 경우, 실제로는 그렇게 마법같은 일이 일어나지 않죠. 하지만 이번만큼은 예외인거 같습니다. 그 정체는 바로 MCP(Model Context Protocol)입니다.\n\n\"이제 MCP로 LLM에 전달할 외부 API를 규격화하세요!\"\n\nAnthropic 주도로 개발되고 오픈소스로 공개된 MCP는 마치 AI계의 USB-C 포트처럼 소개되고 있습니다. 다양한 기기를 표준화된 방식으로 연결하는 USB-C처럼, MCP는 LLM에 전달하는 외부 API의 규격화된 프로토콜을 제공합니다. 이 프로토콜은 https://github.com/modelcontextprotocol 에서 SDK 형태로 제공되어, 누구나 MCP 서버나 클라이언트를 쉽게 구현할 수 있습니다.\n\nAI계의 USB-C가 등장했다! MCP로 연결하는 새로운 AI 세상\n\n온 세상이 MCP 서버를 오픈하고 있습니다. Cursor와 같은 코딩 툴에서는 MCP를 통해 로컬 파일 시스템에 접근하여 코드를 분석하고 자동으로 코드를 작성해주는 기능을 선보이고 있습니다. Claude 데스크탑앱도 MCP 연동을 통해 외부 API를 활용하도록 지원하고 있으며, Microsoft는 Playwright MCP 서버 코드를 직접 오픈하여 웹 테스트 자동화를 지원하고 있습니다. 점점 더 많은 도구들이 이 프로토콜을 채택하며 대세가 되어가고 있습니다.\n\n\"에이, 그게 무슨 대수라고. 기존에도 API 연동 많이 했잖아요?\"\n\n맞습니다. LLM과 외부 도구를 연결하는 방법은 이전에도 있었습니다. 하지만 각 서비스마다 API 구조가 다르고, 인증 방식이 달라 통합하는 과정이 복잡했죠. MCP의 진가는 바로 이 지점에서 빛납니다. 규격화된 프로토콜을 통해 누구나 동일한 방식으로 API를 구현하고 연결할 수 있게 된 것입니다. 개발자라면 이런 표준화의 가치를 아실 겁니다. '모든 것이 연결된' AI 에코시스템의 꿈이 MCP를 통해 한 걸음 더 가까워진 것입니다.\n\nCursor, Figma에서 벌써 시작된 MCP 혁명: \"코드요? 자동으로 뚝딱이죠!\"\n\n예를 들어보죠. Cursor에서는 MCP를 통해 다음과 같은 대화가 가능합니다:\n\n\"내 프로젝트의 모든 Python 파일을 분석해서 중복 코드를 찾아줘\"\n\"이 기능을 테스트하는 유닛 테스트를 작성해줘\"\n\"이 API와 호환되는 클라이언트 코드를 자동으로 생성해줘\"\n\nMCP 서버를 통해 AI가 로컬 파일 시스템에 안전하게 접근할 수 있게 되면서, 이제 AI는 단순히 대화 상자에 붙여넣은 코드 조각이 아니라 전체 프로젝트 구조를 이해하고 맥락에 맞는 코드를 생성할 수 있게 되었습니다. 이것이 바로 개발자들이 \"와, 이거 진짜 마법 같은데?\"라고 반응하는 이유죠.\n\n링크드인 글 퍼옴 - 작성자에게 허락받음 ㅎ..\n\n너무 좋아서 의심스러운 MCP, 과연 실체는?\n\n하지만 잠깐, MCP 서버만 구현하면 LLM이 촥 하고 달라붙어서 모든 기능을 자동으로 수행할까요? 이 역할도 MCP의 몫일까요?\n\n물론 그렇지 않습니다. MCP는 결국 '프로토콜'일 뿐입니다. USB-C 포트가 있다고 해서 모든 기기가 자동으로 모든 기능을 수행하는 것은 아니죠. 케이블은 연결만 해줄 뿐, 각 기기가 어떤 기능을 수행할지는 또 다른 문제입니다.\n\n그렇다면 MCP의 진짜 가치는 무엇일까요? 왜 이것이 중요한 걸까요? 더 나아가, MCP는 앞으로의 개발 패러다임을 어떻게 바꿀까요? 모든 사람이 AI 개발자가 되는 세상이 올까요? 전통적인 프로그래밍 기술 없이도 자신만의 AI 도구를 만들고 연결할 수 있는 미래가 도래할지도 모릅니다.\n\n이제부터 Model Context Protocol의 오해와 진실, 그리고 어떤 가치가 있는지 MCP의 모든 것을 하나씩 파헤쳐보며, AI의 미래가 어떻게 변화할지 함께 살펴보겠습니다.\n\nFunction Call의 사촌, MCP\n잠깐만요, Function Call이 뭐였죠?\n\nAI가 단순히 텍스트만 생성하던 시대는 지났습니다. 현대 LLM(Large Language Model)은 다양한 도구를 사용할 수 있는데, 이것이 바로 'Function Call'입니다. OpenAI가 선보인 이 개념은 AI가 특정 함수를 호출하여 외부 세계와 상호작용할 수 있게 해주었죠.\n\nFunction Call은 본질적으로 특별한 형태의 시스템 프롬프트입니다. 사용자의 질문이 들어오면 LLM은 이 질문이 Function Call을 호출해야 하는지 판단합니다. 만약 호출이 필요하다고 판단되면, LLM은 규격화된 인자(arguments)를 생성하고, 그렇지 않으면 일반적인 대화를 계속 진행합니다.\n\nFunction Call의 작동 방식을 도식화하면 다음과 같습니다:\n\n간단한 예를 들어볼까요? OpenAI의 TypeScript SDK를 사용한 Function Call 예시입니다:\n\nimport OpenAI from 'openai';\n\nconst openai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY,\n});\n\n// 함수 정의\nconst functions = [\n  {\n    name: 'get_weather',\n    description: '특정 위치의 현재 날씨 정보를 가져옵니다',\n    parameters: {\n      type: 'object',\n      properties: {\n        location: {\n          type: 'string',\n          description: '도시 이름, 예: 서울, 뉴욕, 런던',\n        },\n      },\n      required: ['location'],\n    },\n  },\n];\n\n// 채팅 완성 요청\nasync function main() {\n  const completion = await openai.chat.completions.create({\n    model: 'gpt-4',\n    messages: [\n      { role: 'user', content: '서울의 오늘 날씨는 어때?' }\n    ],\n    tools: functions,\n    tool_choice: 'auto',\n  });\n\n  // Function Call 결과 확인\n  const message = completion.choices[0].message;\n  \n  if (message.tool_calls) {\n    // AI가 함수를 호출하려고 한다면\n    const functionCall = message.tool_calls[0];\n    console.log(`함수 호출: ${functionCall.function.name}`);\n    console.log(`매개변수: ${functionCall.function.arguments}`);\n    \n    // 여기서 실제 날씨 API를 호출하고 결과를 AI에게 돌려줄 수 있습니다\n  } else {\n    // 일반 텍스트 응답\n    console.log(message.content);\n  }\n}\n\nmain();\n\n이 코드에서 일어나는 일을 단계별로 살펴보면:\n\n개발자는 get_weather라는 함수와 그 매개변수를 정의합니다.\n사용자가 \"서울의 오늘 날씨는 어때?\"라고 질문합니다.\nLLM은 이 질문을 분석하고 날씨 정보를 요청하는 것으로 판단합니다.\nLLM은 get_weather 함수를 호출하기로 결정하고, location: \"서울\"이라는 인자를 생성합니다.\n개발자가 작성한 코드는 이 함수 호출을 감지하고, 실제 날씨 API를 호출할 수 있습니다.\n그 결과를 다시 LLM에 전달하면, LLM은 사용자에게 적절한 응답을 생성합니다.\n\n이것이 바로 Function Call의 핵심입니다. LLM은 사용자의 의도를 파악하여 적절한 함수를 호출하고, 개발자는 실제로 그 함수를 구현하여 외부 세계와의 상호작용을 가능하게 합니다.\n\n👋 안녕, 나는 MCP야: Model Context Protocol의 정체 파헤치기\n\nFunction Call에 익숙해지셨다면, 이제 MCP(Model Context Protocol)를 만나볼 시간입니다. MCP는 LLM과 외부 도구 간의 통신을 표준화하는 프로토콜입니다. 그런데 이 추상적인 설명만으로는 MCP의 진짜 모습을 이해하기 어렵겠죠? 직접 코드를 살펴보며 MCP의 정체를 파헤쳐 봅시다.\n\nJSON-RPC: MCP의 통신 방식\n\nMCP는 JSON-RPC 2.0 프로토콜을 기반으로 합니다. JSON-RPC란 간단히 말해 JSON 형식으로 원격 프로시저 호출(RPC)을 인코딩하는 경량 프로토콜입니다. 복잡한 말처럼 들리지만, 실제로는 매우 단순합니다:\n\n클라이언트가 서버에 JSON 형식의 요청을 보냅니다\n서버는 요청을 처리하고 JSON 형식의 응답을 반환합니다\n\n각 요청과 응답은 다음과 같은 형태를 가집니다:\n\n요청:\n\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"unique-request-id\",\n  \"method\": \"메서드 이름\",\n  \"params\": { /* 매개변수 */ }\n}\n\n응답:\n\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"unique-request-id\",\n  \"result\": { /* 결과 데이터 */ }\n}\n\nMCP는 이 JSON-RPC 형식을 사용하여 tools/list, tools/call 등의 표준화된 메서드를 정의합니다. 공식 SDK(https://modelcontextprotocol.io/introduction)를 사용하면 쉽게 구현할 수 있습니다. 이를 통해 클라이언트와 서버는 일관된 방식으로 통신할 수 있죠.\n\ntools/list 요청 및 응답 예시\n\ntools/list는 MCP 서버에서 사용 가능한 도구 목록을 조회할 때 사용하는 메서드입니다. 요청과 응답 형식은 다음과 같습니다:\n\n요청:\n\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"request-123\",\n  \"method\": \"tools/list\"\n}\n\n응답:\n\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"request-123\",\n  \"result\": {\n    \"tools\": [\n      {\n        \"name\": \"readFile\",\n        \"description\": \"파일 내용을 읽어옵니다\",\n        \"inputSchema\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"path\": {\n              \"type\": \"string\",\n              \"description\": \"파일 경로\"\n            }\n          },\n          \"required\": [\"path\"]\n        }\n      },\n      {\n        \"name\": \"searchWeb\",\n        \"description\": \"웹에서 정보를 검색합니다\",\n        \"inputSchema\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"query\": {\n              \"type\": \"string\",\n              \"description\": \"검색 쿼리\"\n            },\n            \"limit\": {\n              \"type\": \"number\",\n              \"description\": \"최대 결과 수\",\n              \"default\": 5\n            }\n          },\n          \"required\": [\"query\"]\n        }\n      }\n    ]\n  }\n}\ntools/call 요청 및 응답 예시\n\ntools/call은 특정 도구를 호출할 때 사용하는 메서드입니다. 요청과 응답 형식은 다음과 같습니다:\n\n요청:\n\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"request-456\",\n  \"method\": \"tools/call\",\n  \"params\": {\n    \"name\": \"searchWeb\",\n    \"arguments\": {\n      \"query\": \"최신 AI 기술 동향\",\n      \"limit\": 3\n    }\n  }\n}\n\n응답:\n\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"request-456\",\n  \"result\": {\n    \"content\": [\n      {\n        \"type\": \"text\",\n        \"text\": \"최신 AI 기술 동향에 관한 검색 결과:\\n1. 생성형 AI의 발전과 윤리적 고려사항\\n2. 자율주행 기술의 최신 동향\\n3. 의료 분야에서의 AI 활용 사례\"\n      }\n    ]\n  }\n}\nMCP 서버와 Transport 인터페이스\n\nMCP 서버를 직접 구현한다면 어떻게 할까요? 가장 간단한 방법은 단일 엔드포인트(예: /messages)를 노출하는 API를 만드는 것입니다. 이 엔드포인트는 요청 본문(body)을 해석하여 method 필드의 값에 따라 다른 응답을 반환합니다:\n\n그런데 MCP 설계의 진정한 유연함은 기존 API를 새로 만들지 않고도 MCP 프로토콜에 맞게 사용할 수 있다는 점입니다. 이를 가능하게 하는 것이 바로 Transport 인터페이스입니다:\n\ninterface Transport {\n  // 통신 시작\n  start(): Promise<void>;\n  \n  // JSON-RPC 메시지 전송 (요청 또는 응답)\n  send(message: JSONRPCMessage): Promise<void>;\n  \n  // 연결 종료\n  close(): Promise<void>;\n  \n  // 연결 종료 시 콜백\n  onclose?: () => void;\n  \n  // 오류 발생 시 콜백\n  onerror?: (error: Error) => void;\n  \n  // 메시지 수신 시 콜백\n  onmessage?: (message: JSONRPCMessage) => void;\n  \n  // 세션 ID\n  sessionId?: string;\n}\n\n이 인터페이스를 구현하면 기존 API를 MCP 프로토콜에 맞게 변환할 수 있습니다. 즉, 클라이언트는 Transport를 통해 request를 보내고, 이 Transport가 해당 요청을 적절한 API 호출로 변환하는 것입니다:\n\n이렇게 하면 서버를 새로 구현할 필요 없이, 클라이언트 측의 Transport만으로 MCP 프로토콜을 구현할 수 있습니다.\n\nMCP SDK 직접 사용해보기\n\nMCP SDK를 사용하여 클라이언트를 초기화하고 서버와 통신하는 방법을 살펴봅시다:\n\nimport { Client } from \"@modelcontextprotocol/sdk/client/index.js\";\n\n// 클라이언트 초기화\nconst client = new Client(\n  { name: \"my-client\", version: \"1.0.0\" },\n);\n\n// 기존 엔드포인트를 MCP로 변환하는 Transport\nclass ExistingAPITransport implements Transport {\n  private baseUrl: string;\n  \n  constructor(baseUrl: string) {\n    this.baseUrl = baseUrl;\n  }\n  \n  onmessage?: (message: JSONRPCMessage) => void;\n  onclose?: () => void;\n  onerror?: (error: Error) => void;\n  \n  async start(): Promise<void> {\n    console.log(\"API Transport started\");\n  }\n  \n  async send(message: JSONRPCMessage): Promise<void> {\n    // 요청이 아니면 무시\n    if (!('method' in message)) return;\n    \n    const request = message as JSONRPCRequest;\n    \n    try {\n      let response;\n      \n      // 기존 API 엔드포인트로 라우팅\n      if (request.method === 'tools/list') {\n        // /api/tools 엔드포인트로 변환\n        response = await fetch(`${this.baseUrl}/api/tools`);\n        const tools = await response.json();\n        \n        // MCP 형식으로 변환\n        if (this.onmessage) {\n          this.onmessage({\n            jsonrpc: '2.0',\n            id: request.id,\n            result: { tools }\n          });\n        }\n      } \n      else if (request.method === 'tools/call') {\n        const { name, arguments: args } = request.params;\n        \n        // /api/execute/[도구명] 엔드포인트로 변환\n        response = await fetch(`${this.baseUrl}/api/execute/${name}`, {\n          method: 'POST',\n          headers: { 'Content-Type': 'application/json' },\n          body: JSON.stringify(args)\n        });\n        \n        const result = await response.json();\n        \n        // MCP 형식으로 변환\n        if (this.onmessage) {\n          this.onmessage({\n            jsonrpc: '2.0',\n            id: request.id,\n            result: {\n              content: [{ type: 'text', text: JSON.stringify(result) }]\n            }\n          });\n        }\n      }\n    } catch (error) {\n      if (this.onerror) this.onerror(error);\n      if (this.onmessage) {\n        this.onmessage({\n          jsonrpc: '2.0',\n          id: request.id,\n          error: {\n            code: -32603,\n            message: error.message\n          }\n        });\n      }\n    }\n  }\n  \n  async close(): Promise<void> {\n    if (this.onclose) this.onclose();\n  }\n}\n\n// 기존 API를 가리키는 Transport 연결\nconst transport = new ExistingAPITransport(\"https://api.example.com\");\nawait client.connect(transport);\n\nconsole.log(\"Connected to existing API through MCP\");\n\n// tools/list 요청 예시\nconst toolsListResult = await client.request(\n  { method: \"tools/list\" },\n  ListToolsResultSchema\n);\nconsole.log(\"Available tools:\", toolsListResult.tools);\n\n// tools/call 요청 예시\nconst toolCallResult = await client.request(\n  {\n    method: \"tools/call\",\n    params: {\n      name: \"searchWeb\",\n      arguments: {\n        query: \"최신 AI 기술 동향\",\n        limit: 3\n      }\n    }\n  },\n  CallToolResultSchema\n);\nconsole.log(\"Search result:\", toolCallResult.content[0].text);\n서버 없이 로컬 서비스 활용하기\n\n물론, 서버 없이 로컬에서 직접 구현체를 만들 수도 있습니다. 간단히 로컬 객체의 메서드를 MCP 도구로 노출하는 방식으로 구현할 수 있죠:\n\n// 로컬 서비스 객체\nconst localServices = {\n  getWeather(city) {\n    return `${city}의 날씨는 맑음, 기온 22도입니다`;\n  },\n  \n  translate(text, targetLang) {\n    return `번역된 텍스트: ${text} (${targetLang}로)`;\n  }\n};\n\n// 로컬 서비스를 MCP 도구로 변환하는 Transport\nclass LocalServicesTransport implements Transport {\n  async start() {}\n  async close() {}\n  \n  async send(message) {\n    if (!('method' in message)) return;\n    const req = message;\n    \n    if (req.method === 'tools/list') {\n      this.onmessage({\n        jsonrpc: '2.0',\n        id: req.id,\n        result: {\n          tools: [\n            {\n              name: 'getWeather',\n              description: '도시의 날씨 정보 조회',\n              inputSchema: {/* 스키마 정의 */}\n            },\n            {\n              name: 'translate',\n              description: '텍스트 번역',\n              inputSchema: {/* 스키마 정의 */}\n            }\n          ]\n        }\n      });\n    }\n    else if (req.method === 'tools/call') {\n      const result = localServices[req.params.name](...Object.values(req.params.arguments));\n      this.onmessage({\n        jsonrpc: '2.0',\n        id: req.id,\n        result: { content: [{ type: 'text', text: result }] }\n      });\n    }\n  }\n}\n\n// 로컬 서비스 연결\nconst localTransport = new LocalServicesTransport();\nawait client.connect(localTransport);\n\n// 이제 로컬 서비스를 MCP 도구로 호출할 수 있습니다\nconst weatherResult = await client.request({\n  method: \"tools/call\",\n  params: {\n    name: \"getWeather\",\n    arguments: { city: \"서울\" }\n  }\n});\nconsole.log(weatherResult.content[0].text); // \"서울의 날씨는 맑음, 기온 22도입니다\"\nMCP의 핵심 가치: 표준화된 인터페이스\n\nMCP의 핵심 가치는 바로 여기에 있습니다. 기존에 존재하는 API나, 로컬 서비스, 또는 새로 구현한 서버 등 어떤 도구나 리소스든 Transport layer만 구현해놓으면, MCP client에서 정해진 메서드로 LLM Function Call에 필요한 내용들을 호출할 수 있습니다.\n\n이것이 바로 '규격화'의 의미입니다. LLM이 외부 세계와 상호작용하는 방식을 일관되게 만들어 주는 것이죠. 개발자는 각 서비스마다 다른 방식의 함수 정의를 작성할 필요 없이, MCP 프로토콜만 따르면 됩니다.\n\nFunction Call을 사용할 때는 각 API마다 고유한 함수 정의를 작성해야 했지만, MCP를 사용하면 모든 도구와 리소스에 단일한 인터페이스로 접근할 수 있습니다. 이는 마치 USB 표준이 다양한 하드웨어를 연결하는 방식을 표준화한 것과 유사합니다.\n\nMCP는 다음과 같은 이점을 제공합니다:\n\n표준화된 인터페이스: 모든 도구와 리소스에 동일한 방식으로 접근할 수 있습니다.\n유연한 구현: 서버를 새로 만들거나, 기존 API를 변환하거나, 로컬 서비스를 활용하는 등 다양한 방식으로 구현할 수 있습니다.\nLLM 독립성: 특정 LLM 제공업체에 종속되지 않고, 다양한 LLM과 함께 사용할 수 있습니다.\n확장성: 새로운 도구나 리소스를 추가할 때도 동일한 인터페이스를 사용할 수 있습니다.\n\n이러한 이점을 통해 MCP는 LLM과 외부 도구 간의 통신을 더욱 효율적으로 만들어 줍니다. Function Call이 첫걸음이었다면, MCP는 그 다음 단계로의 도약을 의미합니다.\n\nMCP는 혼자서 아무것도 못해요\n\n지금까지 MCP가 얼마나 멋진 프로토콜인지 살펴봤습니다. 표준화된 인터페이스로 외부 도구와 리소스에 접근하는 방법을 제공한다니, 정말 훌륭하죠? 하지만 이쯤에서 한 가지 중요한 사실을 짚고 넘어가야 합니다.\n\n😈 호스트 앱은 직접 구현하셔야죠!\n\n이쯤 되면 눈치채셨을지도 모르겠습니다. MCP에는 LLM이 없습니다. 그저 외부 리소스를 연결하는 일관된 인터페이스를 제공할 뿐이죠. 즉, LLM과의 연결, 대화 관리, 그리고 실제 도구 호출의 로직은 모두 호스트 앱에서 직접 구현해야 합니다.\n\n다시 말해, MCP는 도구를 표준화된 방식으로 노출하는 방법을 제공하지만, 그 도구를 언제, 어떻게 사용할지는 호스트 앱의 책임입니다. 이 부분이 바로 Claude Desktop, Cursor, 그리고 다양한 AI 서비스들이 독자적으로 구현해야 하는 부분입니다.\n\n호스트 앱에서 구현해야 하는 주요 로직을 살펴보겠습니다:\n\n// 기본 구조\nclass MCPHostApp {\n  constructor() {\n    this.mcpClient = new MCPClient();  // MCP 클라이언트\n    this.llm = new LLMClient();        // LLM 클라이언트 (Claude, GPT 등)\n  }\n  \n  async processUserQuery(query) {\n    // 1. MCP 서버에서 도구 목록 가져오기\n    const tools = await this.mcpClient.request({ method: \"tools/list\" });\n    \n    // 2. LLM에 도구 목록 전달하고 쿼리 처리 요청\n    const llmResponse = await this.llm.processQuery(query, tools);\n    \n    // 3. LLM이 도구 호출을 요청했다면\n    if (llmResponse.hasFunctionCall) {\n      // 4. MCP를 통해 도구 호출\n      const result = await this.mcpClient.request({\n        method: \"tools/call\",\n        params: {\n          name: llmResponse.functionName,\n          arguments: llmResponse.functionArgs\n        }\n      });\n      \n      // 5. 도구 호출 결과를 LLM에 다시 전달\n      return await this.llm.processFunctionResult(result);\n    }\n    \n    // 도구 호출이 없다면 LLM 응답 그대로 반환\n    return llmResponse.text;\n  }\n}\n\n이 단순한 코드에서도 호스트 앱이 해야 할 일이 많다는 것을 알 수 있습니다:\n\nMCP 클라이언트와 LLM 클라이언트를 모두 관리\nMCP에서 도구 목록을 가져와 LLM에 전달\nLLM의 도구 호출 요청을 감지하고 MCP로 전달\n도구 호출 결과를 다시 LLM에 전달\n최종 응답을 사용자에게 제공\n\n이것이 바로 Claude Desktop, Cursor, Visual Studio Code 확장 프로그램과 같은 AI 도구들이 모두 독자적으로 구현해야 하는 부분입니다. MCP는 단지 도구와 리소스에 접근하는 표준화된 방법만 제공할 뿐, 실제로 유용한 AI 경험을 만들기 위한 로직은 호스트 앱이 담당해야 합니다.\n\n요약하자면, MCP는 혼자서는 아무것도 할 수 없습니다. 실제로 가치를 발휘하려면 잘 설계된 호스트 앱이 필요하죠. 그래서 다양한 AI 서비스들이 각자의 방식으로 호스트 앱을 구현하고 있는 것입니다.\n\n🧠 호스트 앱이 전부입니다: LLM 워크플로우의 중요성\n\nMCP 서버가 도구를 제공하고 LLM이 이를 호출한다면 모든 문제가 해결될까요? 단순히 Function Call 목록을 LLM에게 전달하고 호출하게 하면 모든 것을 완벽하게 수행할 수 있을까요?\n\n현실은 그렇게 간단하지 않습니다. LLM의 진정한 능력을 끌어내기 위해서는 효과적인 LLM 워크플로우 설계가 필수적입니다.\n\n가장 단순한 예시부터 생각해 봅시다. MCP를 통해 100개 또는 1000개의 도구를 사용할 수 있다고 가정해 보겠습니다. 이 모든 도구 정의를 한 번에 LLM에게 전달하면 어떻게 될까요?\n\n// ❌ 비효율적인 방식: 모든 도구를 한 번에 LLM에 전달\nconst allTools = await mcpClient.request({ method: \"tools/list\" });\nconst llmResponse = await llm.processQuery(query, allTools); // 수많은 도구로 LLM이 혼란!\n\n이런 접근 방식은 두 가지 문제를 일으킵니다:\n\n토큰 낭비: 수백 개의 도구 정의가 컨텍스트 윈도우를 차지하여 실제 사용자 쿼리를 처리할 공간이 줄어듭니다.\n선택 혼란: LLM은 너무 많은 선택지 중에서 적절한 도구를 찾는 데 어려움을 겪을 수 있습니다.\n\n효과적인 호스트 앱은 이 문제를 다음과 같이 해결할 수 있습니다:\n\n// ✅ 효율적인 방식: 쿼리 기반으로 관련 도구만 선택하여 제공\nasync function processWithRelevantTools(query) {\n  // 1. 모든 도구 목록 가져오기\n  const allTools = await mcpClient.request({ method: \"tools/list\" });\n  \n  // 2. 쿼리 임베딩 생성\n  const queryEmbedding = await generateEmbedding(query);\n  \n  // 3. 도구 설명의 임베딩과 비교하여 관련 도구만 선택\n  const relevantTools = selectRelevantTools(allTools, queryEmbedding);\n  \n  // 4. 선택된 도구만 LLM에 제공\n  return await llm.processQuery(query, relevantTools);\n}\n\n이것은 호스트 앱이 단순한 중계자가 아니라 지능형 조정자로서 작동해야 함을 보여주는 한 가지 예시일 뿐입니다.\n\nLLM 워크플로우: ReAct 패턴과 그 너머\n\nLLM을 운용하는 방식은 아주 다양한 방법론이 있습니다. 그중 가장 널리 알려진 패턴 중 하나는 ReAct(Reasoning + Acting)입니다.\n\nReAct 패턴에서 LLM은:\n\n추론(Reasoning): 어떤 도구를 사용할지 결정하고 그 이유를 설명합니다.\n행동(Acting): 선택한 도구를 호출하여 정보를 얻거나 작업을 수행합니다.\n관찰(Observation): 도구 실행 결과를 분석하고 다음 단계를 계획합니다.\n\n이 과정은 반복적으로 수행되며, 각 단계에서 LLM은 자신의 행동을 설명하고 결과를 평가합니다.\n\n그러나 ReAct는 시작일 뿐입니다. 다양한 워크플로우 패턴이 있습니다:\n\nReflection: LLM이 자신의 응답을 비판적으로 평가하고 개선하는 과정\nHuman-in-the-loop: 특정 시점에서 사용자의 피드백을 받아 정확도 향상\nMulti-agent Collaboration: 여러 LLM 에이전트가 협력하여 복잡한 문제 해결\n\nWindsurf가 Cursor라는 경쟁자를 제치고 인기를 얻은 이유 중 하나는 이러한 LLM 에이전트 협업 관계를 효과적으로 설계했기 때문입니다.\n\n딥 리서치: 검색과 반복 질문\n\n최근 OpenAI, Perplexity, Grok과 같은 서비스에서 볼 수 있는 딥 리서치 기능도 잘 설계된 워크플로우의 한 예입니다:\n\n이 워크플로우에서는:\n\n사용자의 질문을 기반으로 웹 검색을 수행합니다.\n검색 결과를 분석하여 후속 질문을 생성합니다.\n이 과정을 반복하여 점점 더 정확하고 깊이 있는 정보를 수집합니다.\n최종적으로 모든 정보를 종합하여 사용자에게 제공합니다.\n\n이런 방식은 단순한 질의응답보다 훨씬 더 정확하고 최신 정보를 제공할 수 있습니다.\n\n프레임워크: 워크플로우 구축의 도구들\n\n이러한 복잡한 워크플로우를 구현하기 위한 다양한 프레임워크가 존재합니다:\n\nMicrosoft의 AutoGen: 여러 에이전트가 협업하는 방식으로, 각 에이전트는 고유한 시스템 프롬프트를 가지고 특정 역할을 수행합니다.\nLangGraph: 다양한 LLM 컴포넌트를 연결하여 복잡한 워크플로우를 구성할 수 있습니다.\n// AutoGen 스타일의 다중 에이전트 구현 예시 (수도 코드)\nconst codeWriter = createAgent({\n  role: \"코드 작성자\",\n  systemPrompt: \"당신은 사용자의 요구사항에 맞는 코드를 작성하는 전문가입니다...\"\n});\n\nconst codeReviewer = createAgent({\n  role: \"코드 리뷰어\",\n  systemPrompt: \"당신은 코드의 품질과 보안을 검토하는 전문가입니다...\"\n});\n\n// 에이전트 간 협업 워크플로우 설정\nsetupWorkflow([\n  codeWriter.writeInitialCode,\n  codeReviewer.reviewCode,\n  codeWriter.improveBadedOnFeedback,\n  // ...\n]);\n\n저희 팀에서도 글쓰기 워크플로우를 구현하기 위해 독자적으로 프레임워크를 만들어서 사용하고 있습니다.\n\nMCP의 역할과 한계\n\n이 모든 맥락에서 MCP의 역할은 무엇일까요? MCP는 외부 세계와 연결될 단일 인터페이스를 제공하는 것일 뿐입니다. MCP 자체가 멀티에이전트 시스템이나 에이전트 워크플로우를 구성하지는 않습니다.\n\n각 MCP 호스트(Claude Desktop, Cursor, Contiue 등)는 자신만의 고유한 워크플로우를 개발하여 LLM의 능력을 최대한 끌어올립니다:\n\n동적으로 변하는 프롬프트를 사용할 수 있습니다.\n에이전트를 여러 개로 나누어 협업하게 할 수 있습니다.\n사용자와의 상호작용을 최적화할 수 있습니다.\n도구 호출의 결과를 해석하고 다음 행동을 결정하는 방식을 개선할 수 있습니다.\n\n결론적으로, MCP는 매우 유용한 표준화 프로토콜이지만, 진정한 가치는 이를 활용하는 호스트 앱의 워크플로우 설계에 있습니다. LLM의 능력을 최대한 활용하려면, 단순히 도구를 연결하는 것을 넘어서 지능적인 워크플로우를 설계해야 합니다. 이것이 바로 호스트 앱이 전부인 이유입니다.\n\nMCP의 야망: 프롬프트에서 워크플로우까지\n\n지금까지 우리는 MCP가 tools/list와 tools/call을 통해 LLM에게 도구를 제공하는 방법에 대해 살펴봤습니다. 하지만 MCP의 야망은 이에 그치지 않습니다. 단순한 도구 호출을 넘어 더 복잡하고 정교한 워크플로우까지 MCP로 구현할 수 있는 가능성이 열리고 있습니다.\n\n📝 \"프롬프트도 제공합니다만?\" MCP의 특별한 스펙 공개\n\nMCP 프로토콜을 자세히 들여다보면, 도구 호출만이 유일한 기능이 아님을 알 수 있습니다. 다양한 JSON-RPC 메서드가 정의되어 있는데, 그중에는 이런 것들도 있습니다:\n\n**프롬프트 관련**\n* `prompts/get`: 특정 프롬프트 가져오기\n* `prompts/list`: 사용 가능한 프롬프트 목록 조회\n\n**리소스 관련**\n* `resources/list`: 리소스 목록 조회\n* `resources/templates/list`: 리소스 템플릿 목록 조회\n* `resources/read`: 리소스 읽기\n* `resources/subscribe`: 리소스 변경 구독\n* `resources/unsubscribe`: 리소스 구독 취소\n\n눈여겨봐야 할 부분은 바로 prompts/get과 prompts/list입니다. 이는 MCP 서버가 단순히 도구만 제공하는 것이 아니라, 프롬프트도 제공할 수 있음을 의미합니다. MCP 서버에서 제공하는 프롬프트를 호스트 앱이 LLM에게 전달하는 것이죠.\n\n더 놀라운 것은 sampling/createMessage와 같은 메서드의 존재입니다. 이 메서드를 통해 MCP 서버가 호스트 앱에게 LLM 생성을 요청할 수 있습니다:\n\n{\n  \"method\": \"sampling/createMessage\",\n  \"params\": {\n    \"messages\": [\n      {\n        \"role\": \"user\",\n        \"content\": {\n          \"type\": \"text\",\n          \"text\": \"What files are in the current directory?\"\n        }\n      }\n    ],\n    \"systemPrompt\": \"You are a helpful file system assistant.\",\n    \"includeContext\": \"thisServer\",\n    \"maxTokens\": 100\n  }\n}\n\n이것은 무엇을 의미할까요? MCP 서버가 단순한 도구 제공자를 넘어서서, 적극적으로 대화에 참여하는 에이전트가 될 수 있다는 것입니다. 서버가 질문을 하고, 호스트는 LLM을 통해 답변을 제공하며, 필요하다면 사용자를 루프에 포함시킬 수도 있습니다(Human-in-the-loop).\n\n🤖 멀티에이전트 프레임워크가 MCP 서버로 이사 가는 중\n\n이러한 기능들이 시사하는 바는 명확합니다. 복잡한 멀티에이전트 워크플로우를 구성하는 다양한 전략들이 이제 MCP 서버로 이동할 수 있습니다. 여러 MCP 서버들이 각자의 역할을 담당하고, prompts/list와 prompts/get으로 프롬프트를 제공하며, sampling/createMessage로 호스트에 LLM 생성을 요청하는 방식으로 워크플로우를 구성할 수 있습니다.\n\n이런 접근 방식에서는:\n\n여러 MCP 서버가 각각 특정 역할을 담당합니다 (코드 작성자, 코드 리뷰어 등)\n각 MCP 서버는 prompts/list와 prompts/get으로 자신의 역할에 맞는 프롬프트를 제공합니다\nMCP 서버는 sampling/createMessage를 통해 호스트 앱에 LLM 생성을 요청합니다\n호스트 앱은 사용자와의 상호작용을 관리하며 필요할 때 Human-in-the-loop를 구현합니다\n{\n  \"method\": \"sampling/createMessage\",\n  \"params\": {\n    \"messages\": [\n      {\n        \"role\": \"user\",\n        \"content\": {\n          \"type\": \"text\",\n          \"text\": \"현재 디렉토리에 어떤 파일들이 있나요?\"\n        }\n      }\n    ],\n    \"systemPrompt\": \"당신은 도움이 되는 파일 시스템 어시스턴트입니다.\",\n    \"includeContext\": \"thisServer\",\n    \"maxTokens\": 100\n  }\n}\n\n이 기능이 특별한 이유는 Human-in-the-loop 설계를 자연스럽게 지원하기 때문입니다. 샘플링 요청이 들어오면:\n\n호스트 앱은 사용자에게 \"코드리뷰 도구가 LLM에게 질문하려고 합니다. 허용하시겠습니까?\"와 같은 확인을 요청할 수 있습니다.\n사용자는 제안된 프롬프트를 검토하고 수정하거나 거부할 수 있습니다.\n생성된 응답도 사용자가 검토하고 승인한 후에 MCP 서버로 전달됩니다.\n\n이를 통해 사용자는 LLM이 무엇을 보고 생성하는지에 대한 통제권을 유지하면서도, MCP 서버가 복잡한 에이전트 행동을 수행할 수 있게 됩니다.\n\n이처럼 멀티에이전트 워크플로우의 핵심 전략들을 MCP 서버로 옮기면, 동일한 워크플로우를 다양한 호스트 앱에서 재사용할 수 있게 됩니다.\n\n호스트 앱을 MCP로 싸서 드셔보세요\n\n더 나아가, 복잡한 워크플로우 자체를 MCP 서버로 패키징하여 공유 가능한 형태로 제공할 수도 있습니다. 기존에는 호스트 앱에서 구현해야 했던 워크플로우 로직을 MCP 서버로 옮겨서, 다른 호스트 앱들이 쉽게 이용할 수 있게 만드는 것입니다.\n\n예를 들어, 앞서 살펴본 딥 리서치 워크플로우가 호스트 앱에 구현되어 있었다면, 이제는 이를 MCP 서버로 패키징할 수 있습니다:\n\n이 구조에서 딥 리서치 MCP 서버는 복잡한 워크플로우 로직을 모두 내부적으로 처리하지만, 외부로는 단순한 tools/list와 tools/call 인터페이스만 노출합니다. 호스트 앱은 deepResearch라는 단일 도구만 보게 되며, 복잡한 내부 구현은 숨겨집니다.\n\n실제로는 딥 리서치 서버 내부에서 다양한 방식으로 구현될 수 있습니다. 하드코딩된 로직일 수도 있고, MCP 프로토콜을 십분 활용한 정교한 구현일 수도 있습니다. 이 서버는 다음과 같은 복잡한 작업을 수행합니다:\n\n내부적으로 검색 MCP 서버에 도구 호출 요청\n검색 결과 분석 및 후속 질문 생성\n사용자 확인 프로세스 관리\n여러 검색 결과 종합 및 최종 응답 생성\n\n하지만 호스트 앱의 관점에서는 그저 deepResearch라는 단일 도구만 호출할 뿐입니다. 이처럼 MCP를 통해 복잡한 워크플로우를 캡슐화하고 재사용 가능한 형태로 제공할 수 있습니다. 다른 개발자들은 내부 구현을 이해할 필요 없이 자신의 호스트 앱에서 이 기능을 쉽게 활용할 수 있게 됩니다.\n\n호스트는 가볍게, MCP는 다양하게\n\n이러한 접근 방식의 가치는 명확합니다. 개발자들은 자신의 입맛에 맞는 워크플로우를 MCP 서버로 공개하고, 다른 개발자들은 이를 조합하여 새로운 AI 경험을 만들 수 있습니다. 마치 맛집 레시피를 공유하듯, AI 워크플로우 레시피를 공유하는 생태계가 형성될 수 있는 것이죠.\n\n예를 들어:\n\n웹 검색 + 코드 생성 워크플로우를 MCP 서버로 패키징\n복잡한 데이터 분석 파이프라인을 MCP 서버로 구현\n특정 도메인에 특화된 에이전트 협업 시스템을 MCP 서버로 제공\n\n이렇게 되면 AI 개발의 미래는 호스트 앱을 처음부터 개발하는 것이 아니라, 다양한 MCP 서버 조합을 찾는 것만으로 구성하는 방향으로 진화할 수 있습니다.\n\nMCP: 단순한 프로토콜을 넘어서\n\n지금까지 MCP(Model Context Protocol)의 현재를 살펴봤다면, 이제는 미래를 상상해 볼 차례입니다. AI 개발 패러다임이 어떻게 변화할지, MCP가 어떤 역할을 할지 생각해보면 흥미로운 가능성이 펼쳐집니다.\n\n🧩 AI 개발은 레고처럼 된다\n\n가장 먼저 떠오르는 미래는 'AI 개발의 레고화'입니다. 오픈소스 커뮤니티와 상업 업체들이 다양한 MCP 서버 블록을 만들기 시작하면 어떻게 될까요? 개발자들은 이 블록들을 조합하여 복잡한 AI 애플리케이션을 구축할 수 있을 것입니다.\n\n예를 들어:\n\n웹 검색 MCP 서버\nPDF 분석 MCP 서버\n코드 이해 및 생성 MCP 서버\n데이터 시각화 MCP 서버\n\n이들을 조합하면 \"AI 연구 어시스턴트\"나 \"코드 리팩토링 도우미\" 같은 특화된 애플리케이션을 빠르게 만들 수 있습니다. 마치 레고 블록을 조립하듯, 필요한 MCP 서버들을 연결하기만 하면 되는 세상이 오는 것이죠.\n\n💡 AI 오케스트레이션의 시대\n\n두 번째로, AI 워크플로우 오케스트레이션이 새로운 경쟁의 장이 될 것입니다. 현재는 도구를 만들거나 호스트 앱을 개발하는 데 초점이 맞춰져 있지만, 미래에는 다양한 MCP 서버들을 조율하는 '오케스트레이터'가 중요해질 수 있습니다.\n\n이러한 오케스트레이터는:\n\n상황에 맞는 최적의 MCP 서버 조합을 결정\n서버 간 정보 흐름을 관리\n사용자 개입이 필요한 시점을 판단\n복잡한 멀티에이전트 협업을 조율\n\n언젠가는 \"이 오케스트레이터가 더 효율적인 워크플로우를 구성해요\"라는 경쟁이 일어날지도 모릅니다.\n\n🌐 MCP 서버 마켓플레이스\n\n세 번째로, MCP 서버 마켓플레이스가 등장할 가능성이 큽니다. 마치 앱스토어처럼, 전문화된 MCP 서버를 제공하는 생태계가 형성될 수 있습니다. 법률, 의료, 금융 등 각 분야별로 특화된 MCP 서버가, 무료부터 구독형까지 다양한 모델로 제공될 것입니다.\n\n이는 AI 개발의 민주화로 이어질 수 있습니다. 기술적 지식이 없는 사람들도 호스트 앱을 통해 필요한 MCP 서버를 구독하고 조합하여 자신만의 AI 워크플로우를 구성할 수 있게 될 테니까요.\n\n🔄 AI 앱이 없어지고, AI 워크플로우만 남는다\n\n네 번째로, 어쩌면 호스트 앱과 MCP 서버의 경계가 점점 흐려질 수도 있습니다. 사용자들은 특정 앱을 사용하는 것이 아니라, 필요에 따라 다양한 AI 워크플로우를 선택하게 될 수 있습니다.\n\n\"오늘은 연구 논문을 읽어야 하니 학술 워크플로우를 활성화해야겠다\"\n\"지금은 코딩 중이니 개발 워크플로우로 전환해야겠다\"\n\n앱 단위가 아닌 '워크플로우 단위'로 AI 경험을 소비하는 세계가 오지 않을까요?\n\n💼 MCP의 가능성을 탐색한다면?\n\nMCP는 아직 발전 중인 기술이며, 앞으로 어떻게 진화할지는 커뮤니티와 개발자들의 손에 달려 있습니다. 현재 시점에서 MCP를 탐색한다면 고려해볼 만한 방향은 다음과 같습니다:\n\n표준의 진화 지켜보기: MCP는 계속 발전하고 있습니다. 이 표준이 어떻게 진화하는지 지켜보는 것은 AI 개발의 미래 방향을 이해하는 데 도움이 될 수 있습니다.\n\n모듈성 실험하기: 솔루션을 설계할 때 모듈화를 고려해보는 것은 언제나 좋은 접근법입니다. 어떤 부분이 독립적인 MCP 서버로 분리될 수 있을지 실험해볼 가치가 있습니다.\n\n커뮤니티 참여하기: MCP와 관련된 오픈소스 프로젝트와 커뮤니티에 참여하면 다양한 아이디어와 사용 사례를 접할 수 있습니다.\n\nMCP는 단순한 프로토콜이 아닐 수 있습니다. 이는 AI 개발의 새로운 패러다임, 더 모듈화되고, 더 협업적이며, 더 접근하기 쉬운 AI 생태계를 향한 한 걸음일지도 모릅니다.\n\n타락한스벨트전도사\n스벨트쓰고요. 오픈소스 운영합니다\n팔로우\n이전 포스트\nLLM 서비스에서 프론트엔드 살아남기\n19개의 댓글\n댓글 작성\nKimSejun\n2025년 4월 1일\n\n너무 상세하고 맛있는 설명에 mcp의 이해도가 확실히 올라갔습니다. 진심으로 감사드립니다.\n\n1개의 답글\n배준혁\n2025년 4월 4일\n\n잘 이해 안됬는데...\n너무 좋은 글 감사합니다!\n\n1개의 답글\nyeahcold\n2025년 4월 4일\n\nmcp 이제 뭔지 알 것 같아요. 감사합니다\n\n1개의 답글\nSuJeong.K\n2025년 4월 6일\n\nmcp에 대해 얘기가 많이 들려와서 궁금했는데 잘 정리해주셔서 감사합니다 :)\n\n1개의 답글\n이찬호\n6일 전\n\n이건 완전히 ..........!!!!! 🤯\n세상의 진실을 깨달아버린 것 같은 기분이에요\n엄청난 글 너무 감사합니다\n\n1개의 답글\n다율\n6일 전\n\nMCP server 되게 궁금했는데 자세히 알려주셔서 감사합니다 ~ ☺️\n\n1개의 답글\n하민\n5일 전\n\nMCP의 좋은 사례까지 상세하게 정리해주셔서 감사합니다!\n\n1개의 답글\n시호\n5일 전\n\nMCP에 대해 이렇게 깊이 있고 깔끔하게 정리한 글은 처음입니다 — 진심으로 감탄하고 갑니다!\n\n1개의 답글\n짝물\n2일 전\n\nmcp 궁금했었는데... 일목요연한 글 정말 감사합니다!\n\n답글 달기\n阳明\n어제\n\n감사합니다, 정말 잘 작성해 주셨네요! 저는 이 웹사이트 https://www.claudemcp.com/docs에서도 자세히 알아보았고, 그 후에 이 글을 읽으니 더 이해가 잘 되었습니다.\n\n구글에서도 A2A 프로토콜을 출시했는데, 이에 대해서도 설명해 주시면 감사하겠습니다!\n\n답글 달기\njack son\n38분 전\n\nI did so love looking through reports created on this site. They can be striking and has now loads of handy information and facts. Strategies for Binary Options\n\n답글 달기\n관련 채용 정보\n미리디\n[미리캔버스] AI Researcher\n전 세계로 확장 중인 미리캔버스에서 AI를 활용한 혁신적인 디자인 생태계 구축에 동참하세요. 디자인에 깊은 관심과 머신러닝 경험이 있는 개발자를 찾고 있으며, 자율적인 근무 환경과 성장 기회를 제공합니다.\n비상교육\nAI ML 엔지니어\n비상교육은 AI/ML 모델 설계 및 배포를 통해 혁신적인 교육 문화를 만들어가는 에듀테크 기업입니다. SQL, Python 등으로 데이터 가공 및 모델링을 수행하며, 강력한 조직 문화로 개인과 기업의 성장을 돕습니다.\n더존비즈온\n개발 인재\n더존은 AI, 클라우드, 데이터 중심의 디지털 대전환을 선도하며 기업의근본적인 성장을 지원합니다. 다양한 개발 분야 인재를 모집하며, 창의적인 환경에서 최고의 기술력으로 도전할 기회를 제공합니다.",
    "tags": [
      "AI",
      "Agentica",
      "Backend",
      "LLM",
      "MCP",
      "frontend",
      "web"
    ],
    "commentCount": "19"
  },
  {
    "title": "KakaoDevelopers를 활용한 만우절 장난치기",
    "description": "2025년 4월 1일.. 갑자기 친구한테 카카오페이로 100만원이 송금됐다는 카카오톡이 공유되었다. 만우절인걸 몰랐던 송금받기를 눌렀지만 열리는 페이지는 이런 페이지였고, 페이지 url도 snuaprilfoolsday였다. 대충 서울대학교 재학생이 만우절에 장난을 치려...",
    "link": "https://velog.io/@zzae_zze/KakaoDevelopers%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%A7%8C%EC%9A%B0%EC%A0%88-%EC%9E%A5%EB%82%9C%EC%B9%98%EA%B8%B0",
    "author": "zzae_zze.log",
    "date": "2025년 4월 2일",
    "comments": "11개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/zzae_zze/post/d5facfea-02b0-4bc1-a59a-bb214371b6da/image.png",
    "content": "zzae_zze.log\n로그인\nzzae_zze.log\n로그인\nKakaoDevelopers를 활용한 만우절 장난치기\n재윤·2025년 4월 2일\n팔로우\n128\naprilfoolsdaykakao-prankkakaodevelopersprank개발자개발자밈만우절만우절장난장난\n만들게 된 계기\n\n\n2025년 4월 1일.. 갑자기 친구한테 카카오페이로 100만원이 송금됐다는 카카오톡이 왔다. 만우절인걸 몰랐던 나는 송금받기를 눌렀지만 열리는 페이지는\n\n이런 페이지였고, 페이지 url도 snuaprilfoolsday였다. 대충 서울대학교 재학생이 만우절에 장난을 치려고 급하게 만든것 같았고, github.io 주소가 노출되었길래 한번 들어가봤다.\n\n역시나 다들 손이 빠른지 이미 제작자의 깃허브 리포지토리는 털려(?) 있었고 매년 새롭게 등장하는 템플릿이 너무 신기하고 이걸 어떻게 만들었을까 싶어서 대충 비슷하게 따라 만들어봤고, 만드는 방법을 공유하려고 이 글을 쓴다.\n\n삽질 1. 깃허브에 올라가있는 코드는 간단하게 자바스크립트를 이용한 페이지였고, 메타데이터에 prank url을 넣어 만든 방법이였다. 우선 해당 방법대로 비슷하게 따라 만든 뒤 vercel로 배포를 해봤을때는\n\n위와 같은 사진처럼 url이 노출되고 이미지는 썸네일처럼 보여서 꽤나 짜쳐보였다.\n그래서 처음엔 카카오페이 내부 개발자가 그냥 심심해서 만든게 여기까지 공유가 된건가 ? 생각을 했지만 카카오페이와 똑같은건 아니더라도 비슷하게 다른 템플릿을 KakaoDevelopers에서 제공하는 api를 이용하면 만들 수 있을것 같다는 생각이 들었다.\n\n\n다행히(?) 삽질 두번만에 비슷하게 성공을 했고, 꽤나 그럴듯한 메세지가 전송됐다.\n\n만드는 방법\n\n우선 KakaoDevelopers에 회원가입을 하고 내 애플리케이션 등록을 해야한다.\n등록하는 방법은 추가만 하면 되고, 프로필 사진이나 이름을 설정하면 그게 공유된 템플릿에 자동으로 들어간다.\n\n\n애플리케이션에 들어가면 좌측 바에서 플랫폼을 누르고, web에 사이트 도메인을 설정하면 된다.\n필자는 로컬호스트와 낚시용으로 만들어져 있는 템플릿 주소를 임시로 엮어서 제작하였다.\n(정확한건 아니지만 로컬호스트를 추가해야하는 이유는 템플릿을 공유하려면 자바스크립트 sdk를 통해 Kakao.Link.sendCustom()으로 실행해야 전송이 된다고 한다)\n구글 사이트는 상대방을 낚게 하기 위한 주소의 도메인이다.\n\n여기까지 등록을 했으면\n\n\n메시지 탭으로 가서 메시지 템플릿을 만들면 된다. GUI 형태로 되어있어 이것저것 기능을 쉽게 추가할 수 있다.\n\n\n중요한건 버튼을 삽입하고, 버튼을 눌렀을때 리다이렉팅 되는 주소를 낚는 주소로 등록해야한다.\n\n이런식으로 임의의 템플릿을 만들고 저장을 해두면 템플릿 ID가 생성이 되고, 그 생성된 템플릿 ID를 기억해둔다.\n\n이제 80프로까지 왔다.\n마지막으로 공유하기 위한 자바스크립트 파일을 만들어야하는데\nvs코드나 cursor 등 아무거나 사용해도 상관없다. index.html 파일을 만들고 아래의 코드를 붙혀넣는다\n\n<!DOCTYPE html>\n<html lang=\"ko\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>카카오 장난 메시지 공유</title>\n  <!-- 카카오 SDK 불러오기 -->\n  <script src=\"https://developers.kakao.com/sdk/js/kakao.js\"></script>\n  <style>\n    body {\n      font-family: sans-serif;\n      text-align: center;\n      margin-top: 100px;\n    }\n    button {\n      padding: 12px 24px;\n      font-size: 18px;\n      background-color: #fee500;\n      border: none;\n      border-radius: 8px;\n      cursor: pointer;\n    }\n  </style>\n</head>\n<body>\n\n  <h1>📢 중간고사 패스권 도착!?</h1>\n  <p>친구에게 카카오톡 장난 메시지를 보내보세요 😆</p>\n  <button onclick=\"sendFoolMessage()\">카카오톡으로 공유하기</button>\n\n  <script>\n    // JavaScript 키로 초기화 (너의 앱 키로 바꿔야 함!)\n    Kakao.init(\"자바스크립트 앱키 복붙하시면 됩니다.\");\n\n    function sendFoolMessage() {\n      Kakao.Link.sendCustom({\n        templateId: 템플릿 ID 복붙하시면 됩니다. // 너가 만든 템플릿 ID\n      });\n    }\n  </script>\n\n</body>\n</html>\n\n\n\n앱키는 이 탭에서 확인이 가능하다.\n\nindex.html을 저장하고, 로컬에서 실행시키면 아래처럼 나올텐데\n\n\n카카오톡으로 공유하기 버튼을 누르고, 로그인을 하면 카카오톡 친구로 등록된 사람들에게 공유가 가능하다.\n\n\n이런식으로.. 이걸 공유받은 사람이 버튼을 누르면 필자가 당했던 url이 열리게 된다.\n\n\n처음 이런 만우절 장난을 만드신분이 어떻게 만들었는진 아직 등판을 하지 않으셔서 자세히는 모르지만 이런식으로 최대한 간단하게 장난치는 템플릿을 제작할 수 있다.\n\n최대한 상세하게 글보단 사진 위주로 설명했는데, 혹시 이해가 안되는 부분이 있으시다면 댓글 남겨주시면 감사하겠습니다!!\n\n아무튼 오늘도 개발자가 되면 이런 장난까지 칠 수 있구나를 느끼며 개발자로써 한발자국 관심도가 올라가게 되었다..\n\n재윤\n팔로우\n이전 포스트\n공식문서 기반 Next.js 독학일기(4) - React 핵심개념 3가지(Components, Props, State)\n11개의 댓글\n댓글 작성\n롱이\n2025년 4월 2일\n\n감사합니다. 덕분에 친구에게 장난쳐보았습니다 ㅎㅎ\nindex.html 실행할 때 서버로 실행하는것을 몰라서 GPT가 python -m http.server index.html로 알려주어서 해결했습니다.\n\n1개의 답글\n김록기\n2025년 4월 3일\n\n오 재밌겠다!\n\n1개의 답글\n윤상혁\n5일 전\n\n재밌게 잘 봤습니다!\n\n1개의 답글\nmakiito__\n4일 전\n\n이 게시물을 4월 1일에 보았으면 좋았을 것을 . . 재밌게 읽고 갑니다!\n대신귀\n여운알\n파카를\n드리겠\n습니다\n\n1개의 답글\n허서영\n2일 전\n\n우왕 재밌네요 해봐야겠어요 ㅋㅋㅋ\n\n답글 달기\n차한음\n1일 전\n\n감사합니다~\n\n답글 달기\n관련 채용 정보\n채널코퍼레이션\n[채널톡] Software Engineer\n채널톡은 아시아에서 가장 빠르게 성장하는 B2B SaaS 회사로, '올인원 AI 메신저'를 통해 고객 소통을 혁신하고 있습니다. 다양한 기술 스택을 활용해 글로벌 시장의 복잡한 문제를 해결할 수 있는 엔지니어를 기다립니다.\n미리디\n[미리캔버스] 프론트엔드 개발자\n미리캔버스는 디자인 생태계를 혁신하는 올인원 플랫폼으로, 1,400만 고객을 위해 프론트엔드 개발을 통해 사용자 경험을 최적화하고 있습니다. React와 Next.js를 활용해 확장 가능한 구조를 설계하며, 빠르게 변화하는 환경에서도 뛰어난 성능을 제공하는 팀의 일원이 되어보세요!\n토스플레이스\nFrontend Developer\n토스플레이스에서 프론트엔드 개발자로 팀에 합류하여 오프라인 결제 시장의 디지털 혁신에 기여하세요. React와 TypeScript를 활용하여 매장 운영의 새로운 경험을 창출하고, 자율적인 근무 문화를 누리며 도전적인 프로젝트에 참여할 기회를 가져보세요.",
    "tags": [
      "aprilfoolsday",
      "kakao-prank",
      "kakaodevelopers",
      "prank",
      "개발자",
      "개발자밈",
      "만우절",
      "만우절장난",
      "장난"
    ],
    "commentCount": "11"
  },
  {
    "title": "VSC 마우스 없이 사용하기 (스압 주의)",
    "description": "VScode 전문가가 돼 봅시다.",
    "link": "https://velog.io/@joch2712/VSC-%EB%A7%88%EC%9A%B0%EC%8A%A4-%EC%97%86%EC%9D%B4-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0-%EC%8A%A4%EC%95%95-%EC%A3%BC%EC%9D%98",
    "author": "민경찬",
    "date": "2025년 4월 4일",
    "comments": "1개의 댓글",
    "likes": "95",
    "thumbnailUrl": "https://velog.velcdn.com/images/joch2712/post/7a8ce737-5c82-48eb-8683-d37b1942bbcd/image.png",
    "error": "Navigation timeout of 60000 ms exceeded"
  },
  {
    "title": "[번역] 자바스크립트 Temporal 기능이 곧 도입됩니다",
    "description": "자바스크립트에서 날짜와 시간 처리는 항상 복잡하고 까다로웠던 것 같습니다. 이제 곧 새로운 Temporal 객체가 도입되며 더욱 간단하고 현대적인 방식을 통해 시간 관리가 편리해질 예정이니, 그 가능성을 이 글에서 확인해 보실 수 있습니다.",
    "link": "https://velog.io/@eunbinn/javascript-temporal-is-coming",
    "author": "eunbinn.log",
    "date": "2025년 4월 3일",
    "comments": "3개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/eunbinn/post/d1561930-2e0f-428d-a1c7-d8c522978d9d/image.png",
    "content": "eunbinn.log\n로그인\neunbinn.log\n로그인\n[번역] 자바스크립트 Temporal 기능이 곧 도입됩니다\neunbinn·2025년 4월 3일\n팔로우\n24\nFrontEnd 번역\n목록 보기\n42/42\n\n출처: https://developer.mozilla.org/en-US/blog/javascript-temporal-is-coming/\n\n자바스크립트 Temporal 객체의 구현이 브라우저의 실험 버전에 도입되기 시작했습니다. 이로써 자바스크립트에서 날짜와 시간을 다루는 작업이 훨씬 더 간단하고 현대적으로 변화할 것이기 때문에, 웹 개발자들에게 매우 반가운 소식입니다.\n\n스케줄링, 국제화, 또는 시간에 민감한 데이터를 활용하는 애플리케이션은 이제 내장 기능을 통해서 더 효율적이고, 정확하며, 일관된 날짜, 시간, 기간, 그리고 캘린더를 다룰 수 있게 될 것입니다. 아직 모든 브라우저에서 안정적으로 지원되기까지는 갈 길이 멀고, 구현 과정에서 변경이 있을 수도 있지만, 현재 시점에서 Temporal의 모습과 그 매력, 그리고 Temporal이 해결하는 문제들을 미리 살펴볼 수 있습니다.\n\n여러분이 빠르게 익힐 수 있도록, 이번 주 MDN에 상세한 설명과 예제가 포함된 270 페이지 이상의 Temporal 관련 문서가 추가되었습니다.\n\nTemporal 객체란 무엇인가요?\n\nTemporal 객체를 이해하기 위해서는 자바스크립트의 Date 객체를 살펴봐야 합니다. 자바스크립트가 1995년에 만들어졌을 때, Date 객체는 결함이 많았던 자바의 java.util.Date 초기 구현에서 가져왔습니다. 자바는 이 구현을 1997년에 교체했지만, 자바스크립트는 알려진 문제들에도 불구하고 거의 30년 동안 동일한 API를 사용해 왔습니다.\n\n자바스크립트 Date 객체의 주요 문제는 사용자 로컬 시간과 UTC만 지원하고, 시간대(time zone)를 따로 지원하지 않는다는 점입니다. 게다가, 파싱 동작을 신뢰할 수 없으며, Date 객체 자체가 변경 가능하다는 점은 추적하기 어려운 버그를 야기합니다. 이 외에도 서머타임(Daylight Saving Time)에 대한 계산이나 과거의 달력 체제 변화와 같은 매우 복잡하고 다루기 어려운 문제도 존재합니다.\n\n이러한 문제들 때문에 자바스크립트에서 날짜와 시간을 다루는 작업은 복잡하고 버그가 발생하기 쉽습니다. 이는 일부 시스템에는 심각한 결과를 초래할 수 있습니다. 그래서 대부분의 개발자들은 애플리케이션의 날짜와 시간을 좀 더 잘 다루기 위해 Moment.js나 date-fns와 같은 전용 라이브러리에 의존해 왔습니다.\n\nTemporal은 Date 객체를 완전히 대체할 수 있도록 설계되었으며, 날짜와 시간 관리를 신뢰 가능하고 예측 가능하게 합니다. Temporal은 타임존, 캘린더 표현에 대한 지원과 변환, 비교, 계산, 포맷팅 등을 위한 다양한 내장 메서드를 추가로 제공합니다. API의 기능은 200개 이상의 유틸리티 메서드에 걸쳐 있으며, 이러한 모든 정보는 MDN의 Temporal 문서에서 확인할 수 있습니다.\n\n핵심 개념\n\nTemporal에서는 고유한 시점(Instants), 지역 시간(Wall-clock times), 그리고 기간(Durations)을 주요 개념으로 다룹니다. 이러한 개념들을 처리하기 위해 API는 다음과 같은 전체적인 구조를 가지고 있습니다.\n\n기간: Temporal.Duration 두 시점 간의 시간 차이\n시점:\n고유한 시점:\n타임스탬프 형식: Temporal.Instant\n시간대를 포함한 날짜-시간: Temporal.ZonedDateTime\n시간대가 없는 날짜/시간(\"Plain\"):\n전체 날짜와 시간: Temporal.PlainDateTime\n날짜만: Temporal.PlainDate\n연도와 월만: Temporal.PlainYearMonth\n월과 일만: Temporal.PlainMonthDay\n시간만: Temporal.PlainTime\n현재 시간: Temporal.now를 사용하면 현재 시간을 다양한 클래스 인스턴스 형태로 가져오거나 특정한 형식으로 얻을 수 있습니다.\nTemporal 예제\n\nTemporal의 가장 기본적인 사용법 중 하나는 현재 날짜와 시간을 ISO 문자열로 가져오는 것입니다. 아래 예시에서 볼 수 있듯이, 이제 여러 메서드에서 시간대를 제공할 수 있게 되어, 복잡한 계산을 직접 수행할 필요 없이 간편하게 처리할 수 있습니다.\n\n// 시스템의 시간대에서 현재 날짜 가져오기\nconst dateTime = Temporal.Now.plainDateTimeISO();\nconsole.log(dateTime); // 예: 2025-01-22T11:46:36.144\n\n// \"America/New_York\" 시간대에서 현재 날짜 가져오기\nconst dateTimeInNewYork = Temporal.Now.plainDateTimeISO(\"America/New_York\");\nconsole.log(dateTimeInNewYork);\n// 예: 2025-01-22T05:47:02.555\n\n다른 달력 시스템을 다룰 때도 작업이 훨씬 간단해졌습니다. 예를 들어, 그레고리력 외에도 히브리력, 중국력, 이슬람력 등 다양한 달력 체계를 사용하여 날짜를 생성할 수 있습니다. 아래의 코드는 다가오는 춘절(중국 설날)이 언제인지 쉽게 확인할 수 있도록 도와줍니다(곧이네요!(글이 작성된 시간 기준)).\n\n// 중국 설날은 중국력에서 1월 1일입니다.\nconst chineseNewYear = Temporal.PlainMonthDay.from({\n  monthCode: \"M01\",\n  day: 1,\n  calendar: \"chinese\",\n});\nconst currentYear = Temporal.Now.plainDateISO().withCalendar(\"chinese\").year;\nlet nextCNY = chineseNewYear.toPlainDate({ year: currentYear });\n// 만약 nextCNY가 현재 날짜보다 이전이라면, 1년을 앞으로 이동합니다.\nif (Temporal.PlainDate.compare(nextCNY, Temporal.Now.plainDateISO()) <= 0) {\n  nextCNY = nextCNY.add({ years: 1 });\n}\nconsole.log(\n  `The next Chinese New Year is on ${nextCNY\n    .withCalendar(\"iso8601\")\n    .toLocaleString()}`\n);\n// 다음 중국 설날은 2025년 1월 29일입니다. (이 글을 작성할 당시 기준)\n\n유닉스 타임스탬프는 많은 시스템(API나 데이터베이스 등)에서 시간을 나타내기 위해 사용되는 형식으로 매우 일반적인 사용 사례입니다. 아래 예제는 밀리초 단위의 유닉스 타임스탬프를 받아 이를 기반으로 인스턴스를 생성하고, Temporal.Now를 사용해 현재 시간을 구한 다음, 현재 시점부터 해당 유닉스 타임스탬프까지 몇 시간이 남았는지 계산하는 방법을 보여줍니다.\n\n// 1851222399924는 우리가 사용할 타임스탬프입니다.\nconst launch = Temporal.Instant.fromEpochMilliseconds(1851222399924);\nconst now = Temporal.Now.instant();\nconst duration = now.until(launch, { smallestUnit: \"hour\" });\nconsole.log(`발사까지 ${duration.toLocaleString(\"en-US\")}가 남았습니다.`);\n// \"발사까지 31,600시간이 남았습니다.\" <- @js-temporal/polyfill\n// \"발사까지 PT31600H가 남았습니다.\" <- Firefox Nightly\n\n현재 Firefox의 구현에서는 toLocaleString 메서드가 지역화된 문자열을 출력하지 않으므로, 위의 예제처럼 (PT31600H) 지역 특정적이지 않은 기간 형식이 반환됩니다. 이는 기술적 한계라기보다는 설계 선택에 더 가깝기 때문에, 기간을 포매팅하는 것이 가능하므로 향후 폴리필(@js-temporal/polyfill)과 Firefox의 구현이 최종적으로 일치할 가능성이 있습니다.\n\n강조할 내용이 많지만, 개인적으로 API에서 흥미롭게 느껴진 하나의 패턴은 compare() 메서드 입니다. 이 메서드는 기간을 간단하면서도 효율적으로 정렬할 수 있도록 해줍니다.\n\nconst durations = [\n  Temporal.Duration.from({ hours: 1 }),\n  Temporal.Duration.from({ hours: 2 }),\n  Temporal.Duration.from({ hours: 1, minutes: 30 }),\n  Temporal.Duration.from({ hours: 1, minutes: 45 }),\n];\n\ndurations.sort(Temporal.Duration.compare);\nconsole.log(durations.map((d) => d.toString()));\n// [ 'PT1H', 'PT1H30M', 'PT1H45M', 'PT2H' ]\nTemporal 사용과 브라우저 지원 현황\n\nTemporal 기능이 점진적으로 실험적인 브라우저 릴리스에 포함되기 시작했으며, 현재 Firefox에서 가장 성숙하게 구현되어 있는 것으로 보입니다. Firefox의 경우, Temporal은 최신 개발 버전(Nightly)에 기본적으로 포함되어 있으며, 이를 활성화하려면 javascript.options.experimental.temporal 환경설정을 키면 됩니다. 전체 브라우저 호환성에 대한 자세한 내용을 확인하고 싶다면, (꽤나 방대한)Temporal 객체 브라우저 호환성 섹션에서 확인하실 수 있습니다.\n\n다음은 Temporal 구현에 대한 주요 브라우저 별 추적 링크입니다.\n\nFirefox: 최신 개발 빌드(Nightly)에서 기본적으로 Temporal을 빌드\nSafari: [JSC] Temporal 구현\nChrome: Temporal 제안 구현\n\n또한, https://tc39.es/proposal-temporal/docs/ 페이지를 방문하시면 @js-temporal/polyfill을 사용할 수 있습니다. 따라서 TC39 문서 페이지에서 개발자 도구를 열어, 플래그나 환경설정을 변경하지 않고도 어떤 브라우저에서든 콘솔을 통해 일부 예제를 직접 실행해볼 수 있습니다.\n\n실험적인 구현이 점차 도입되고 있는 지금이야말로 Temporal을 시도해 보고, 자바스크립트에서 날짜와 시간을 처리하는 현대적인 접근 방식에 익숙해질 좋은 시점입니다.\n\neunbinn\n팔로우\n이전 포스트\n[번역] 리액트에서의 단일 책임 원칙: 컴포넌트 집중의 기술\n3개의 댓글\n댓글 작성\nRohitI ModhI\n2025년 4월 4일\n\nIf you’re a fan of online gaming and entertainment, Laser247 Club is the place to be! With easy Laser247 Login, you can dive into top gaming experiences and exciting challenges. Join now and take your online gaming to the next level! Visit: https://laser247club.co.in/\n\n답글 달기\nRohitI ModhI\n2025년 4월 4일\n\nIf you’re a fan of online gaming and entertainment, Laser247 is the place to be! With easy Laser247 Login, you can dive into top gaming experiences and exciting challenges. Join now and take your online gaming to the next level! Visit: https://laser247club.co.in/\n\n답글 달기\n___\n2025년 4월 4일\n\nDate보다 좀 복잡해 보이네요\n\n답글 달기\n관련 채용 정보\n아이포트폴리오\n프론트엔드 개발자\n'올바른 영어 교육 방법으로 비효율적인 영어 교육 시장을 혁신하는 iPortfolio에서 프론트엔드 개발자를 찾습니다. TypeScript와 React를 활용해 고객 맞춤형 영어 학습 플랫폼을 개발하고 글로벌 서비스를 확장하며 성장할 기회를 놓치지 마세요!'\n피클플러스\n프론트엔드 주니어 개발자\n피클플러스는 OTT 시장에서 빠르게 성장하며 '글로벌 OTT 슈퍼앱' 비전을 추구하는 스타트업입니다. TypeScript, React, Next.js를 활용한 프론트엔드 개발을 통해 뛰어난 동료들과 함께할 기회를 제공합니다.\n씨제이올리브영(CJ올리브영)\n프론트엔드 개발자 (커머스서비스)\n올리브영은 헬스&뷰티 스토어로 옴니채널 혁신을 이끄는 글로벌 라이프스타일 플랫폼입니다. JavaScript와 React를 활용한 프론트엔드 개발 프로젝트로 고객 경험을 개선하며, 독보적인 오프라인 비즈니스와 온라인 결합한 플랫폼을 함께 만들어갈 인재를 기다립니다.",
    "tags": [],
    "commentCount": "3"
  },
  {
    "title": "(번역) 리액트 개발자를 위한 SSR 심층 분석",
    "description": "지금부터 리액트의 서버 사이드 렌더링(SSR), 사전 렌더링(pre-rendering), 하이드레이션(hydration) 및 정적 사이트 생성(SSG)이 작동하는 방식, 비용, 성능에 미치는 영향, 이점 및 장단점에 대해 단계별로 살펴보시죠.",
    "link": "https://velog.io/@tap_kim/ssr-deep-dive-for-react-developers",
    "author": "tapk.log",
    "date": null,
    "comments": "2개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/tap_kim/post/5d42addc-4fa6-4eef-a875-c5a573265903/image.jpeg",
    "content": "tapk.log\n로그인\ntapk.log\n로그인\n(번역) 리액트 개발자를 위한 SSR 심층 분석\nTapK·4일 전\n팔로우\n18\nReactSSR\n\n원문: https://www.developerway.com/posts/ssr-deep-dive-for-react-developers\n\n지금부터 리액트의 서버 사이드 렌더링(SSR), 사전 렌더링(pre-rendering), 하이드레이션(hydration) 및 정적 사이트 생성(SSG)이 작동하는 방식, 비용, 성능에 미치는 영향, 이점 및 장단점에 대해 단계별로 살펴보시죠.\n\n이전 글에서는 초기 부하를 측정하기 위한 성능 지표의 기본 사항, CSR(클라이언트 사이드 렌더링)의 정의와 인기 있는 이유, 성능 플레임 차트를 기록하고 읽고 해석하는 방법에 대해 알아보았습니다. 또한 클라이언트 사이드 렌더링의 가장 중요한 두 가지 단점, 즉 초기 로딩 성능에 부정적인 영향을 미치고 자바스크립트가 없는 환경에서는 작동하지 않는다는 사실도 알게 되었습니다.\n\n이 글에서는 SSR이라는 또 다른 렌더링 패턴과 사전 렌더링 및 SSG와 같은 변형을 소개함으로써 이러한 단점을 해결하는 데 초점을 맞출 것입니다. 아름다운 웹사이트를 위한 가장 간단한 사전 렌더링을 구현하고 그 비용과 해결 방법을 살펴본 다음, 적절한 SSR을 구현하고 성능 영향을 측정하고 SSR의 비용에 관해 이야기하고 웹사이트를 위한 SSG의 빠른 구현으로 마무리하는 스터디 프로젝트가 다시 시작됩니다.\n\n이번 내용은 흥미진진할 것입니다!\n\n자바스크립트가 없는 환경이 중요한 이유\n\n먼저 자바스크립트가 없는 환경부터 시작하겠습니다. 그런데 이 말은 굉장히 의아할 수 있습니다. 요즘 누가 브라우저에서 자바스크립트를 비활성화하나요? 모든 곳에서 기본적으로 활성화되고, 자바스크립트 없이 작동하는 것은 거의 없으며, 대부분의 사람은 자바스크립트를 비활성화할 줄도 모릅니다. 그렇죠?\n\n여기서 답은 “사람”이라는 단어에 있습니다. 더 정확히 말하자면, 웹사이트에 액세스할 수 있는 사람이 실제 사람만이 아니라는 사실에 있습니다. 이 분야의 두 가지 주요 플레이어가 있습니다.\n\n검색 엔진 로봇(크롤러), 특히 구글 크롤러.\n다양한 소셜 미디어 및 메신저의 '미리보기' 기능.\n\n모두 비슷한 방식으로 작동합니다. 먼저 어떻게든 웹사이트 페이지의 URL을 가져옵니다. 이는 일반적으로 사용자가 소셜 미디어 친구들과 페이지 링크를 공유하려고 할 때 발생합니다. 또는 검색 봇이 온라인에 공개된 수백만 개의 페이지를 무의식적으로 크롤링할 때 발생합니다. 그래서 크롤러라고 불리는 것입니다.\n\n둘째, 봇은 처음에 브라우저가 하는 것처럼 서버로 요청을 전송하고 HTML을 수신합니다.\n\n셋째, 봇은 해당 HTML에서 원하는 정보를 추출하여 처리합니다. 검색 엔진은 텍스트, 링크, 메타 태그 등과 같은 정보를 추출합니다. 이를 바탕으로 검색 색인을 생성하고 페이지가 “구글 검색 가능” 상태가 됩니다. 소셜 미디어 미리보기는 메타태그를 가져와 큰 사진, 제목, 때로는 짧은 설명과 함께 우리가 모두 보았던 멋진 미리보기 기능을 만듭니다.\n\n마지막으로 네 번째... 사실, 네 번째는 없을 때도 있습니다. 그게 다입니다. 자바스크립트 없이 순수한 HTML만 있습니다. 자바스크립트로 페이지를 제대로 렌더링 하려면 로봇이 실제 브라우저를 구동하고 자바스크립트를 로드한 다음 페이지 생성이 완료될 때까지 기다려야 하기 때문입니다. 이는 리소스와 시간 측면에서 상당히 큰 비용이 소요됩니다. 따라서 모든 로봇이 이를 수행할 수 있는 것은 아닙니다.\n\n스터디 프로젝트에서 실제로 작동하는 모습을 확인할 수 있습니다. 다운로드하고 의존성을 설치합니다.\n\nnpm install\n\n빌드하고 시작하세요.\n\nnpm run build\nnpm run start\n\n홈(Home)과 설정(Setting) 사이를 탐색합니다. 탐색을 통해 페이지의 제목이 변경되는 것을 볼 수 있습니다. 홈(Home) 페이지는 \"Study project: Home\"으로, 설정(Setting) 페이지는 \"Study project: Settings\"로 변경됩니다.\n\n이 제목은 다음과 같은 간단한 코드로 리액트에 삽입됩니다.\n\nuseEffect(() => {\n  updateTitle(\"Study project: Home\");\n}, []);\n\n내부 코드는 이게 전부입니다.\n\nexport const updateTitle = (text: string) => {\n  document.title = text;\n};\n\n그러나 처음 로드할 때 잠시 \"깜박이는\" 것을 볼 수 있는데, 이는 기본 제목이 \"Vite + React + TS\"이기 때문입니다. 이는 index.html에 있는 제목이고 결과적으로 서버에서 받는 제목입니다.\n\n이제 ngrok(또는 유사한 도구가 있는 경우)을 사용하여 웹사이트를 외부에 노출합니다.\n\nngrok http 3000\n\n생성된 URL을 원하는 소셜 미디어에 게시하려고 시도합니다. 생성된 미리보기에서 기존의 “Vite + 리액트 + TS” 제목을 볼 수 있습니다. 이때 자바스크립트는 로드되지 않았습니다.\n\n하지만 일부 봇에선 그렇지 않은 경우가 있습니다. 대부분의 성능이 좋은 검색 엔진은 자바스크립트 파일의 실행을 기다립니다. 예를 들어 구글은 “순수한” HTML의 구문을 분석하고 페이지를 “렌더링” 대기열에 넣는 2단계 프로세스를 통해 브라우저를 실행하고 웹 사이트를 로드한 다음 자바스크립트 렌더링을 기다립니다. 그리고 가능하면 모든 것들을 다시 추출하는 과정을 수행합니다.\n\n그러나 이 프로세스는 자바스크립트에 크게 의존하는 웹사이트의 색인 작업이 “더 느리고 자원이 많이 소요될 수 있다”는 것을 의미합니다.\n\n따라서 웹사이트의 경우 아래 두 가지가 중요합니다.\n\n가능한 한 많은 검색 엔진에서 최대한 빨리 검색될 수 있도록 하는 것이 중요합니다.\n소셜 미디어 플랫폼에서 공유할 수 있어야 하고 그 과정에서 보기 좋게 보이는 것이 중요합니다.\n\n그런 다음 서버가 첫 번째 요청에 중요한 정보가 모두 포함된 “적절한” HTML을 반환하는 것이 매우 중요합니다. 이러한 웹사이트의 대표적인 예는 다음과 같습니다.\n\n읽기 우선 웹사이트, 즉 다양한 형태의 블로그, 문서, 지식 기반, 포럼, Q&A 웹사이트, 뉴스 매체 등.\n다양한 형태의 전자상거래 웹사이트.\n랜딩 페이지.\n이외 월드 와이드 웹에서 검색할 수 있는 거의 모든 것들.\n\n즉, 첫 번째 HTML 응답으로 빈 div를 사용하여 “고전적인” 클라이언트 사이드 렌더링을 하는 SPA는 검색 엔진에 좋지 않습니다.\n\n하지만 그렇다고 해서 분노에 차서 리액트를 버려야 한다는 뜻은 아닙니다. 먼저 시도해 볼 수 있는 몇 가지 해결책이 있습니다.\n\n서버 사전 렌더링\n\n이 경우에는 서버를 도입해야 합니다. 현재 스터디 프로젝트에서는 다음과 같이 보입니다.\n\napp.get(\"/*\", async (c) => {\n  const html = fs.readFileSync(path.join(dist, \"index.html\")).toString();\n\n  return c.html(html);\n});\n\n서버는 요청을 받으면 빌드 단계에서 미리 생성한 index.html 파일을 읽고 문자열로 변환한 후 요청자에게 다시 전송합니다. 이는 기본적으로 SPA를 지원하는 모든 호스팅 플랫폼이 수행하는 작업입니다. 다만 플랫폼에서 직접 제어하거나 수정할 수 있는 기능은 아닙니다.\n\n하지만 “자바스크립트 없음” 문제를 해결하려면 지금 당장 서버를 수정해야 합니다. 다행히도 이는 큰 문제는 아닙니다. 우리가 작업한 내용이 문자열이라는 사실인 것만으로도 많은 것들이 단순화됩니다. 문자열을 다시 보내기 전에 이 문자열을 수정하는 것을 막을 수 있는 것은 아무것도 없기 때문입니다. 이제 기존 제목을 찾아서 “Study project”로 바꾸어 보겠습니다. 아래 예문을 확인해 보시죠.\n\napp.get(\"/*\", async (c) => {\n  const html = fs.readFileSync(path.join(dist, \"index.html\")).toString();\n\n  const modifiedHTML = html.replace(\n    \"<title>Vite + React + TS</title>\",\n    `<title>Study project</title>`\n  );\n\n  return c.html(html);\n});\n\n이 방법이 조금 더 나은 방법이지만, 실제로는 모든 페이지마다 제목이 바뀌어야 하므로 이렇게 정적으로 유지하는 것은 의미가 없습니다. 다행히도 각 서버는 요청이 어디에서 오는지 항상 정확히 알고 있습니다. 제가 사용하는 프레임워크(Hono)의 경우 c.req.path를 요청하여 경로 정보를 추출하기만 하면 됩니다.\n\n그런 다음 해당 경로를 기반으로 다양한 제목을 생성할 수 있습니다.\n\napp.get(\"/*\", async (c) => {\n  const html = fs.readFileSync(path.join(dist, \"index.html\")).toString();\n\n  const title = getTitleFromPath(pathname);\n\n  const modifiedHTML = html.replace(\n    \"<title>Vite + React + TS</title>\",\n    `<title>${title}</title>`\n  );\n\n  return c.html(html);\n});\n\ngetTitleFromPath에서 다음과 같은 작업을 수행할 수 있습니다.\n\nconst getTitleFromPath = (pathname: string) => {\n  let title = \"Study project\";\n\n  if (pathname.startsWith(\"/settings\")) {\n    title = \"Study project: Settings\";\n  } else if (pathname === \"/login\") {\n    title = \"Study project: Login\";\n  }\n\n  return title;\n};\n\n실제 환경에서는 실제 페이지와 함께 배치하거나 페이지 내 코드에서 추출해야 할 수도 있습니다. 그렇지 않으면 거의 즉시 동기화되지 않습니다. 하지만 스터디 프로젝트의 경우 이 정도면 충분합니다.\n\n마지막으로 예쁘게 만들기 위해 index.html 파일에서 원래 제목인 <title>Vite + 리액트 + TS</title>을 <title>{{title}}</title>과같이 바꾸고 템플릿으로 바꿀 수 있습니다.\n\n<html lang=\"en\">\n  <head>\n    <title>{{ title }}</title>\n  </head>\n  ...\n</html>;\n\n// 서버에서 이 작업을 대신하세요.\nconst modifiedHTML = html.replace(\"{{title}}\", title);\n\n향후에는 필요에 따라 템플릿 언어 중 원하는 언어로 변환할 수 있습니다.\n\n물론 제목 title 태그에만 국한되지 않고 <head>에 있는 모든 정보를 이렇게 사전 렌더링 할 수 있습니다. 이렇게 하면 소셜 미디어 미리보기 기능의 “자바스크립트 없음” 문제를 비교적 쉽고 적은 비용으로 해결할 수 있어 일반적으로 이 이상은 필요하지 않습니다. 대부분은 정보가 포함된 <meta> 태그의 집합인 오픈 그래프 프로토콜에 의존합니다.\n\n메타 태그뿐만 아니라 전체 페이지를 사전 렌더링 할 수도 있습니다! 하지만, 이 부분은 아래 '도전 과제' 블록에서 SSR에 대해 더 많은 것들을 배울 수 있습니다.\n\n도전 과제\n\n백엔드에서 index 파일의 내용을 backend/pre-rendering-index.ts의 내용으로 바꿉니다.\nsrc/index.html에서 title 태그의 내용을 {{ title }}로 바꿉니다.\n소셜 미디어 공유에 필요한 메타태그를 지원하도록 프런트엔드 및 백엔드 코드를 모두 리팩터링합니다(목록 참조).\n프로젝트를 빌드하고 다시 ngrok을 통해 노출한 다음 각 페이지(로그인, 홈, 설정)를 원하는 소셜 미디어에 공유해 보세요. 이제 미리보기가 제대로 작동하고 각 페이지의 세부 정보가 표시되어야 합니다.\n보너스 질문: 메타태그 정보가 클라이언트와 서버 간에 중복되지 않도록 프로젝트를 어떻게 리팩토링하나요?\n사전 렌더링 서버 비용\n\n위에서 메타태그 사전 렌더링이 비교적 저렴하다고 언급했습니다. 하지만 이것이 정확히 무엇을 의미할까요? 특히 도입 전의 비용과 노력에 비해 얼마나 저렴할까요?\n\n안타깝게도 완전히 정적인 SPA와 비교하면 좋은 소식은 없습니다. 간단한 사전 렌더링 스크립트를 추가함으로써 이제 처리해야 할 복잡성이 명백하게 증가하는 것 외에 두 가지 문제가 생겼습니다.\n\n어디에 배포할까요?\n\n첫 번째 문제는 앱을 지금 어디에 배포해야 해야하는가입니다. 요즘에는 정적 리소스를 호스팅 하는 것이 매우 저렴하기 때문에 변경 전에는 호스팅 비용을 오랫동안 0으로 유지할 수 있었습니다. 이제는 서버가 필요합니다. 그리고 서버는 일반적으로 저렴하지 않습니다.\n\n여기에는 가장 일반적으로 두 가지 해결법이 있습니다.\n\n정적 리소스를 제공하는 호스팅 제공업체의 서버리스 펑션(function)을 사용할 수 있습니다. Cloudflare Workers, Netlify Functions, Vercel Functions, Amazon Lambdas 등입니다. 대부분의 정적 리소스 호스팅 제공업체는 어떤 형태로든 이러한 펑션을 갖추고 있을 것입니다.\n\n여기서 장점은 서버와 유지 관리에 대해 신경 쓸 필요가 없다는 것입니다. 클라우드 펑션은 제공업체가 우리를 대신해 처리하는 미니 서버와 같습니다. 우리가 할 일은 코드를 작성하는 것뿐이고, 마법처럼 그냥 작동합니다. 그 외의 모든 것은 그들의 관심사입니다. 스터디 프로젝트, 일부 특정 분야의 프로젝트, 초기의 프로젝트, 바이럴성이 내재되어 있지 않은 프로젝트의 경우 클라우드 펑션이 최적의 선택이 될 것입니다.\n\n클라우드 펑션은 일반적으로 구성 및 배포가 매우 쉽고, 사용량에 따라 요금이 책정되며, 실제로 엔드포인트에서 사용량에 따라 요금이 부과됩니다. 주말 동안 실수로 컨테이너를 실행 상태로 두었다가 예상치 못한 요금이 부과될 가능성은 없습니다.\n\n단점은 \"사용량 당 가격\" 부분입니다. 웹사이트의 인기가 높을수록 사용량이 한도를 초과할 가능성이 높아집니다. 한 프로젝트가 HackerNews나 TikTok에서 인기를 얻으면서 갑자기 수백 명이 아닌 수백만 명의 방문자를 확보하고 소유자가 깜짝 놀라 5천 달러의 청구서를 받은 끔찍한 이야기를 몇 번 읽은 적이 있습니다. 따라서 서버리스 해결법에서는 지출 한도를 설정하고, 지출을 면밀히 모니터링하며, 이러한 상황에서 어떻게 해야 할지에 대한 계획을 세우는 것이 중요합니다.\n\n서버리스 펑션이 마음에 들지 않는다면 실제 작은 노드(또는 다른 어떤 것들) 서버로 유지한 후 AWS, Azure, Digital Ocean, [선호하는 호스팅 제공업체 적용]에 이르기까지 모든 클라우드 플랫폼에 배포할 수 있습니다.\n\n이 해결법에는 장점이 있습니다. 모든 것을 사용자가 제어할 수 있습니다. 한 해결법에서 다른 해결법으로 마이그레이션 할 때 공급업체에 종속되는 서버리스 펑션과 달리 코드 변경이 필요하지 않습니다. 가격은 일반적으로 훨씬 더 예측할 수 있고 훨씬 간단하며 사용량이 증가할 때 훨씬 저렴합니다. 또한 서버리스 펑션은 일반적으로 매우 제한적이지만, 원하는 기술 스택을 사용할 수 있습니다.\n\n단점도 장점과 똑같습니다. 이제 모든 것은 여러분에게 달려 있습니다. CPU/메모리 사용량을 모니터링해야 합니다. 통합 가시성에 대한 걱정. 확장에 대한 걱정. 메모리 누수로 인해 밤잠을 설치게 될 것입니다.\n\n그리고 지리적 영역에 대해서도 걱정해야 합니다. 이는 순수 SPA 앱에 어떤 종류의 서버를 도입할 때 발생하는 두 번째 문제로 이어집니다.\n\n서버 도입이 성능에 미치는 영향\n\n초기 로드와 지연 시간 및 CDN이 초기 로드 성능에 미치는 영향에 대한 글을 기억하시나요? 메타태그만 사전 렌더링하는 초보적인 서버라도 도입하여 신규 사용자든 기존 사용자든 상관없이 모든 초기 로드 요청에 대해 서버에 캐시 되지 않은 불가피한 왕복 요청을 의무적으로 도입하고 있습니다.\n\n처음부터 좋지 않았던 SPA 앱의 초기 로드 성능을 조금 더 나쁘게 만들었을 뿐입니다. 얼마나 더 나빠졌는지는 서버가 정확히 어디에 배포되었는지에 따라 크게 달라집니다.\n\n서버리스 펑션 중 하나로 배포된 경우라면 그렇게 나쁘지 않을 가능성이 있습니다. 일부 공급자는 이러한 펑션을 \"엣지 서버\"에서 실행할 수 있습니다. 즉, 이러한 펑션은 여러 서버가 최종 사용자에게 더 가까이 분산되어 있습니다. 정적 리소스에 대한 CDN과 거의 동일합니다. 이 경우 지연 시간이 최소화되고 성능 저하가 최소화됩니다.\n\n하지만 자체 관리형 서버를 사용하면 분산 네트워크의 이점을 누릴 수 없습니다. 특정 지역에 배포해야 하기 때문입니다. 따라서 이 지역과 지구 반대편에 있는 사용자가 성능 저하의 영향을 실제로 느낄 수 있습니다.\n\n성능에 미치는 영향이 중요하다면 어떻게든 해결해야 합니다. 복잡한 캐싱 전략, 다른 지역으로의 배포 등을 준비해야 합니다. 기본적으로 더 이상 서버가 없는 단순한 프런트엔드 앱이 아닙니다. 이제는 풀스택 또는 백엔드 우선 앱입니다.\n\nVercel/Netlify의 Next.js\n\n바로 떠오를 수 있는 질문입니다. \"Next.js로 프런트엔드를 작성하고 Vercel/Netlify에 배포하기만 하면 됩니다. 이런 내용을 꼭 알아야 하나요?\"\n\n여기서 정답은 \"안타깝지만, 예, 피할 수 없습니다.\"입니다. 왜냐하면 Next.js 우선 호스팅 제공업체는 기본적으로 앱을 자바스크립트 파일과 여러 개의 작은 서버리스 펑션으로 변환하기 때문입니다. 사용자가 제어할 수도, 알지도 못하는 사이에 이런 일이 벌어집니다.\n\n따라서 Next.js 프로젝트를 '정적'으로 내보내도록 명시적으로 설정하지 않은 경우 '사전 렌더링의 서버 비용'은 모든 항목에 적용됩니다.\n\n도전 과제\n\nVercel/Netlify와 같은 서버리스 플랫폼에 \"기본적으로\" 배포(원클릭 배포)된 Next.js 앱이 있는 경우, 해당 앱을 위해 생성된 펑션이 몇 개인지 찾아보세요.\n\"엣지\" 펑션인가요, 아니면 일반 펑션인가요? 사용량이 어떻게 계산되는지 알 수 있나요? 한도를 초과하기 전에 웹사이트가 처리할 수 있는 방문자 수는 몇 명인가요?\n\"일반\" 펑션과 \"엣지\" 펑션의 조합이 있는 경우 어떤 펑션이 무엇을 담당하고 배포된 프로젝트에 어떤 영향을 미치는지 대응할 수 있나요?\n서버에서 전체 페이지 사전 렌더링(SSR)\n\n사전 렌더링에 대해 좀 더 이야기해 보겠습니다. 위 섹션에서는 기존 문자열을 다른 문자열로 대체하는 것이 쉽기 때문에 메타태그만 사전 렌더링했습니다. 하지만 <head> 태그를 넘어서면 어떻게 해야 할까요? 서버에서 전송되는 HTML 페이지의 <body> 태그의 내용을 살펴봅시다.\n\n<body>\n  <div id=\"root\"></div>\n  <script type=\"module\" src=\"./main.tsx\"></script>\n</body>\n\n클라이언트 사이드 렌더링이 어떻게 작동하는지 기억하시나요? 스크립트가 다운로드되고 처리되면 리액트는 \"root\" 요소를 가져와서 생성된 DOM 요소에 추가합니다. 그렇다면 빈 div 대신 일부 콘텐츠가 포함된 div를 반환하면 어떻게 될까요? 커다란 빨간색 블록으로 만들어 봅시다.\n\n<div id=\"root\">\n  <div style=\"background:red;width:100px;height:100px;\">Big Red Block</div>\n</div>\n\nindex.html에 추가하고 프로젝트를 빌드하고 난 다음 시작하고 더 잘 보이도록 캐시를 비활성화하고 CPU와 네트워크 속도를 낮추는 것을 잊지 마세요.\n\n페이지를 새로 고치면 큰 빨간색 블록이 잠시 깜박이다가 일반 대시보드 페이지로 바뀐 것을 볼 수 있을 것입니다. 첫 번째 좋은 소식은 빨간색 블록이 계속 남아 있지 않았다는 것입니다. 분명히 리액트는 내부에 무언가를 삽입하기 전에 “root” div를 지웁니다. 또는 기존 자식들을 재정의해도 이 글에서는 상관없습니다.\n\n두 번째 좋은 소식은 성능 그래프를 보면 알 수 있습니다. 지금 기록해 보세요. 결과는 다음과 같이 나옵니다.\n\n여기서 순서와 타이밍에 특히 주목해 주세요.\n\n처음에는 이전에 보았던 그래프와 똑같아 보입니다. 먼저 서버에서 HTML을 기다리면 'Main' 섹션에 파란색 HTML 파싱 블록이 나타납니다. 이 블록은 어느 시점에서 CSS와 자바스크립트('Network'의 노란색과 보라색 블록)의 다운로드를 트리거 했습니다.\n\n하지만 CSS 다운로드가 완료된 후 다른 일이 발생하기 시작했습니다. 먼저 보라색 Layout 블록(파란색 HTML 블록과 같은 수준)이 다소 길게 표시되었습니다. 전에는 이런 일이 없었는데요! 다운로드가 완료된 후 거의 즉시 FCP(First Contentful Paint)가 트리거 되었습니다. 하지만 상단의 자바스크립트 바는 여전히 로딩 중입니다! 그 후 자바스크립트 로딩이 완료되고, 처리되고, 페인팅 된 다음 LCP(Large Contentful Paint)가 트리거 되는 등 평소와 같은 상황이 계속됩니다.\n\n프레임 스크린숏이 표시되는 맨 위 섹션에 마우스를 가져가면 FCP와 LCP 사이의 간격이 페이지에 큰 빨간색 블록이 표시된 기간과 정확히 일치하는 것을 확인할 수 있습니다. 저에게 있어 FCP와 LCP 사이의 간격은 약 500밀리초이며, FCP는 약 800밀리초, LCP는 약 1.3초입니다.\n\n이 500ms는 초기 로드 시 클라이언트 사이드 렌더링 비용과 거의 비슷한 수준인 것 같습니다. 엄청나네요! LCP에서 500ms를 어떻게든 줄일 수 있다면 40%나 개선되는 것이죠! 이걸로 승진할 수도 있겠네요.\n\n다행히 모든 것이 가능합니다. 리액트는 전체 앱을 사전 렌더링 할 수 있는 몇 가지 메서드을 제공하며 이론적으로 여기에서 사용할 수 있습니다. 예를 들어, “renderToString”이 있습니다. 문서에 따르면 이 메서드는 앱을 문자열로 렌더링 할 수 있습니다.\n\nconst App = () => <div>React app</div>;\n\n// 어딘가의 서버\nconst html = renderToString(<App />); // 출력물: <div>React app</div>\n\n이미 서버에서 문자열을 다루고 있기 때문에 이것은 완벽해 보입니다. 제가 해야 할 일은 빈 “root” div를 이 함수의 출력물로 대체하는 것뿐입니다. 메타 태그에서 했던 것과 똑같습니다. 해볼까요?\n\nbackend/index.ts로 이동하여 위에서 수정한 내용을 정리합니다. 주석 처리된 코드를 찾습니다.\n\n// return c.html(preRenderApp(html));\n\n그리고 코멘트를 취소합니다. 퍼포먼스를 다시 녹화합니다. 최종 결과는 다음과 같아야 합니다.\n\nFCP와 LCP가 동시에 발생한 것을 보면 그 차이를 바로 확인해 볼 수 있습니다. 리액트로 생성된 메인 자바스크립트가 트리거 되기 전, 심지어 자바스크립트 로딩이 완료되기도 전에 말이죠. 이는 콘텐츠 사전 렌더링이 작동하고 있음을 의미합니다! 🎉 행복한 하루가 되었네요 ☀️☺️. 맨 위에 있는 스크린숏을 마우스로 가리키면 이는 무작위로 발생한 현상이 아니라 실제로 그 당시에 표시된 아름다운 대시보드가 맞는지 확인할 수 있습니다.\n\n그런데 작은 이상 현상이 있습니다. FCP가 약속한 것보다 늦게 트리거 된다는 것입니다. 800ms로 예상했지만 실제로는 900ms 정도입니다. 모든 성능에 대한 반복적인 교훈으로, 정확한 수치를 미리 약속하지 않는다는 것입니다. 😅. 그런데 어디서 100ms가 손실된 걸까요?\n\n먼저, 서버에 대한 초기 요청이 있는 왼쪽 맨 위 모서리인 \"Network\" 섹션을 살펴보세요. 파란색 실선이 보이시나요? 이것이 HTML 콘텐츠 다운로드입니다. 이제 단순한 빈 <div> 뿐만 아니라 더 많은 요소를 전송하고 있습니다. 정확한 수치를 보려면 해당 블록 위로 마우스를 가져가세요. 누락된 100ms 중 약 1/3이 콘텐츠 다운로드에 소요됩니다.\n\n또한 'Parse HTML' 작업 뒤에 있는 보라색 'Layout' 블록에 주목하세요. 훨씬 길어 보이지 않나요? 정확한 수치를 보려면 다시 마우스를 가져가 보세요. 여기 100ms 중 3분의 2가 사라졌습니다. 브라우저는 추가 HTML을 다운로드할 뿐만 아니라 더 많은 요소의 위치를 계산한 후 페인팅해야 했기 때문입니다.\n\n그래서 시간을 놓쳤습니다. 그래도 그만한 가치가 있지 않나요? LCP 타이밍에서 400ms를 단축하고 초기 로드 성능을 30% 개선했습니다! 그리고 또 다른 멋진 부분이 있습니다. 지금 자바스크립트를 비활성화하고 페이지를 새로고침해보세요. 대시보드가 그대로 표시됩니다! 전체 리로드를 유발하지만, 링크도 작동합니다.\n\n이 부분이 바로 SSR의 가치입니다. 이제 페이지에 액세스 권한을 부여하려는 모든 검색 엔진과 다른 모든 로봇이 자바스크립트를 로드하지 않고도 모든 것을 볼 수 있습니다. 성능 향상은 좋은 보너스입니다. 그리고 불안정한 보너스이기도 합니다.\n\nSSR의 초기 부하 악화의 가능성\n\n성능에 확실한 해결책이 없기 때문에 불안정합니다. SSR이 SPA 앱의 초기 부하를 100% 증가시킬 것이라고 말하는 사람은 잘못 알고 있는 것입니다. 이제 네트워크 상태, 클라이언트 사이드 및 서버 사이드 렌더링이 어떻게 작동하는지 알았으니, SSR이 LCP를 악화시키는 시나리오를 생각해 볼 수 있을까요?\n\n방법은 다음과 같습니다.\n\nCPU 쓰로틀링을 비활성화하고 컴퓨터를 다시 빠르게 만듭니다. 네트워킹을 가능한 가장 느린 시뮬레이션으로 설정합니다. 저에게는 기본 Chrome 3G가 적합했지만, 컴퓨터의 속도에 따라 더 느리게 설정해야 할 수도 있습니다. 'disabled cache' 체크박스를 선택을 취소합니다. CSS/JS 파일이 브라우저 메모리에서 제공되기를 원합니다.\n\n이제 사전 렌더링이 있는 경우와 없는 경우의 LCP를 측정합니다.\n\n결과는 다음과 같습니다. 사전 렌더링이 없는 'SPA' 모드에서는 LCP가 약 2.13초입니다. 사전 렌더링을 사용하면 “SSR” 모드에서는 약 2.62초입니다. 거의 500밀리 초나 더 길어졌습니다!\n\n성능 차트는 이 상황에서도 흥미롭게 읽을 수 있습니다. “SPA” 모드는 다음과 같습니다.\n\n처음에는 네트워크 섹션에서 서버의 응답을 기다리는 아주 긴 블록(2초)이 표시됩니다. 이는 느린 네트워크 연결로 인한 지연 시간입니다. 그다음에는 네트워크가 아닌 브라우저 캐시에서 자바스크립트 및 CSS 리소스에 거의 즉각적으로 액세스 할 수 있습니다. 또한 빈 div일 뿐인 HTML 콘텐츠도 거의 즉각적으로 다운로드됩니다. 그런 다음 CPU 속도가 느려지지 않기 때문에 자바스크립트 실행 속도가 평범하거나 매우 빠릅니다. 이것이 리액트가 페이지를 생성하는 과정입니다. 그리고 마지막으로 페이지가 표시됩니다.\n\n이제 SSR 모드가 활성화된 동일한 네트워크/CPU 조건입니다.\n\n동일하게 초기 대기 시간과 지연 시간이 사라지지 않았습니다. 그런 다음 HTML 다운로드가 시작됩니다. 하지만 지금은 콘텐츠가 많기 때문에 다운로드에 시간이 아주 오래 걸리고 대역폭이 매우 줄어듭니다.\n\n그리고 가장 흥미로운 부분은 콘텐츠가 다운로드되는 동안 메인 섹션에서 활동량이 급증하는 것을 볼 수 있다는 점입니다. 확대해서 마우스를 가져가면 대부분 레이아웃 작업입니다. 브라우저는 이미 (캐시에서) CSS와 자바스크립트를 다운로드한 상태이므로 작은 조각을 얻자마자 레이아웃을 그리는 데 필요한 모든 정보를 가지고 있습니다. 그리고 실제로도 그렇습니다.\n\n페이지에서 인터페이스가 점진적으로 구축되는 것을 실제로 볼 수 있습니다. 먼저 사이드바, 상단 탐색, 상단 차트, 표가 차례로 표시됩니다. 이 모든 것이 HTML이 천천히 표시되는 순서대로 진행됩니다. 이것이 멋지지 않다면 무엇이 멋진지 모르겠습니다.\n\n이 예는 이상한 엣지 케이스처럼 느껴지지만 실제로는 그렇지 않습니다. 예를 들어 느린 네트워크 + 엄청난 지연 시간 + 빠른 노트북의 조합은 비즈니스 여행객에게 자주 발생합니다. 또는 야생동물 사진작가. 또는 여행 블로거. 또는 원격지로 파견된 엔지니어도 마찬가지입니다. 따라서 앱이 주로 특정 틈새시장을 목표로하고 있고 이미 SPA인 경우 SSR을 도입하면 문제가 더 악화될 수 있습니다.\n\n물론 그렇지 않을 수도 있습니다. 이는 다운로드되는 HTML의 크기, 디바이스의 실제 속도, 앱이 렌더링해야 하는 자바스크립트의 양에 따라 달라집니다. 결국 모든 것은 고객을 파악하고 모든 것을 측정하는 두 가지로 귀결됩니다.\n\nSSR과 하이드레이션\n\n콘텐츠를 더 빨리 보여주는 것에 대한 흥분으로 콘텐츠가 로드된 후 어떤 일이 일어나는지 조사하는 것을 잊었습니다.\n\n큰 빨간색 블록의 동작을 기억하시나요? 리액트가 자체 요소를 로드하고 생성한 후에는 “root” div의 콘텐츠와 큰 빨간색 블록을 포함한 내부의 모든 것을 완전히 대체했습니다. 하지만 이상한 빨간색 블록 대신 향후 페이지의 실제 HTML을 보내면 어떻게 될까요?\n\n사실 아무 일도 일어나지 않습니다. 리액트에게 이 콘텐츠가 중요하다고 어떤 식으로든 말하지 않았기 때문에 “루트” div의 전체 콘텐츠를 지우고 그 자체로 대체하는 것과 똑같은 방식으로 작동합니다. HTML 관점에서 보면 완전히 동일한 콘텐츠이므로 육안으로는 차이가 보이지 않습니다.\n\n하지만 성능 프로필에서는 그 차이를 확인할 수 있습니다. CPU와 네트워크 속도를 낮춰 동작이 약간 더 잘 보이도록 하고 SSR 예제의 성능을 다시 기록합니다. CSS와 자바스크립트가 수신된 후 어떤 일이 일어나는지 주목해 주세요.\n\n왼쪽 상단에는 리소스 다운로드가 완료된 네트워크 섹션이 있습니다. CSS를 받은 직후 아래에 큰 보라색 'Layout' 섹션이 표시되는데, 바로 여기에 SSR이 적용된 콘텐츠가 표시됩니다. 왼쪽 상단의 자바스크립트 노란색 블록 로딩이 완료되면 리액트가 시작됩니다. 다소 긴 작업(180ms)은 리액트가 UI를 빌드 할 때입니다. 오른쪽 맨 아래에는 다시 작은 레이아웃 블록이 표시됩니다.\n\n이것은 우리가 이미 여러 번 보았던 클라이언트 사이드 렌더링의 전형적인 그림입니다. 리액트가 “root” div를 지우고 대신 생성하는 모든 것을 삽입하는 경우입니다. 그리고 이것은 완전히 불필요한 작업입니다. 리액트에는 이미 모든 DOM 요소가 존재하므로 대신 재사용할 수 있습니다. 당연히 더 빨라야 합니다.\n\n이때 “하이드레이션”이라는 것이 등장합니다. “하이드레이션\"은 위에서 제가 원했던 것과 정확히 일치하는 HTML이 페이지에 이미 있다는 것을 리액트에 보여줍니다. 따라서 리액트는 기존 DOM 노드를 재사용하고, 이벤트 리스너를 추가하고, 향후 기능을 위해 내부적으로 필요한 모든 것을 준비한 다음 하루를 마무리할 수 있습니다. 불필요한 컴포넌트를 처음부터 마운트 할 필요가 없습니다!\n\n리액트의 하이드레이션은 실제로 한 번의 함수 호출로 매우 간단하게 구현할 수 있습니다. createRoot 진입점을 이것으로 대체하기만 하면 됩니다.\n\nhydrateRoot(\n  document.getElementById(\"root\")!,\n  <StrictMode>\n    <App />\n  </StrictMode>\n);\n\n이 코드는 src/main.tsx에서 찾을 수 있습니다. createRoot 부분을 주석 처리하고 hydration 부분을 주석 처리 해제하세요. 그런 다음 프로젝트를 다시 빌드하고 다시 시작하세요.\n\nnpm run build\nnpm run start\n\n리액트 관련 자바스크립트 실행에 더 이상 보라색이 표시되지 않습니다. 그리고 이제 180ms에서 142ms로 약간 더 빨라졌습니다. 특히 이전에 LCP가 트리거 되었다는 점을 고려하면 지금은 그다지 크게 느껴지지 않을 수도 있습니다. 하지만 항상 이렇게 유지되는 것은 아닙니다.\n\n예를 들어 'disable network cache'을 선택 해제하고 CPU를 낮추면서 네트워크 스로틀링을 제거해 보세요. 인터넷 속도는 빠르지만, 디바이스가 느린 재방문자를 가상화합니다. 하이드레이션이 없으면 FCP와 LCP가 분리되고 LCP가 자바스크립트 작업의 맨 끝으로 밀려납니다. 이 경우 LCP는 약 550ms입니다. 하이드레이션을 활성화하면 LCP는 FCP에 더 가깝게 이동하여 자바스크립트 작업이 시작될 때 약 280ms를 유지합니다.\n\n메인 스레드를 차단하고 최대한 줄이는 문제도 있는데, 하이드레이션이 이를 도와줍니다. 또한 하이드레이션은 자바스크립트 리스너에만 국한된 것이 아닙니다. 또한 일부 초기 데이터를 가져와 앱에 주입할 수 있으므로 스피너나 콘텐츠의 플래시를 로딩하는 것을 방지할 수 있습니다. 이에 대해서는 나중에 다른 글에서 다룰 예정입니다.\n\n이렇게 SSR을 구현해야 하나요?\n\n이제 SSR이 특정 사례에 매우 유용할 수 있고 구현하는 것이 다소 사소해 보이기 때문에, 스터디 프로젝트의 코드를 사용하여 나만의 SSR을 구현할 수 있느냐는 질문이 생길 수 있습니다.\n\n이 블로그의 대답은 매우 드물게도 '절대 안 된다'입니다! 이 해결법은 한 가지를 켜고 끄면서 사전 렌더링 된 콘텐츠가 다양한 관점에서 어떻게 작동하는지 살펴보는 스터디 목적으로는 괜찮습니다.\n\n하지만 실제로는 전혀 사소한 일이 아닙니다. 저는 제대로 작동하기 위해 해야 할 일의 절반을 숨기고 절반은 아직 구현되지 않았습니다. 백엔드에서 최신 리액트 기능을 지원하지 않은 매우 기본적이고 거의 사용되지 않은 버전입니다.\n\n우선, 여기에는 개발 서버에 대한 SSR이 없습니다. 따라서 프로젝트를 지속적으로 다시 빌드하는 것 외에는 SSR을 디버깅할 방법이 없습니다. 변경 사항을 적용하기 위해 항상 다시 빌드해야 하는 이유의 절반은 바로 이 때문입니다. (나머지 절반은 항상 프로덕션 빌드에서 성능을 측정해야 해서 특별히 죄책감을 느끼지 않습니다).\n\n핫 리로드와 같은 멋진 기능을 원한다면 직접 구현해야 합니다. SSR을 Vite와 올바르게 통합하는 방법에 대한 전체 지침이 있습니다. 웹팩의 경우 매우 다르며 문서화가 잘 되어 있지 않을 가능성이 높습니다. 더 색다른 것을 위해 어디서부터 시작해야 할지 모르겠습니다.\n\n둘째, 리액트 문서에서 보여드린 예쁘게 생긴 문자열인 const html = renderToString(<App />); 은 실제로는 작동하지 않습니다. 여기서 문제는 이 부분, 즉 <App />입니다. 이건 JSX이고, 우리가 대부분 리액트 코드를 작성하는 방식이기 때문에 지금은 매우 정상적으로 보입니다. 하지만 JSX가 작동하는 유일한 이유는 빌드 시스템에 Babel에 의해 구동되는 변환 단계가 있기 때문입니다(또는 아닐 수도 있고, 항상 달라질 수 있습니다). “순수” 노드나 다른 서버 프레임워크는 이를 지원하지 않습니다.\n\n실제로 어떻게 구현되는지 backend/pre-render.ts를 살펴보세요.\n\n먼저 Vite 자체에서 변환된 App 코드를 추출했습니다:\n\nconst { default: App } = await vite.ssrLoadModule(\"@/App\");\n\n웹팩을 사용하는 경우 수동으로 Babel 플러그인을 구성하고 등록해야 할 가능성이 높습니다. 따라서 첫 번째 단계부터라도 여기서 무슨 일이 일어나고 있는지, 앱이 어떻게 구현해야 하는지 이해해야 합니다.\n\n두 번째 단계는 실제 renderToString입니다.\n\nconst reactHtml = renderToString(React.createElement(App, { ssrPath: path }));\n\n여전히 문서와 달리 실제 백엔드 파일에 대한 JSX 지원은 Vite에서 추출하는 것과는 다릅니다. 하지만 문서를 읽어보면 renderToString이 데이터 스트리밍 및 대기를 지원하지 않는다는 것을 알 수 있습니다.\n\n따라서 실제로 적절한 SSR을 구현하려면 앱에 이러한 새로운 기능이 필요한지 여부를 이해해야 합니다. 그리고 필요하다면 백엔드에서 구현하는 방법을 파악해야 합니다. 권장 방법에 대한 몇 가지 문서가 있고 깃허브에 해당 주제에 대한 토론에 대한 스레드도 몇 개 있으므로 최소한 시작은 할 수 있습니다.\n\n그러나 많은 작업이 필요하고 언급된 내용은 시작에 불과하며, 어느새 프로젝트가 3개월이나 늦어져 기본적으로 자신만의 Next.js를 구현하고 있습니다. 왜 경쟁자가 그렇게 많지 않다고 생각하시나요?\n\n그래서 매우 타당한 비즈니스 이유가 있고 시간, 리소스 및 전문성 측면에서 많은 지원이 없다면 이미 존재하는 SSR 프레임워크를 사용하는 것이 더 쉬울 수 있습니다. 특히 백엔드 부분은 퍼즐의 한 조각에 불과하다는 점을 고려하면 더욱 그렇습니다. 또한 프런트엔드에는 많은 복잡성이 수반됩니다.\n\nSSR과 프런트엔드\n\n앱의 크기와 SSR에 최적화된 정도에 따라 실제로는 백엔드 부분보다 훨씬 더 복잡할 수 있습니다. 그래요, 위에서 SSR을 구현하면서 숨겼던 또 하나의 사실은 프런트엔드 코드도 변경해야 한다는 점입니다.\n\n브라우저 API와 SSR\n\n브라우저로 전송되는 HTML을 어떻게 얻었는지 기억하시나요? 리액트의 renderToString으로 문자열을 생성한 다음 그 문자열을 다른 문자열에 주입했습니다. 이 과정 근처에는 브라우저가 없었고 앞으로도 없을 것입니다.\n\n그렇다면 프런트엔드에서 사용하던 브라우저 변수에 대한 모든 호출은 어떻게 될까요? window.location, window.history, document.getElementById? window, document 등이 undefined 상태로 바뀔 것입니다. 전역 범위로 주입할 수 있는 브라우저가 없기 때문입니다.\n\n따라서 리액트가 이들에 직접 접근하는 함수를 호출(즉, 컴포넌트를 렌더링)하려고 하면 window is not defined 오류와 함께 실패합니다. 앱 전체가 폭발할 것입니다. 단순히 폭발하는 것이 아닙니다. 서버 부분이 폭발할 것이고, 더 심각한 것은 프런트엔드 부분에서 오류를 포착하여 “작업 중입니다, 여기 쿠키가 있습니다”라는 예쁜 화면을 표시할 기회가 전혀 없다는 것입니다. 오류 처리는 서버에서 처리해야 하며, 특별한 '서버' 오류 화면이 있어야 합니다.\n\n도전 과제\n\n프런트엔드 코드의 임의의 부분(예: src/App.tsx)에 간단한 console.info(window.location);을 추가해 보세요.\nnpm run build를 사용하여 앱을 다시 빌드하고 다시 시작합니다.\n화면에 Internal Server Error 문자열이 표시되어야 합니다.\n이 문제를 해결할 방법이 있나요?\n\n이 문제를 해결하는 일반적인 방법은 window(및 다른 모든 변수)에 액세스 하기 전에 전역 변수가 선언되었는지 확인하는 것입니다:\n\nif (typeof window !== \"undefined\") {\n  // global window API를 사용할 수 있을 때 무언가를 수행합니다.\n}\n\nfrontend/utils/use-client-router.tsx의 코드를 보면 바로 이것이 제가 해야 했던 일입니다. 그리고 런타임에 window, document 또는 다른 모든 것에 액세스해야 할 때마다 이 작업을 수행해야 합니다.\n\nuseEffect와 SSR\n\n자세히 보면 useEffect 내부에서 typeof window를 확인할 필요가 없다는 것을 use-client-router파일을 보면 알 수 있습니다.\n\nuseEffect(() => {\n  const handlePopState = () => {\n    setPath(window.location.pathname);\n  };\n  window.addEventListener(\"popstate\", handlePopState);\n  return () => window.removeEventListener(\"popstate\", handlePopState);\n}, []);\n\n서버에서 실행할 때(즉, renderToString과 친구를 통해) 리액트는 useEffect를 트리거하지 않기 때문입니다. 그리고 useLayoutEffect도 마찬가지입니다. 이러한 훅은 하이드레이션이 발생한 후에 클라이언트에서만 실행됩니다. 이 동작의 이유에 대해 더 자세히 알고 싶다면 이 짧은 설명과 핵심 리액트 팀원들의 이 주제에 대한 긴 토론을 살펴보세요.\n\n자바스크립트가 로드될 때 콘텐츠의 \"깜빡임\"이 발생하므로 useEffect의 결과로 UI 변경이 예상되는 경우 반드시 염두에 두어야 할 사항입니다.\n\n조건부 SSR 렌더링 불가\n\n코드의 일부에는 브라우저 API에 대한 종속성이 너무 많아서 SSR 모드에서는 해당 부분의 렌더링을 완전히 건너뛰는 것이 더 쉽다고 생각할 수 있습니다. 따라서 자연스럽게 이렇게 하고 싶은 유혹이 생길 수 있습니다.\n\nconst Component = () => {\n  // SSR 모드에서는 아무것도 렌더링하지 않습니다.\n  if (typeof window === \"undefined\") return null;\n\n  // 클라이언트 모드가 시작될 때 렌더링합니다.\n  return ...\n}\n\n아니요. 이건 작동하지 않습니다. 아니, 더 정확하게는 작동할 것입니다. 리액트는 “서버” 코드에서 생성된 HTML이 클라이언트 코드에서 생성된 HTML과 완전히 동일하다고 기대할 것입니다.\n\n너무 혼란스러워졌는데 클라이언트 사이드 렌더링 패턴으로 돌아가서 “root” div의 전체 콘텐츠를 지우고 새로 생성된 요소로 대체할 것입니다. 하이드레이션이 전혀 일어나지 않은 것처럼 작동하며 이에 따라 발생하는 모든 단점이 있습니다.\n\n이 도전 과제를 시도해 보세요.\n\nfrontend/pages/dashboard.tsx의 어딘가에(또는 원하는 다른 위치에) 코드를 사용하여 ClientOnlyButton 컴포넌트를 만듭니다.\nconst ClientOnlyButton = () => {\n  if (typeof window === \"undefined\") return null;\n  return <button>Button</button>;\n};\n페이지의 어딘가에 렌더링 합니다.\n평소처럼 프로젝트를 다시 빌드하고 다시 시작합니다.\n성능 프로필을 기록합니다. 하이드레이션이 아직 구현되지 않았을 때 보았던 그림이 리액트 자바스크립트 태스크 내부의 레이아웃 블록과 함께 표시되어야 합니다.\n\n사라진 하이드레이션 - 운이 좋다면! 때로는 정말 이상한 레이아웃 버그가 발생하여 웹사이트가 완전히 망가져 보일 수 있습니다.\n\n올바른 방법은 리액트의 라이프사이클에 의존하여 SSR과 호환되지 않은 블록을 “숨김”하는 것입니다. 이를 위해서는 상태를 도입하고 컴포넌트가 마운트되었는지 여부를 추적해야 합니다.\n\nconst Component = () => {\n  // 초기에는 마운트 되지 않습니다.\n  const [isMounted, setIsMounted] = useState(false);\n};\n\n그런 다음 컴포넌트가 마운트되었을 때, 즉 useEffect 내부에서 이 상태를 true로 뒤집습니다.\n\nconst Component = () => {\n  // 초기에는 마운트 되지 않습니다.\n  const [isMounted, setIsMounted] = useState(false);\n\n  useEffect(() => {\n    setIsMounted(true);\n  }, []);\n};\n\n기억하세요. useEffect는 서버에서 실행되지 않으므로 웹사이트의 클라이언트 사이드 버전이 리액트에 의해 완전히 초기화될 때만 상태가 true로 바뀝니다.\n\n마지막으로, SSR과 호환되지 않은 렌더링을 하고자 합니다.\n\nconst Component = () => {\n  // 초기에는 마운트 되지 않습니다.\n  const [isMounted, setIsMounted] = useState(false);\n\n  useEffect(() => {\n    setIsMounted(true);\n  }, []);\n\n  // SSR 모드에서는 아무것도 렌더링 하지 않습니다.\n  if (!isMounted) return null;\n\n  // 클라이언트 모드가 시작될 때 렌더링 합니다.\n  return ...\n}\n\n도전 과제\n\n이전 예제의 ClientOnlyButton을 다시 작성하여 SSR에서 올바르게 작동하도록 합니다.\n평소처럼 프로젝트를 다시 빌드하고 다시 시작합니다.\n성능 프로필을 기록합니다. SSR 빨간색 모양으로 되돌아갑니다.\n서드파티 라이브러리\n\n모든 외부 종속성이 SSR을 지원하는 것은 아닙니다. 라이브러리는 항상 도박과도 같습니다. 일부 라이브러리의 경우 위의 해결법을 사용하여 SSR을 거부할 수 있습니다. 일부는 번들러에 의해 거부되므로 클라이언트 사이드 자바스크립트가 로드된 후 동적으로 가져와야 합니다. 그중 일부는 프로젝트에서 제거하고 더 SSR 친화적인 라이브러리로 대체해야 합니다.\n\nSSR과 호환되지 않은 라이브러리가 전체 프로젝트의 기본 요소인 경우 특히 문제가 될 수 있습니다. 상태 관리 해결법이나 CSS-in-JS 해결법처럼 말입니다.\n\n예를 들어, 스터디 프로젝트의 어딘가에서 Material UI 아이콘을 사용해 봅시다.\n\n// 어딘가 예제에 있는 src/App.tsx\nimport { Star } from \"@mui/icons-material\";\n\nfunction App() {\n  // 나머지 코드는 같습니다.\n  return (\n    <>\n      ...\n      <Star />\n    </>\n  );\n}\n\n다시 빌드하고 시작하면 SSR이 함께 무너진 것을 볼 수 있습니다.\n\n[vite] (ssr) Error when evaluating SSR module @/App: deepmerge is not a function\n\n해결 방법을 재미있게 찾아보세요 😬\n\n정적 사이트 생성(SSG)\n\n서버에서 “적절히” 렌더링 되는 페이지가 반드시 필요하고 이를 위해 프런트엔드에서 발생하는 결과를 처리할 준비가 되어 있다고 가정해 봅시다. 예를 들어 멋진 “프로모션” 웹사이트를 구현하고 있다고 가정해 봅시다. 모든 검색 엔진에서 가능한 한 빨리 색인화되어야 하며 링크를 공유할 수 있는 모든 곳에서 공유할 수 있어야 합니다. 이것이 바로 이런 웹사이트의 핵심입니다.\n\n또한 웹사이트의 모든 정보가 “정적”, 즉 사용자가 생성한 콘텐츠가 없고, 고려해야 할 권한이 없으며, 요청당 복잡한 데이터가 생성되지 않는다고 가정해 봅시다. 웹사이트는 제품을 소개하는 몇 개의 페이지와 '이용 약관'과 같은 몇 가지 표준 페이지, 일주일에 한 번 업데이트되는 블로그만 있다고 가정합니다.\n\n이 상황은 케이크도 먹고 떡도 먹을 수 있는 드문 사용 사례입니다. 우리는 이미 서버에서 웹사이트를 사전 렌더링하는 것이 비교적 쉽다는 것을 알고 있습니다. 앱에서 React.renderToString을 호출하기만 하면 됩니다(어느 정도).\n\n그렇다면 여기서 중요한 질문은 빌드 시간 동안, 즉 npm run build를 실행한 직후에 React.renderToString을 실행하지 못하게 하는 이유는 무엇일까요? 이론적으로 어쨌든 적절한 HTML 페이지를 사전 렌더링하여 브라우저에 전송하고 있습니다. 그리고 사전 렌더링 된 콘텐츠는 항상 동일합니다. 예전처럼 사전 렌더링해서 실제 HTML 파일로 저장하면 “적절한” 서버를 보유하는 수고를 덜 수 있을 것입니다. 그렇죠?\n\n정답은, 그렇게 하는 것을 막을 방법이 전혀 없다는 것입니다. 이걸 실행해 보세요.\n\nnpm run build:ssg\n\n\n먼저 Vite를 사용하여 일반적인 방식으로 웹 사이트를 구축한 다음, 빈 <div id=“root”></div>를 renderToString으로 생성된 콘텐츠로 대체하는 매우 근본적인 스크립트(backend/generate-static-pages.ts)를 실행합니다. 서버가 하는 일과 정확히 일치합니다. 이제 더 이상 서버가 필요하지 않습니다.\n\ndist 폴더에서 빌드 된 파일을 살펴보세요. 이제 login.html과 settings.html이라는 추가된 두 개의 파일이 보입니다. HTML 파일을 열면 <div id=“root”>가 콘텐츠로 채워져 있는 것을 볼 수 있습니다.\n\n이것은 모든 웹서버에서 시작할 수 있는 “정적” 웹사이트입니다.\n\nnpx serve dist\n\n또는 다른 클라이언트 사이드 렌더링 앱과 마찬가지로 거의 모든 곳에 업로드 할 수 있습니다. 이번에는 CSR의 단점이 없고, 모든 검색 엔진이 즉시 제대로 색인을 생성할 수 있으며, 소셜 미디어 공유가 원활하게 작동합니다.\n\n정적 웹사이트는 세 글자로 된 자체 약어까지 있을 정도로 훌륭한 기능입니다(SSG(정적 사이트 생성)). 물론 수작업이 필요 없이 자동으로 생성해 주는 프레임워크가 많이 있습니다. Next.js는 SSG를 지원하고, Gatsby는 여전히 인기가 많고, 많은 사람들이 Docusaurus를 좋아하고, Astro는 최고의 성능을 약속하며, 그 외에도 많은 프레임워크가 있습니다.\n\nSSR에 대해 아직 할 말이 많지만, 여기 소개한 개념은 기초를 다지기 위한 것일 뿐입니다. 하지만, 이 글이 도움이 되었기를 바라며 다음에 다음 웹사이트를 만들 때 SSR로 시작할지 말지 결정해야 할 때 좀 더 자신감을 가질 수 있기를 바랍니다.\n\nTapK\n누구나 읽기 편한 글을 위해\n팔로우\n이전 포스트\n(번역) 모노레포 인사이트: Nx, Turborepo 그리고 PNPM (4/4 - pnpm 중점적인)\n2개의 댓글\n댓글 작성\n윤성현\n3일 전\n\n이전글 번역본도 있을까요?\n\n1개의 답글\n관련 채용 정보\n메이크스타\nSoftware Engineer\nK-Culture 플랫폼 메이크스타에서 당신의 개발 역량을 발휘해보세요. Vue.js와 Flutter 등을 활용한 글로벌 서비스 개발로 빠르게 성장하는 엔터 스타트업의 주인공이 되어보세요!\n미리디\n[미리캔버스] 프론트엔드 개발자\n미리캔버스는 디자인 생태계를 혁신하는 올인원 플랫폼으로, 1,400만 고객을 위해 프론트엔드 개발을 통해 사용자 경험을 최적화하고 있습니다. React와 Next.js를 활용해 확장 가능한 구조를 설계하며, 빠르게 변화하는 환경에서도 뛰어난 성능을 제공하는 팀의 일원이 되어보세요!\n스터닝\n프론트엔드 개발자(신입)\n프론트엔드 개발자로서 국내 최대 크리에이티브 플랫폼 스터닝에서 UX/UI 협업 및 웹 서비스 개발을 통해 창작자의 가치를 실현하는 데 기여해보세요. React, Typescript, Next.js와 같은 기술을 활용하며 유연한 근무 환경에서 업무에 몰입할 수 있습니다.",
    "tags": [
      "React",
      "SSR"
    ],
    "commentCount": "2"
  },
  {
    "title": "메일의 혁명 \"노션 메일\"",
    "description": "노션은 혁명이고 사랑입니다",
    "link": "https://velog.io/@zerone001/notion-mail",
    "author": "장인정신",
    "date": "2025년 4월 1일",
    "comments": "7개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/zerone001/post/af9b2077-0e01-4c54-bb0a-355089afa643/image.png",
    "content": "장인정신\n로그인\n장인정신\n로그인\n메일의 혁명 \"노션 메일\"\n정현·2025년 4월 1일\n팔로우\n49\n노션노션 메일\n노션 메일\n\n현재 노션에서 개발중인 또 하나의 노션 플랫폼이다\n개발 단계라 대기자 명단에 등록만 할 수 있어서 등록했었다\n그러던 어느날 등록한 사람만 쓸 수 있게 해주는 건지는 모르겠지만 최근에 노션 하단에 노션 메일을 사용할 수 있는 버튼을 발견해서 사용해보았다\n\n대기자 명단 등록 링크 : https://www.notion.com/ko/product/mail\n\n사실 벨로그를 쓸 생각이 없었는데 막상 자료가 많이 없는 것 같아서 1시간 정도 독학?한걸 바탕으로 유용한 기능들을 알려주겠다\n\n\n\n\n\n구경해보자\n\n일단 노션 메일은 이렇게 생겼다\n메일 화면 같으면서도 노션스러움이 있는 깔끔한 UI인 것 같다\n그리고 못 찾은건지는 모르겠지만 베타테스트라 언어 변경이 안 되는 것 같았다\n\n\n메일을 확인하려고 누르면 노션에서 작은 페이지 열리듯이 오른쪽 절반만큼 화면을 차지하여 열린다\n\n이제 제대로 뭐가 다른지 하나씩 살펴보자\n\n\n\n마크다운\n\n\n노션답게 마크다운을 지원한다\n기존처럼 /를 누르면 이렇게 기능을 쓸 수 있는 것을 볼 수 있다\n\n제목, 번호 매기기, 인용, 투두 리스트,색상 변경, 심지어는 코드도 노션처럼 붙일 수 있다\n\n음 마크다운, 코드는 유용하게 사용될 수 있을 것 같다!\n더 깔끔한 메일을 보내는데 큰 도움이 될 것 같다\n\n\n전송은 당연하게도? 예약 전송도 가능하다\n\n숏컷\n\n개인적인 생각으로 이거 좀 괜찮은 것 같다\n\n\n바로 숏컷 기능이다\n\n\n이렇게 숏컷 이름과 내용을 입력하고 저장하면 앞으로 메일을 작성할때\n/숏컷 이름\n작성하면 바로바로 내용이 나온다\n반복되는 내용이나 자주 쓰는 내용, 코드를 저장해두고 쓰면 유용할 것 같다\n\n\n그리고 여기서는 {뭐시기뭐시기}를 넣을 수 있는데\n실제로 사용할때 넣고 {} 누르면 입력하여 저 자리에 이름 같은걸 집어 넣을 수 있다\n\n개인적인 생각으로는 수동으로 말고 저거 입력해두면 자동으로 받는 사람의 이름을 들고와주면 좋겠는데 받는 사람 이름이 항상 이름이 아닌 경우가 있어서 그냥 사용자가 입력하게 두는 것도 나쁘지 않은 것 같다\n\n추가 테스트 결과 자동으로 입력된다\n라벨링\n\n노션처럼 라벨링을 해둘 수 있다\n\n\n저기 옆에 보면 velog 태그로 라벨링 되어있는 것을 볼 수 있다\n이건 수동으로 넣을 수도 있고, AI가 자동으로 넣게 만들 수도 있다\n\n\n\n라벨 이름을 넣으면 자동으로 레벨링 해주는건데\n내가 잘 못 쓰는건지 아니면 원래 그런건지 라벨링은 잘 해주는데 모든 메일을 다 라벨링 해주는게 아니라 그냥 일부분(3~4개)만 해주는 것 같아서 AI 라벨링은 잘 못 쓰겠다\n\n개인적인 생각으로 라벨링은 그냥 사용자가 직접 '해야하는 일', '나중에 다시 읽어보기' 같은거로 수동으로 해두는게 더 나을 것 같다\n\n왜냐하면 뒤에 나올 기능이 사실 라벨링보다 더 좋다고 생각하기 때문이다\n그리고 사실 gmail도 비슷한 라벨 기능을 제공하기 때문에 엄청 큰 유용함은 아니라고 생각한다\n\n메일을 노션 페이지처럼 VIEW\n\n\n노션 메일은 이렇게 View 라는 기능으로 일종의 메일 페이지를 생성할 수 있다\n나는 그냥 이게 메인 기능이라고 본다\n\n이것 역시 템플릿이 있지만 그냥 configure manually가 더 편한 것 같다\nconfigure manually를 누르고 이름만 지정하면 하나의 view가 생성된다\n\n\n각 view마다 여러 조건을 걸어둘 수 있다\n읽기 여부, 첨부 파일 여부, 캘린더 이벤트, 라벨, 다중 선택, 보낸 사람, 받은 사람, 제목, 날짜 등\n여러 조건을 중첩으로도 걸어둘 수 있다\n\n그렇게 중첩을 걸어두면 이제 앞으로 그 view는 그 조건을 충족하는 메일만 보여주는 view가 되는거다\n\n어떻게 써야 할지 잘 모르겠다면 일단 나는 이렇게 만들어보았다\n\n\n벨로그, 엣코더,채용공고 알림 / 안 읽은거 모음 / 첨부파일 여부 / 특정 보낸 이메일 / 년도 별로\n\n이렇게 정리해두니 진짜 노션처럼 깔끔해지는 것 같은 기분이 든다\n나는 사실 gmail만 썼어서 다른 메일에 있었는지는 모르겠지만 일단 마음에 든다\n\n상태 관리\n\n노션에서 데이터 베이스를 써본 사람이라면 상태가 뭔지 알것이다\n완료, 진행중, 진행전과 같은 상태를 토글 형태로 관리할 수 있었다\n비슷한게 메일에도 있다\n\n\n일단 어떻게 만드는건지는 모르겠지만 템플릿에 있다\n여러 예시가 있었지만 이게 가장 괜찮은 것 같다\n\n\n이렇게 노상태, 중요, 할일, 기다리는 중 같은 상태를 지정할 수 있고, 지정하면 자동으로 위에 화면처럼 분리된다\n\n또한 저렇게 상태를 다른 페이지(View)로 분해하여 볼 수도 있다\n\n그 외\n\n내가 소개한 기능 외에도 다양한 기능들이 더 있다\n카테고리(소셜, 업데이트, 프로모션)으로 구분해서 보는 View, AI에게 맡기는 메일 자동화, 호버 액션, 스팸 처리, 전체 라벨(다중 선택) 처리, 등\n\n그리고 무엇보다 나는 노션 캘린더와 연동을 하여 사용해보고 싶은데\n\n\n커넥트를 눌러도 노션 캘린더 화면으로 넘어가기만 하고 아무런 일도 발생하지 않으며, 노션 캘린더 안에서 노션 메일 연동 같은걸 찾아봐도 찾을 수 없었다\n\n그래서 내가 못 찾았을 가능성도 있지만 아직 미지원 기능일 가능성도 있어보였다\n노션 캘릭더까지 연동되면 정말 노션 생태계는 한 단계 넓어질 것 같다!\n\n\n\n\n\n마무리\n\n음 솔직히 노션이 아무리 대단해도 나는 메일 서비스는 크게 유용할 것 같지 않다고 생각했다\n노션은 항상 쉬움을 추구하기보다 살짝 어렵더라도 편리함, 예쁨을 주기 때문에 존재한다고 생각한다(메모장 -> 노션)\n\n그런데 메일은 정말 메일 보낼때 말고는 크게 쓸 일이 없는 것 같아서 아직 안 써본 입장에서는 정말 유용할지 잘 모르겠긴하다\n\n그래도 딱 봤을때 나쁘지 않은 것 같아서 앞으로 1주 ~ 2주정도 사용해보며 노션 메일에 대해 더 알아볼 예정이다\n그리고 2025년 정식 출시할때까지 열심히 써보고 싶다\n그리고 무엇보다\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUI가 깔끔하고 예쁘잖습니까?\n이거 하나로 쓸 이유는 끝났다고 봅니다\n\n\n\n\n이상 글 읽어주셔서 감사합니다!\n\n정현\n노력으로 재능을 이길 수 없다면, 노력으로 재능을 만드는 개발자 서정현입니다\n팔로우\n이전 포스트\n마크다운과 JSX를 합친다면?\n7개의 댓글\n댓글 작성\nNoah\n2025년 4월 4일\n\n감사합니다 ☺️\n\n1개의 답글\noed\n약 6시간 전\n\nView 기능 너무 유용할 것 같아요. 소개 감사합니다~!\n\n1개의 답글\n관련 채용 정보\n넥스트그라운드\n[인턴] 백엔드 개발자\n넥스트그라운드는 부동산 시장의 정보 비대칭을 해소하는 '집품' 서비스를 운영하며, 빠르게 성장하는 개발 팀에서 백엔드 전문가를 찾습니다. JAVA와 Spring을 활용한 API 설계 및 성능 최적화 업무를 통해 함께 성장할 기회를 제공합니다.\n채널코퍼레이션\n[채널톡] Software Engineer\n채널톡은 아시아에서 가장 빠르게 성장하는 B2B SaaS 회사로, '올인원 AI 메신저'를 통해 고객 소통을 혁신하고 있습니다. 다양한 기술 스택을 활용해 글로벌 시장의 복잡한 문제를 해결할 수 있는 엔지니어를 기다립니다.\n리브애니웨어\n백엔드 엔지니어(2년~5년)\n리브애니웨어는 한달살기에 최적화된 숙소 추천 서비스를 제공하며, 백엔드 개발자로서 서비스의 API 구현 및 유지보수에 참여할 수 있습니다. Java, Spring Boot 등을 활용한 개발 경험을 활용해 고객 중심의 혁신적인 서비스에 기여해 보세요!",
    "tags": [
      "노션",
      "노션 메일"
    ],
    "commentCount": "7"
  },
  {
    "title": "사내 서비스 수익화 구글 애드센스 제대로 런칭하기 🚀",
    "description": "\"이거 그냥 코드만 제대로 붙이면 빨리 될 것 같은데요?\" 라는 말로 만만하게 시작한 구글 애드센스가  별별 이슈를 다 만나 안정적인 런칭을 향해 헤쳐나아갔던 그 과정을 공유합니다 !",
    "link": "https://velog.io/@osohyun0224/%EC%82%AC%EB%82%B4-%EC%84%9C%EB%B9%84%EC%8A%A4-%EC%88%98%EC%9D%B5%ED%99%94-%EB%8F%84%EC%A0%84%EA%B8%B0-%EA%B5%AC%EA%B8%80-%EC%95%A0%EB%93%9C%EC%84%BC%EC%8A%A4-%EC%A0%9C%EB%8C%80%EB%A1%9C-%EB%9F%B0%EC%B9%AD%ED%95%98%EA%B8%B0",
    "author": "<SohyunO />",
    "date": "2025년 4월 6일",
    "comments": "5개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/osohyun0224/post/0f9ad29a-c811-4ddc-aad0-7a81ae474bc9/image.png",
    "content": "<SohyunO />\n로그인\n<SohyunO />\n로그인\n사내 서비스 수익화 구글 애드센스 제대로 런칭하기 🚀\nosohyun0224·2025년 4월 6일\n팔로우\n33\nGoogle Adsense구글 애드센스\n구글 애드센스\n목록 보기\n1/1\n\n참고로 Nextjs, React 환경에서의 구글 애드센스를 런칭한 회고가 담겨있습니다\n\n안녕하세요 :) 프론트엔드 개발자 Garden, 오소현입니다 !\n\n최근 회사 서비스에 유저들이 가장 많이 이용하는 기능부터 차례로 구글 애드센스 광고를 게시하고 있는데요!\n\n처음에는 회사 마케터와 함께 \"이거 그냥 코드만 제대로 붙이면 빨리 될 것 같은데요?\" 라는 말로 만만하게 시작했다가 ... 별별 이슈를 다 만나 안정적인 런칭을 향해 헤쳐나아갔던 그 과정을 공유합니다 !\n\n구글 애드센스로 현재 웹 서비스에 광고를 부착하고 계시거나, 계획이 있으신 분들은 꼭꼭 읽어보시길 추천합니다 :) 구글 애드센스 초기 설정 부터 ~ 개발 이슈까지 모든 내용을 정리했습니다!\n\n시작하기에 앞서 런칭하기 까지 희노애락을 함께해준 저희 회사 마케터 Ella에게 감사드려요 😎😎\n\n이슈만을 읽고 싶은 개발자 분들은 4) 본격적인 개발 이슈들 💻 을 바로가기 해주세요!\n\nIntro.\n🤔 구글 애드센스 광고란?\n\n흔하게 티스토리나, 다른 사이트에서 쉽게 볼 수 있는 구글 광고입니다 :)\n아래의 사진 처럼 콘텐츠 사이사이 내 삽입되는 광고나, 화면을 아예 막고 노출하는 오버레이 광고 등등 다양한 형태로 광고 노출이 되고, 광고주(삽입자)들은 유저들의 화면 노출 시간 + 광고 클릭수에 따라서 돈으로 들어오는 형태로 이루어져 있어요!\n\n\n\n\n개발자들은 흔히 자신의 웹사이트에 광고를 삽입하여 수익화를 진행하기도 하는데, 이 중에서 가장 많이 사용되는게 바로 오늘의 구글 애드센스 인데요,\n\nGoogle 애드센스는 한마디로 개발자가 타겟팅된 Google 광고를 자신의 사이트에 게재하여 수익을 얻는 무료 프로그램입니다 😎\n\n구글 애드센스를 사용하는 이유는 게시자가 Google 애드센스를 사용하는 이유 구글 공식 문서를 통해 확인해주세요!\n\n1) 사이트 등록하기\n\n제가 사이트에 광고를 노출시키기 위해서 가장 먼저 해야할일은 Adsense에 회사 서비스를 등록해야했습니다.\n\n먼저 Google Adsense에 가입을 진행해주시면 됩니다 내 사이트가 없어도 계정 가입이 가능하니 아래와 같이 계정을 등록해주세요\n\n다음은 광고를 노출할 사이트를 추가해줍니다 (실제로는 저희 회사 웹 사이트를 등록했습니다)\n\n\n사이트를 정상적으로 등록하면 구글 애드센스에서 제가 등록한 사이트를 광고하기에 적합한지 검토하는 과정이 필요한데요, 이를 구글 애드센스 심사라고 하겠습니다.\n\n심사 기간은 최대 2주 정도가 소요되고, 사이트의 콘텐츠가 제대로 적합하지 않으면 승인이 거절될 수 있어요, 여기서 가장 중요한 점은 설정된 페이지가 주기적으로 조회되지 않으면(사이트 화면이 노출되지 않으면) 최대 2달까지 걸릴 수 있습니다. 이에 대한 자세한 답변은 Q.사이트의 광고게재 승인신청을 한지 4주가 되었는데 아무런 답변이 없습니다. 에서 자세히 읽어볼 수 있어요!\n\n2) 사이트 소유권 확인하기\n사이트 심사 받기\n\n앞서 말한 것 처럼 사이트 소유권을 확인하기 위해 아래의 방법들을 선택해 적용해야합니다.\n\n처음에 보고 3개 중에 원하는 방법으로 적용하면 되는 것인가 생각했는데, 1) 애드센스 코드 스피넷이나 2) 메타 태그로 사이트 심사를 받고, Ads.txt 스니펫으로 사이트의 소유주 확인을 진행해야합니다.\n\n저희 회사 사이트는 이미 검증된(?) 사이트인지 사이트 심사가 사이트 url로 바로 확인이 되었는데, 노출이 덜 된 사이트에 대해서는 1), 2) 방법을 진행하면서 사이트 심사를 진행하면됩니다.\n\n예시로, 애드센스 코드 스니펫을 프로젝트에 적용해본다면, 프로젝트 script 삽입되는 최상단에 등록해주시면 됩니다.\n\n//_document.jsx\nimport { Html, Head, Main, NextScript } from \"next/document\"\n\nexport default function Document({ assetPrefix, ...etc }) {\n..\n\n  return (\n    <Html>\n      <Head>\n        <script <script async src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-{광고id}\"\n     crossOrigin=\"anonymous\"></script>\n      </Head>\n      <body style={{ overflow: \"hidden\" }}>\n        <div id={\"root\"}>\n          <Main />\n          <NextScript />\n        </div>\n      </body>\n    </Html>\n  )\n}\n\n\n애드센스는 참고로 서비스 내에서만 제공되어야만 하므로, 개발 단계를 분리하고 있다면 분기 처리를 진행하고, 운영기에서만 노출되도록 해주세요!\n\n자세한 사항은 해당 사항과 관련된 Nextjs 공식 문서 를 참고해서 구현해주세요 :)\n\n이렇게 모든 과정을 거쳐 사이트 심사를 완료 받고 나면, 우리가 해당 사이트에 소유권이 있는지 인증 단계를 진행하면 됩니다.\n\n사이트 소유권 인증하기\n\n소유권을 인증하려면 ads.txt를 설정하여 파일을 public 폴더 내부에 삽입해주시면 됩니다. public/ads.txt를 생성하고 파일을 다음과 같이 (사이트에서 지시하는 코드 대로 추가해주세요)\n\n/public/ads.txt\n\ngoogle.com, pub-ID, DIRECT, HASHCODE\n\n이렇게 등록하고 나면, 이후에 구글 봇이 돌면서 우리가 사이트에 추가한 내용을 확인하게 됩니다.\n\n저희는 계정이슈로 이 과정을 2번 정도 반복하게 되었는데 첫번째 승인은 3일, 두번째 승인은 1주일 정도 걸렸던 것 같아요!\n\n위와 같이 저희 회사 서비스가 잘 승인된 것을 확인하실 수 있습니다 🙂\n\n3) 사이트 내 광고 게시하기\n🤔 어떤 광고 유형이 있을까??\n\n이제 본격적으로 구글 애드센스는 우리에게 광고를 다양한 방법으로 삽입할 수 있다고 알려줍니다.\n\n광고 탭으로 들어가게 되면 사이트 기준, 광고 단위 기준을 분류하여 사이트에 맞게 광고 영역을 잡을 수 있습니다!\n\n이 4개의 광고 중에서 구글이 권장하는 디스플레이 광고를 선택하게 되었는데요! (사실 구글에서 권장하는 데에는 이유가 있답니다! 구글 광고 노출이 더 잘 되기 때문이예요 ㅎㅎ)\n\n디스플레이 광고 유형에는 3가지 사각형, 수평형, 수직형이 있습니다 ! 광고 크기로는 개발자가 직접 광고의 높이 너비를 지정할 수 있는 고정형, 구글 애드센스가 게시자(개발자)의 사이트의 페이지 레이아웃을 자동으로 감지하여 맞춰서 게재되는 반응형이 있습니다 :)\n\n사각형\t수평형\t수직형\n\n\t\n\t\n\n이렇게 어떤 광고가 있는지 살펴보았다면, 우리 사이트 기존 UIUX를 많이 해치지 않으면서 사용자들에게 노출은 최적화된 광고를 어떻게 삽입할 수 있을 지 저와 마케터 Ella와 함께 많은 고민을 진행했습니다 ㅎㅎ\n\n사실 광고가 화면에 많이 노출 될 수록, 그리고 오랜 시간 사용자들이 보고 있을 수록 저희에게 많은 광고 수익으로 잡히고, 또한 구글 애드센스 측에서도 \"어? 이 사이트 광고 노출 잘되네 더 잘 노출 시켜야지?!\" 이런 식으로 최적화 가 되기 까지의 그 시간이 단축됩니다 ㅎㅎ 하지만 유저들이 이탈하는 이유도 너무 많은 광고 이기 때문에 우리는 그 경계를 잘 찾고 다양한 광고 노출 방법으로 진행하기로 했습니다.\n\n👀 광고 런칭한 화면 살펴보기\n\n처음 런칭하고자 하는 유튜브 수익 계산기 서비스 기능에 UI를 많이 해치지 않도록 화면 왼쪽과 하단에 노출되도록 레이아웃을 잡았습니다!\n\n채널을 계속 검색하게 되면 채널 정보 컴포넌트가 추가되는 형태로 서비스가 개발되어있는데 이런식으로 크게 해치지 않는 선에서 노출이 되도록 광고 노출을 진행하였습니다!\n\n회사 서비스가 모바일 유입도 많은 터라, 모바일에서는 사각형 - 반응형으로 진행하였습니다 !\n\n광고를 어떻게 삽입했는지, 개발 내용은 아래 부터 자세히 설명하고 있습니다 ㅎㅎ\n\n😽 광고 런칭 그 후?\n\n광고를 삽입하고 런칭하고 난 후 수익이 $10달러 이상 노출되게 된다면 수익을 출금할 수 있는 계좌를 등록하게 됩니다!\n\n그리고 어느정도 최적화 작업이 구글 애드센스 내에서 진행되게 되는데요! 바로 오버레이 광고를 자동으로 삽입하는 앵커 광고 자동 실험 테스트도 시작하게 되어 어느정도 테스트 기간을 거치는 과정도 시작되었어요 :) 하지만 저희는 멤버십제로, 유료 결제 고객에게는 구글 애드센스 광고를 노출하지 않고 있기 때문에 오버레이 광고 테스트기간이 시작되면 유료 고객에게도 뜨기 때문에 이 테스트를 중지하게 되었답니다 ,, 하지만 오버레이 광고가 가장 수익이 잘 나오는!! 효자 광고 친구입니다\n\n슬프게도 유료 고객에도 갑자기 상관없이 떴던,,, 오버레이 광고,,,, 🥹🥹 멤버십제 오버레이 광고 런칭을 위해서 다양한 방법으로 리서치 및 시도를 진행했었는데,, 구글 애드센스가 vling.net 사이트 url을 기준으로 오버레이 광고를 삽입하는 것이기 때문에 아직까지 테스트 기간 런칭은 보류인 상태입니다 테스트 기간동안을 척척 해결하는 방법을 찾게 된다면 바로 새로운 글로 찾아올게요 !\n\n우선 해당 문제에 대해서는 구글 애드센스 커뮤니티에 help를 친 상태입니다 :) 답변은 아래의 원글에서 확인하실 수 있습니다!\n\nQ. 웹에서 오버레이 광고 개발자가 제어하는 방법이 없나요?\n\n4) 본격적인 개발 이슈들 💻\n\n본격적으로 개발이야기를 진행해보려고 합니다.\n\n먼저, 구글 애드센스에서 # 🤔 어떤 광고 유형이 있을까?? 에서 어떤 광고를 등록할지 정하고, 등록했다면 본격적으로 코드 삽입을 진행해볼게요!\n\n💵 광고 코드 삽입\n\n<script async src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=아이디\"\n     crossorigin=\"anonymous\"></script>\n<!-- 채널상세_수익분석(모바일)_사각형_반응형 -->\n<ins class=\"adsbygoogle\"\n     style=\"display:block\"\n     data-ad-client=\"ca-pub-광고Id\"\n     data-ad-slot=\"Id\"\n     data-ad-format=\"auto\"\n     data-full-width-responsive=\"true\"></ins>\n<script>\n     (adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n\n이런식의 광고 html 코드가 생성되게 되고, 저는 본격적으로 레이아웃 컴포넌트 구조를 확인면서 광고를 삽입하게 되었습니다:)\n\ndeclare global {\n  interface Window {\n    adsbygoogle: any;\n  }\n}\n \nexport const 광고컴포넌트 = () => {\n  \n  useEffect(() => {\n    (window.adsbygoogle = window.adsbygoogle || []).push({});\n  }, []);\n \n  return (\n    <ins\n      class=\"adsbygoogle\"\n      style={{ display: 'block' }}\n      data-ad-client=\"ca-pub-광고Id\"\n       data-ad-slot=\"Id\"\n      data-ad-format=\"auto\"\n      data-full-width-responsive=\"true\"\n    />\n  );\n};\n\n이렇게 무난하게 삽입하면 개발 끝!?! ㅎㅎㅎ 하지만 현실은 그렇지 못했습니다,,🥹\n\n✅ 이슈 1) local에서 광고 확인 불가 🚫\n\n우리가 흔하게 개발하는 단계인 localhost에서는 구글 애드센스가 등록된 url(vling.net) 으로 찾아오지 못하기 때문에 로컬환경에서는 구글 애드센스 광고를 확인하지 못합니다 🥹 그래서 빌드-배포 과정을 거쳐 번거롭지만 사이트에 배포를 하면서 광고를 확인하면서 확인하게 되었는데요!\n\n🔍 dev 환경에서 광고 확인을 위한 우회 전략\n\n저희는 dev url을 따로 사용하고 있어서 직접 개발하면서 dev Url에 배포를 하면서 제대로 확인하게 되었습니다!\n\n개발 단계에서 광고 레이아웃을 잡을 때에는 다음과 같이\n\n\n광고 영역에 배경색을 넣어가면서 임의로 레이아웃을 잡아가며 개발하였습니다.\n\n* 참고로 위의 사진에 하단에는 수평형 반응형 광고, 오른쪽에는 수직형 고정형 광고를 삽입했습니다.\n\n🧩 반응형 광고 vs 고정형 광고\n\n여기서 주의할 점은, 앞선 방법에는 크기가 고정되어있는 고정형 광고에만 유용합니다. 크기를 예측할 수 있기 때문이예요!\n\n하지만 반응형 광고는 광고 크기가 정해져 있지 않기 때문에 실제 광고 크기가 자유롭게 바뀝니다 따라서 반응형 광고를 삽입하실 예정이라면, 실제 배포하여 다양한 광고 크기에 대해 체크하면서 잡아가시면 좋을 것 같습니다. 저희도 반응형 광고를 삽입할때에는 그렇게 광고 크기가 크게 변경되어도 괜찮은 곳에만 삽입하게 되었습니다!\n\n예시로 아래처럼 높이가 높은 광고가 들어오게 될 수도 있습니다!\n\n사실 개발하면서 로컬에서도 띄우게 하는 방법이 없나 많은 리서치나,,, 해보았지만 배포하면서 그냥 빨리 개발하는게 더 빨라서 진행하게 되었습니다 ㅠㅠ 다들 좋은 방법이 있으시다면 알려주세요!\n\n✅ 이슈 2) root에 자동 auto !important 적용 😰\n\n다음 이슈는 구글 애드센스를 런칭했을 때 광고를 삽입한 페이지 전체에 height: auto !important 가 강제적으로 적용되는 이슈를 공유해보려고 합니다.\n\n⚠️ height: auto !important의 영향\n\n이 현상이 발생하는 이유는 반응형 광고를 설정하면, 광고 크기에 따라 사이트 구성 요소들이 변경되어야하기 때문에 스크립트가 강제적으로 스타일을 변경하기 때문입니다.\n\n이 자동 설정은 광고 크기에 따라 유동적으로 높이를 조절할 수 있게 하지만, 특정 페이지 레이아웃에서는 이러한 스타일 적용이 페이지 디자인에 부정적인 영향을 미쳐서, 현재 전체 너비에 영향을 미쳐 강제 조정이 들어간 상황입니다.\n\n저희 사이트에서 이 문제가 발생해서 영향을 끼쳤던 화면은 다음과 같은데요!\n\n위와 같이 root에 height: auto !important이 적용되어 세로 스크롤이 2개가 생겨버리게 되었습니다 😱😱\n\n구글 애드센스로부터 auto !important로 들어오는 것을 막을 수 없기에 열심히 대응하기 시작했습니다.\n\n🛠️ MutationObserver 최적화로 이슈 대응\n\n우선 공식문서에서 안내한 첫 번째 방법은 ,\n바로 구글 애드센스 설정에 가서 모바일 광고 크기가 자동으로 최적화 되는 토글을 off해주면 된다고 합니다!\n\n하지만 저희는 해당 설정을 꺼도 여전히 auto !important 문제가 적용되었는데요.\n\n따라서 저는 두 번째 방법으로,\nMutationObserver를 사용해 스타일이 자동적으로 바뀔 때마다 바로 원상복구 시킬 수 있도록 구현하였습니다.\n\nconst layoutAdsenseObserver = () => {\n  // 1 ) 문제가 생기는 DOM 요소들을 찾습니다.\n  const rootLayout = document.getElementById(\"root\")\n  const layoutSection = document.getElementsByClassName(\"Layout\")[0]\n  const headerWrapper = document.getElementsByClassName(\"Header\")[0]\n\n  // 2 ) MutationObserver로 아예 스타일을 비워주도록 합니다.\n  const observer = new MutationObserver(() => {\n    if (rootLayout) rootLayout.style.height = \"\"\n    if (layoutSection) layoutSection.style.height = \"\"\n    if (headerWrapper) headerWrapper.style.height = \"\"\n    if (headerContainer) headerContainer.style.height = \"\"\n  })\n\n  // 3) 실제 존재하는 요소만 설정하도록 했습니다.\n  const elements = [rootLayout, layoutSection, headerWrapper, headerContainer].filter(Boolean)\n\n  elements.forEach((element) => {\n    observer.observe(element, {\n      attributes: true,\n      attributeFilter: [\"style\"],\n    })\n  })\n\n  return () => observer.disconnect()\n}\n\n이런 식으로 요소의 style 속성이 바뀌는지 감시하는 옵저버를 만들고, 변경이 감지되면 바로바로 height 값을 비워서 원래 CSS가 적용되게 했습니다. 또한 이를 사용할 때 useEffect로 감싸 컴포넌트 언마운트될 때 옵저버를 정리하도록 했습니다.\n\n이걸 구현할 때, MutationObserver가 DOM 변경을 계속 감시하면 느려질 수 있으니까 style 속성만 참조하도록했습니다. 또한 filter(Boolean)으로 실제 있는 요소인지 검사하고, 컴포넌트가 없어질 때 옵저버도 정리하도록 해서 리소스를 관리했습니다!\n\n🧠 해결을 위해 더 고민해본 내용\n\n사실 위와 같이 구현하고 해당 이슈는 해결되었지만 직접 dom 요소를 건드리는 방식이 올바르게 해결한 방법인지는 아직 고민입니다.\n\n아무래도 React 생태계에서는 직접 DOM을 조작하는 것이 권장되지 않는 방식이라 이런 해결책이 적절한지 고민이 많았어요. React의 선언적 패러다임과는 어긋나는 명령형 코드가 되니까욥,,, 😅\n\n더 좋은 해결책을 찾아보려고 시도해봤는데, CSS로만 해결하는 방법도 찾지 못했습니다. 구글 애드센스가 inline style로 !important를 붙여서 적용하는데, CSS 우선순위에서 이를 덮어쓸 방법이 없거든요.\n\n또 다른 방법으로 생각해본 것은 광고 컨테이너를 iframe으로 완전히 격리시키는 방법이었는데요. 하지만 이 방법은 애드센스의 정책상 제한이 있고, 구현도 복잡해질 수 있어서 결국 MutationObserver 방식이 가장 실용적인 해결책이었습니다.\n\n그리고 특히 외부 라이브러리나 API(이 경우 구글 애드센스)와 통합할 때는 어쩔 수 없이 직접 DOM을 다뤄야 하는 상황이 생길 수도 있을 것 같았습니다.\n\n결론적으로는, 더 좋은 방법이 있다면 좋겠지만 현재로서는 MutationObserver를 사용하는 이 방식이 구글 애드센스와 React를 함께 사용할 때 발생하는 이슈를 해결하는 최선의 방법이라고 생각이 되어 이슈 해결을 종료했습니다. 실제로 애플리케이션에서도 잘 작동하고 있으니까요!\n\n다만 한 가지 더 개선할 점이 있다면, 현재는 특정 클래스 이름에 의존하고 있는데 리팩토링이나 클래스명 변경 시 이 코드도 함께 수정해야 한다는 단점이 있어요. 이런 부분을 좀 더 유연하게 관리할 수 있는 방법도 고민 중입니다!\n\n해당 문제를 개선하게 된다면, 추가로 기술 블로그로 작성해서 본문에 추가하도록 하겠습니다.\n\n✅ 이슈 3) 광고 노출 최적화\n\n광고를 런칭하고 실제 배포하면서 확인해보니 광고가 너무 늦게 뜨거나, 아예 안 뜨는 상황을 종종 만났습니다.\n\n⚠️ 광고가 노출되지 않을 때 발생하는 문제\n\n위 화면에서 컴포넌트 하단 공백은 원래 광고가 들어와야 하는 자리였지만, 광고 송출이 제대로 되지 않아 공백으로 남아 있었습니다.\n\n처음엔 단순히 광고 응답 지연이라고 생각했지만, 일반적인 딜레이라면 광고 컴포넌트가 렌더링된 후 최대 5초 안에는 광고가 뜨는 것이 정상입니다. 그러나 실제로는 1~2분이 지나도 광고가 아예 뜨지 않거나, 특정 상황에서는 계속해서 뜨지 않는 현상이 반복되었습니다.\n\n이 문제가 중요한 이유는 광고가 뜨지 않으면 광고 영역 자체가 의미 없는 공백 공간으로 남아버려 전체 UI/UX에 부정적인 영향을 미치기 때문입니다.\n\n🔧 광고 초기화 최적화로 이슈 대응\n\n광고를 더 안정적으로 노출시키기 위해 고민한 끝에, 광고 초기화 타이밍과 방식에 대한 최적화 작업을 진행하게 되었습니다.\n\n광고가 정상적으로 송출되지 않는 이유는, 구글 애드센스 스크립트가 특정 조건(예: 사용자가 비교 채널을 선택한 뒤에 페이지가 업데이트되는 상황 등)에서는 광고를 새로 불러오지 않거나, 이미 초기화된 상태에서 반응하지 않는 경우가 종종 발생했기 때문입니다.\n\n그래서 저는 광고를 더 잘 띄우기 위해, 초기화 타이밍을 명확하게 제어하고, 반복 실행되지 않도록 최적화된 로직을 구성했습니다.\n\n또한 광고 초기화가 지속적으로 반복되지 않도록 하기 위해 useRef를 사용하여 초기화 여부를 추적했습니다.\n\nexport function CompareDetailWrapper() {\n  const { query } = useRouter()\n  \n  // * 여기서 광고를 초기화하고, 이슈2를 해결한 내용은 따로 커스텀 훅으로 분리했습니다.\n  //  initAds : 초기화 하는 역할, fixAdStyle : 스타일 이슈 해결하는 역할\n  const { initAds, fixAdStyle } = useGoogleAdsense()\n  \n  // 2)  중복 초기화를 막기 위한 useRef\n  const adInitializationStatusRef = useRef(false)\n\n  const queryLength = useMemo(() => {\n    if (typeof query?.ids === \"string\") {\n      return query.ids.split(\",\").filter(Boolean).length\n    }\n    return 0\n  }, [query?.ids])\n\n  const isNotHigherThanStandard = true // 예시를 단순화하기 위한 조건 처리\n\n  // 페이지 최초 진입 시 광고 초기화\n  useEffect(() => {\n    initAds()\n    adInitializationStatusRef.current = true\n  }, [])\n\n\n  useEffect(() => {\n    const cleanup = fixAdStyle()\n    return cleanup\n  }, [])\n\n  // 1) 비교 채널이 생겼을 때 조건을 만족하면 광고 다시 초기화\n  useEffect(() => {\n    if (queryLength >= 1 && isNotHigherThanStandard && !adInitializationStatusRef.current) {\n      initAds()\n      adInitializationStatusRef.current = true\n    }\n  }, [queryLength, isNotHigherThanStandard, initAds])\n\n  // 3) 광고 초기화 상태 재설정\n  useEffect(() => {\n    adInitializationStatusRef.current = false\n  }, [queryLength, isNotHigherThanStandard])\n\n  return (\n    <div>\n      <ins\n        className=\"adsbygoogle\"\n        style={{ display: \"block\", width: \"100%\", minHeight: \"100px\", height: \"auto\", overflow: \"hidden\" }}\n        data-ad-client=\"ca-pub-xxxxxxxxxxxx\"\n        data-ad-slot=\"xxxxxxxxxx\"\n        data-ad-format=\"horizontal\"\n        data-full-width-responsive=\"true\"\n      />\n    </div>\n  )\n}\n\n코드를 살펴보며, 제가 해결한 방식을 차근차근 설명드리겠습니다.\n\n(1) 광고를 초기화 하는 로직을 조건에 맞춰 실행하도록\n\n광고를 무조건 한 번만 초기화하는 것이 아니라,\n\n페이지 최초 진입 시 사용자가 비교 채널을 선택해 queryLength가 1 이상일 때(추가 노출 조건)\n\n이 두 경우에만 광고를 초기화할 수 있도록 조건을 설정했습니다.\n\nif (queryLength >= 1 && isNotHigherThanStandard && !adInitializationStatusRef.current) {\n  initAds()\n  adInitializationStatusRef.current = true\n}\n\n광고 송출이 필요한 시점에만 초기화되고, 불필요한 재초기화는 방지할 수 있습니다.\n\n(2) 중복 초기화를 막기 위한 useRef\n\nuseRef를 사용하여 광고가 이미 초기화되었는 경우에는 다시 초기화하지 않도록 안전장치를 만들었습니다.\n\nconst adInitializationStatusRef = useRef(false)\n\n\n이건 useState와 달리 컴포넌트 리렌더링 없이 값을 유지할 수 있고, 광고 로딩 로직이 계속해서 불필요하게 반복되지 않도록 막아줍니다.\n\n(3) 광고 초기화 상태 재설정\n\n또한 페이지가 변경되거나 사용자의 액션으로 상태가 바뀌는 경우, adInitializationStatusRef.current 값을 다시 false로 초기화하여 광고를 다시 띄울 수 있도록 준비해두었습니다.\n\nuseEffect(() => {\n  adInitializationStatusRef.current = false\n}, [queryLength, isNotHigherThanStandard])\n\n이렇게 해서 상황에 따라 광고를 유연하게 다시 초기화할 수 있는 구조로 구현하였습니다.\n\n전체적으로 위와 같은 방법을 통해 광고 초기화 문제를 해결했고, 결과적으로 광고가 송출되지 않아 생기던 공백 문제와 UX 저하 현상을 어느정도 개선할 수 있었습니다!\n\n칭찬해주셔서 사실 넘 행복했습니다 🥰🥰🥰\n\n💬 해결 방식에 대한 회고\n\n이번 광고 노출 최적화 작업은 실제 서비스 운영 과정에서 겪은 \"광고가 안 뜨는 문제\" 를 단순히 눈으로 확인하고 넘어가는 것이 아니라, 광고 초기화 로직 자체의 구조적 문제로 인식하고 해결한 과정이었습니다.\n\n구글 애드센스는 외부 스크립트를 기반으로 동작하다 보니, React와 같은 SPA 환경에서는 초기 로딩 이후 상태 변화에 제대로 반응하지 않는 경우가 자주 발생하더라고요,\n\n특히 사용자가 페이지 내에서 채널을 비교하거나, 동적으로 UI가 바뀌는 경우엔 애드센스가 이를 인식하지 못해 광고가 아예 뜨지 않는 일이 생깁니다.\n\n저는 이런 문제를 해결하기 위해\n\n1) 광고 초기화가 필요한 시점을 명확히 정의하고,\n\n2) 중복 초기화를 막는 안전장치를 두고,\n\n3) 상태가 변경되었을 때 다시 초기화가 가능하도록 유연하게 구성하는 방식!\n\n이렇게 광고 라이프사이클을 앱 내에서 직접 제어하게 된 점이 가장 핵심이었습니다.\n\n🤔 아쉬웠던 점 & 개선해보고 싶은 내용\n\n하지만 이번 해결 방식에도 아쉬움은 있었습니다.\n\n초기화 상태를 직접 관리하고 조건을 걸어주는 방식은 기능적으로는 동작하지만, 코드가 점점 조건에 의존하게 되면서 복잡도가 생기기 시작했습니다.\n\nuseRef 플래그 방식은 비교적 간단하고 빠르지만, 광고 상태가 언제 초기화됐는지를 명확하게 추적하거나 디버깅하는 데에는 한계가 있었습니다. 또한 비즈니스 로직과 광고 로직이 섞이게 되면서 관심사의 분리가 어려워지는 구조가 되기도 했습니다.\n\n앞으로 더 개선해보고 싶은 방향을 생각해봤는데요!\n\n광고를 관리하는 전용 커스텀 훅(useAdManager) 혹은 Context로 분리하여 광고 초기화 상태와 트리거를 전역에서 일관되게 제어할 수 있도록 개선하거나,\n\n광고의 \"노출 조건\"을 모듈화해서, 페이지마다 조건을 다르게 적용해도 코드 중복 없이 구성할 수 있는 구조 를 설계하던지 해보고 싶습니다.\n\n이번 문제는 \"광고가 안 뜬다\"는 단순한 UX 이슈처럼 보였지만,\n내부적으로는 외부 스크립트와 SPA 구조의 충돌이라는 더 근본적인 문제였고, 이를 광고 초기화의 타이밍과 조건을 명확히 설정하는 방식으로 대응했다는 점에서 큰 의미가 있었다고 생각이 듭니다!\n\n🎉 마무리하며,,\n\n다양한 개발 이슈를 헤쳐나가며 구글 애드센스를 사내 서비스 환경에 적용했던 과정을 쭉 돌아보니 정말 많은 일들이 있었네요 😅\n\n처음엔 단순히 “코드만 넣으면 바로 되지 않을까?”라는 가벼운 생각으로 시작했지만, 막상 실무 환경에서 애드센스를 런칭해 보니 예상치 못한 다양한 기술적 문제들이 계속해서 등장했습니다.\n\n특히 로컬 환경에서 광고 확인이 불가능한 점이나, 애드센스의 자동 스타일링으로 인한 UX 이슈, 광고가 제대로 로드되지 않는 상황 등 실제 운영을 위한 최적화 과정에서 많은 고민과 삽질이 있었는데요.\n\n돌이켜 보면, 단순한 기능 구현을 넘어 서비스의 전반적인 품질과 사용자 경험을 세심하게 고려하며 문제를 해결했던 시간들이었습니다. 특히 MutationObserver를 통해 DOM 요소의 스타일을 실시간으로 복구했던 방식이나, 광고 초기화 타이밍을 세밀하게 제어하여 광고 노출의 안정성을 높인 것은 실질적인 운영 환경에서 좋은 성과를 낸 솔루션이었다고 생각해요.\n\n한편으로는 이렇게 DOM을 직접 조작하거나 외부 스크립트와의 충돌을 처리하는 과정에서 React의 기본적인 원칙과 조금 충돌하는 면이 있긴 했습니다. 앞으로는 이러한 문제를 더욱 React스럽게 해결할 수 있도록 고민을 이어가고, 커스텀 훅이나 상태 관리를 좀 더 명확히 하는 방법으로 리팩토링도 해보려고 합니다!\n\n구글 애드센스는 특히 웹!!!은 딱히 공식 문서를 찾기 어려웠습니다 대부분 커뮤니티로 문의 - 해결 , 몇 없는 기술 블로그들만 있는데요, 구글 애드센스 개발 커뮤니티 를 주로참고하면서 개발하시기를 추천드립니다!\n\n이 모든 여정을 함께 해준 마케터 Ella! 이 글을 빌어 감사의 말씀을 드립니다 ❤️\n\n여러분들의 사이드 프로젝트에도 구글 광고를 삽입해 많은 수익을 올리시길 바라며 글을 마칩니다 💵💵\n\nosohyun0224\nGarden / Junior Frontend Developer\n팔로우\n5개의 댓글\n댓글 작성\nant\n2025년 4월 6일\n\n실제 생긴 문제와 해결책까지 다 다뤄주셔서 넘좋아요!\n\n답글 달기\n정소윤\n2025년 4월 6일\n\n생각보다 많은 문제가 있네요...! 해결하는 과정까지 담겨있어서 비슷한 상황이 발생했을 때 유용할 것 같아요 :) 경험 공유 감사합니다 소현님!!\n\n답글 달기\n원정\n6일 전\n\n우와..👍 실제 경험을 녹여낸 글이라서 좋네요! 구글 애드센스 광고를 하게 되면 가이드로 사용해도 될만큼 상세하게 적어주신 점도 좋았어요! 감사합니다!\n\n답글 달기\n장운서\n5일 전\n\n진짜 디테일 하게 적어줘서 넘모 좋아요\n\n답글 달기\n김도운\n4일 전\n\n나중에 블로그에 광고 붙이려고 고민중이었는데 좋은 글 감사합니다 !!\n\n답글 달기\n관련 채용 정보\n뱅크샐러드\n웹 프론트엔드 엔지니어\n뱅크샐러드는 금융과 건강 데이터를 연계하여 혁신적인 서비스를 제공하는 플랫폼입니다. 프론트엔드 엔지니어로서 React를 활용한 개발 및 크로스 플랫폼 환경에서의 최적화 작업에 참여하게 됩니다.\n페이타랩(패스오더)\n웹 프론트엔드 개발자(JavaScript, React)\n대한민국 No.1 카페 주문 플랫폼인 패스오더에서 프론트엔드 개발자를 채용합니다! React와 TypeScript로 혁신적 서비스를 개발하며, 성장 중심의 문화를 통해 자신만의 커리어를 쌓아보세요!\n무무즈\n프론트엔드 엔지니어\n아이와 함께 하는 삶을 행복하게 만드는 무무즈에서 프론트엔드 엔지니어로 웹서비스를 혁신할 기회를 제공합니다. React와 Typescript를 활용한 프로젝트 설계 및 진행 경력이 있다면, 자율적인 업무 환경에서 성장할 수 있는 기회를 놓치지 마세요!",
    "tags": [
      "Google Adsense",
      "구글 애드센스"
    ],
    "commentCount": "5"
  },
  {
    "title": "유튜브로 시간 낭비 안하는 방법",
    "description": "유튜브는 참 유용한 플랫폼이다. 하지만 한 번쯤 경험해봤을 거다. 그냥 음악 플레이리스트나 검색하려고 유튜브에 들어갔는데, 정신 차려보니 알고리즘이 던져준 영상들을 한참이나 보고 있었다는 걸.\"이거 하나만 더 보고 끌 거야!\"라고 다짐하지만, 결국 새벽 2시... 익숙...",
    "link": "https://velog.io/@hello1234/%EC%9C%A0%ED%8A%9C%EB%B8%8C-%ED%94%BC%EB%93%9C-%EC%97%86%EC%95%A0%EC%A3%BC%EB%8A%94-%ED%81%AC%EB%A1%AC-%EC%9D%B5%EC%8A%A4%ED%85%90%EC%85%98",
    "author": "indie-hacker.log",
    "date": "2025년 4월 2일",
    "comments": "6개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/hello1234/post/014c08f7-c9b3-466e-9c02-6093b6ccad5b/image.jpg",
    "content": "indie-hacker.log\n로그인\nindie-hacker.log\n로그인\n유튜브로 시간 낭비 안하는 방법\n인디해커·2025년 4월 2일\n팔로우\n48\n개발과정크롬익스텐션\n✨ 다운로드 하러가기 (클릭)\n\n유튜브는 참 유용한 플랫폼이다. 하지만 한 번쯤 경험해봤을 거다.\n\n그냥 음악 플레이리스트나 검색하려고 유튜브에 들어갔는데, 정신 차려보니 알고리즘이 던져준 영상들을 한참이나 보고 있었다는 걸.\n\n\"이거 하나만 더 보고 끌 거야!\"라고 다짐하지만, 결국 새벽 2시... 익숙하지?\n\n나도 똑같았다. 집중해서 일하려고 유튜브를 켰다가, 갑자기 길거리 싸움 영상이 뜨고, 다음엔 미친 듯이 웃긴 강아지 영상이 나오고, 어느새 나는 10년 전 레전드 예능 클립을 보고 있었다.\n\n🤔 이놈의 유튜브 알고리즘만 뜨지 않는다면 의도한 대로 검색만 하고 나올텐데...\n\n이렇게 메인화면 피드가 뜨지 않고,\n\n영상을 시청 중일 때 우측에 나를 유혹하는 추천 영상이 뜨지 않는다면??\n\n이게 구현된다면 일주일에 적어도 7시간은 나의 시간을 아낄 것 같았다 ㅋㅋ\n\n그래서 직접 크롬 익스텐션을 만들기로 했다. 유튜브의 유혹을 차단하는 도구!\n\n개발 과정\n\n아래와 같이 코드를 작성했고, 전체 코드는 깃허브에서 확인해보면 된다.\n\nconst getRandomQuote = () => QUOTES[Math.floor(Math.random() * QUOTES.length)];\n\nconst insertQuote = (limit) => {\n  if (limit < 1) {\n    return;\n  }\n\n  const browseElement = document.querySelector(\"ytd-browse\");\n\n  if (browseElement) {\n    browseElement.innerHTML = `<h1 id='indie-hacker-quote'>${getRandomQuote()}</h1>`;\n  } else {\n    setTimeout(() => {\n      insertQuote(--limit);\n    }, 500);\n  }\n};\n\nconst callback = async (URL) => {\n  const rootElement = document.documentElement;\n\n  if (URL === \"https://www.youtube.com/\") {\n    rootElement.setAttribute(\"data-yt-page\", \"home\");\n\n    insertQuote(3);\n  } else if (URL.includes(\"youtube.com/watch\")) {\n    rootElement.setAttribute(\"data-yt-page\", \"watch\");\n  } else {\n    rootElement.setAttribute(\"data-yt-page\", \"other\");\n  }\n};\n\nchrome.runtime.onMessage.addListener((request) => {\n  callback(request.url);\n});\n\ncallback(window.location.href);\n\n와 몇 일동안 사용해봤는데 적응되니 제 시간을 매우매우매우 아껴줬습니다.\n\n배포\n\n하지만 자랑하고 끝낼 수는 없겠죠?\n\n제 시간도 이렇게 아꼈는데 여러분들에게도 좋은 영향을 줬으면 좋겠습니다.\n\n그래서 Chrome Web Store에 배포하기로 했습니다.\n\n개발자 계정 등록하려니 5$가 들더라고요?\n\n하지만 1명의 시간이라도 아낄 수 있다면 5$ 이상의 가치가 있다고 생각합니다.\n\n✨ 다운로드 하러가기 (클릭)\n인디해커\n많은 사람들이 사용하는 SW 서비스를 만드는 것이 꿈입니다.\n팔로우\n다음 포스트\n하루콩 제품 분석\n6개의 댓글\n댓글 작성\nwqfqwffqw\n2025년 4월 2일\n\n우와 좋네요 ~ 감사합니다\n\n답글 달기\nabcdefg\n2025년 4월 2일\n\n좋은 아이디어네요 ! 좋아요 누르고 갑니다\n\n답글 달기\nJavis\n2025년 4월 2일\n\n💪\n\n답글 달기\n채근영\n2025년 4월 5일\n\n제 시간을 아껴주셔서 감사합니다 잘 사용할게요!\n\n답글 달기\nSeongeun Hong\n3일 전\n\n오,, 맨날 유튜브 알고리즘에 이끌리기만 해봤지 아이디어 너무 좋은것 같아요\n\n답글 달기\nPeter\n2일 전\n\n오오 바로 설치했습니다!\n\n답글 달기\n관련 채용 정보\n미리디\n[미리캔버스] 백엔드 개발자\n디자인 생태계를 혁신하는 미리디에서 전세계 사용자에게 더 나은 디자인 경험을 제공하는 백엔드 개발자를 찾습니다. Java, Spring, AWS 기술과 함께 글로벌 서비스 최적화, AI 추천 시스템 개발에 참여하며 성장할 수 있는 기회를 놓치지 마세요.\n채널코퍼레이션\n[채널톡] Software Engineer\n채널톡은 아시아에서 가장 빠르게 성장하는 B2B SaaS 회사로, '올인원 AI 메신저'를 통해 고객 소통을 혁신하고 있습니다. 다양한 기술 스택을 활용해 글로벌 시장의 복잡한 문제를 해결할 수 있는 엔지니어를 기다립니다.\n무신사\nBackend Engineer (Core 광고플랫폼)\n무신사 테크는 고객과 브랜드에 개인화된 경험을 제공하며, Java와 Kotlin을 활용해 고성능 광고 시스템을 개발합니다. 혁신과 협업을 중시하는 이곳에서 분산 서비스 개발의 기회를 놓치지 마세요.",
    "tags": [
      "개발과정",
      "크롬익스텐션"
    ],
    "commentCount": "6"
  },
  {
    "title": "AI 시대에 개발자가 되려면",
    "description": "LLM이 급성장하면서, 프로그래밍 언어에 대한 지식이나 구현 방법을 AI가 대신 찾아주고 심지어 코드를 자동 생성해주는 일은 이미 흔해졌습니다.\n\n“곧 AI가 개발 업무를 대부분 커버할 것이다”라는 전망이 현실화되는 게 아닌가 하는 불",
    "link": "https://velog.io/@whatever/AI-%EC%8B%9C%EB%8C%80%EC%97%90%EB%8F%84-%EA%B2%B0%EA%B5%AD-%EC%A7%91%EC%A4%91%ED%95%B4%EC%95%BC-%ED%95%98%EB%8A%94-%EA%B2%83%EC%9D%80-%EB%82%98%EC%9D%98-%EC%97%AD%EB%9F%89%EC%84%B1%EC%9E%A5",
    "author": "whatever.log",
    "date": "2025년 4월 3일",
    "comments": "19개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/whatever/post/175186fe-68aa-46e8-b598-f67fd629f24d/image.png",
    "content": "whatever.log\n로그인\nwhatever.log\n로그인\nAI 시대에 개발자가 되려면\n왓에버·2025년 4월 3일\n팔로우\n35\nAI백엔드취업시장프론트엔드\n\n안녕하세요.\n왓에버 입니다.\n\nLLM이 급성장하면서, 프로그래밍 언어에 대한 지식이나 구현 방법을 AI가 대신 찾아주고 심지어 코드를 자동 생성해주는 일은 이미 흔해졌습니다.\n\n“곧 AI가 개발 업무를 대부분 커버할 것이다”라는 전망이 현실화되는 게 아닌가 하는 불안도 생깁니다. 특히 개발 직군에 진입하려는 분, 저연차 개발자들 사이에 큰 혼란이 생기고 있죠.\n\n이렇게 급속도로 발전하는 AI 시대에도 개발자 시장은 여전히 ‘탄탄한 기본 역량’을 갖춘 인재를 필요로 하고 있습니다. 오히려 평범한 반복 업무는 AI가 대체할수록, 문제를 스스로 정의하고 해결하는 개발자 본연의 역량이 더욱 중요해졌다고 이야기 합니다.\n\n이번 글은 AI가 개발자 채용시장에 어떤 변화를 일으키고 있는지, 그럼에도 불구하고 우리는 왜 “나의 역량성장”에 집중해야하는지에 대해 이야기하고자 합니다.\n\n1. GPT, Copilot, Claude 등 AI 도구의 급부상\n\n가깝게 와닿는 변화는 바로 개발 생산성이 단기간에 급상승하고 있다는 점입니다. 대표적인 예가 GitHub Copilot 코딩 에디터에 사소한 함수나 로직만 입력해도 자동으로 관련 코드를 제안해 줍니다. 개인적으로 필자도 개발을 하면서 개발생산성이 이전과 비교해 최소 100% 이상은 늘어났다고 이야기 할 수 있습니다.\n\nClaude가 활성화 되기 이전이지만 Stack Overflow 설문에서도 개발자의 70%가 이미 AI 코딩 도구를 사용하거나 사용할 계획이라고 답했고, 그중 가장 많이 사용되는 툴은 ChatGPT(83%)와 Copilot(56%)이라는 결과가 나왔습니다. 실제로 저연차 개발자들이 빠른 속도로 문법을 익히고, 에러 해결 과정을 학습하는 데에도 GPT의 도움을 받고 있습니다. ChatGPT가 단순한 문법 설명뿐 아니라, 의미 있는 예시까지 제공해주기 때문이죠.\n\n특히 GPT 추론과 딥리서치가 생겨나면서 생각을 함께하는 파트너, 레퍼런스 조사에 대한 비용도 상당히 줄어들었어요.\n\n이젠 MPC의 등장으로 LLM의 세계관이 확장되어 생산성을 더욱 개선할 수 있을 것으로 기대하고 있습니다. (저도 매일매일 업데이트가 버거울 정도입니다...)\n\n2. AI 도구의 한계: 신뢰도와 맥락 이해의 부족\n\n그러나 이렇듯 편리한 AI가 만능은 아닙니다. 정량적으로는 생산성이 향상되기도 했지만, 한계 역시 분명합니다.\n\n코드 품질과 일관성\nGPT가 제안하는 코드가 항상 최적의 해답인 것은 아닙니다. 기업 현장에서 Copilot을 테스트해 본 사례에 따르면, 제안 코드 중 최종적으로 반영되는 비율은 약 33%에 그쳤다고 합니다. 이는 AI가 만든 코드가 프로젝트 맥락이나 비즈니스 로직에 꼭 맞지는 않다는 뜻입니다. 도메인 지식이 부족하고, 코드 스타일이나 유지보수 방식을 충분히 반영하지 못하기 때문이죠.\n\n추론 오류 및 신뢰도 문제\nGPT 역시 근거 없는 자신감을 보이는 경우가 잦습니다. 실제로 Stack Overflow에서 AI 답변 신뢰도에 대해 조사했을 때, “AI 답변을 매우 신뢰한다”는 의견은 3% 정도에 불과했습니다. 반면 “전혀 신뢰하지 않는다”라는 의견이 6%나 됐을 정도로, 잘못된 정보를 그럴듯하게 말하는 AI 답변에 대한 경계심이 여전합니다.\n\n복잡한 문제 해결 능력 부족\n무엇보다 AI는 “어떤 문제를 풀어야 하는가?”를 스스로 정의하지 못합니다. 복잡한 비즈니스 요구사항이나 이해관계자를 조율해야 하는 상황에서, AI가 적절한 해법을 제시하는 데에는 한계가 뚜렷합니다.\n\n\n이런 사실들은 “AI가 개발자를 대체한다”는 말이 아직은 섣부르다는 것을 보여줍니다. 실제로 대기업 기술 리더들과 스타트업 CTO들은 한목소리로 “AI는 분명 강력한 보조 도구지만, 여전히 사람이 문제를 정의하고 의사결정해야 한다”라고 지적합니다.\n\n3. 유명 개발자들의 공통된 조언: ‘기본기와 문제 해결 능력’\n\nAI 시대가 도래해도 변치 않는 것은, 개발자의 진짜 가치는 문제 해결 능력과 기본기에서 나온다는 사실입니다. 세계적인 개발자나 기술 리더들도 입을 모아 이를 강조하는데요, 대표적인 몇 가지를 살펴봅시다.\n\n존 카맥(John Carmack)\n\n“코딩 자체는 가치의 원천이 아니다. 어떤 문제를 정의하고 풀어갈지 결정하는 능력이야말로 개발자의 핵심 역량이다.”\n\n‘둠(Doom)’과 ‘퀘이크(Quake)’로 유명한 id 소프트웨어의 공동창업자이자, 전설적인 프로그래머인 존 카맥은 초창기부터 “문제를 어떻게 해결할 것인가”를 중시해왔습니다. 단순히 코딩 기술을 뽐내는 것이 아니라, 사용자가 겪는 불편함이나 비즈니스 목표를 실현하기 위해 창의적으로 접근하는 태도가 중요하다는 것이죠. (코드 없이 해결할 수 있는 해결 방법이 더 좋을 때가 많습니다...)\n\n일론 머스크(Elon Musk)\n\n지식을 나무에 비유하자면, 줄기와 가지가 되는 ‘기본 원리’를 이해해야 하고, 그 후에 잎사귀에 해당하는 세부사항을 덧붙여라.\n\n스페이스X, 테슬라를 이끄는 일론 머스크는 면접 시에 가장 어려웠던 문제와 해결 과정을 집요하게 물어봅니다. 머스크는 실제 문제 해결 경험이 있는 사람은 해결 과정의 맥락과 디테일을 정확히 기억하고 논리적으로 설명할 수밖에 없다고 봅니다. 이런 맥락에서 학벌이나 경력보다, 직접 부딪히고 해결했던 경험을 더 중시하는 편이죠.\n\n4. 한국 스타트업들의 시각: 토스, 당근, 두잇, 올웨이즈, 모요 등\n\n이러한 기본기에 대한 요구는 단지 글로벌 빅테크나 전설적인 개발자들에게 해당하는 것은 아닙니다. 한국의 유망 스타트업들도 같은 방향을 가리키고 있습니다. 토스, 당근, 두잇, 올웨이즈, 모요 등은 빠른 속도로 성장하고 있으며, 채용 시장에서도 많은 주목을 받고 있죠. 이들의 공통점은 무엇일까요?\n\n토스\n토스는 공식 블로그를 통해 “실제 서비스에서 복잡한 요구사항을 이해하고 코드로 명확히 구현할 수 있는 역량”을 본다고 밝힌 바 있습니다.\n면접에서는 지원자가 “다뤘던 프로젝트에서 어떻게 문제를 찾고 해결했는가”를 많이 물어봅니다. 즉, 비즈니스와 사용자 관점을 이해하고, 그 문제를 기술적으로 어떻게 풀어냈는지에 주목한다는 뜻이죠.\n당근\n당근 역시 미션 크리티컬한 문제를 빠르게 해결할 수 있는 역량을 중요하게 봅니다.\n특히, 다양한 도메인에서 오는 요구사항을 정리하고, 사용자 경험을 핵심에 두면서 협업할 줄 아는 개발자를 선호하죠. AI가 코드를 짜주더라도, 현실의 문제를 어떻게 정의하고 개선할지는 오롯이 사람의 몫이기 때문입니다.\n두잇, 올웨이즈, 모요\n최근 떠오르는 스타트업들의 채용 페이지를 살펴보면, 대부분 “뛰어난 문제 해결사”, “주도적 학습 능력”, “도메인 이해도”를 강조하고 있습니다.\n실제 공고 문구 예: “우리의 문제를 함께 정의하고 해결할 개발자를 찾습니다”, “단순히 시키는 대로가 아닌, 주도적으로 아이디어를 내고 실행할 줄 아는 분 환영” 등.\n이는 GPT, Copilot 시대에 굳이 ‘코드 타이핑 장인’을 원하지 않는다는 의미입니다. “기술 자체는 무수히 많은 도구 중 하나일 뿐, 어떤 문제를 풀 것인지가 더 중요하다”는 메시지이기도 하죠.\n5. AI에 익숙해져야 하지만, 더 중요한 것은 ‘AI 활용 능력 + 기본기’\n\n물론 AI 도구를 능숙하게 사용하는 역량이 중요해지는 것은 사실입니다. 해외 주요 IT 리서치 기관에서는 향후 AI를 제대로 활용할 줄 아는 개발자가 주도권을 잡을 것이라고 예상합니다. 그러나, AI가 뿌려주는 정보를 ‘잘못된 방향’으로 적용하지 않는 분별력이 뒤따르지 않으면, 오히려 시간과 리소스를 낭비할 수 있습니다.\n\n한편, AI에게 요청(prompt)을 주고 결과물을 해석하는 능력도 새로운 필수 역량으로 떠오릅니다. 예컨대 GPT가 제안한 코드를 보고, “왜 이런 로직이 나왔는가?”, “우리가 해결해야 할 문제와 부합하는가?”를 분석하고 수정할 줄 알아야 하죠.\n\n이를 위해서라도 문제 해결 원리에 대한 이해, 데이터 구조나 알고리즘의 기본 개념, 도메인-specific 로직에 대한 이해가 필수적입니다. 예시로 과거에는 전기전자 회로부터 직접 알아야 하드웨어 프로그래밍이 가능했던 시대가 있었지만, 점차 높은 수준의 추상화가 이루어지면서 기본기가 없는 사람도 “코드만” 짤 수 있는 환경이 열렸습니다. 그러나 그 결과물의 퀄리티와 유지보수성을 책임지는 것은 여전히 기본기를 탄탄히 갖춘 사람이었던 것처럼, 오늘날에도 “AI가 코드를 대량으로 만들어 줄 수 있다” 해도 결과물을 이해하고 점검하는 개발자가 최종 승자가 될 것입니다.\n\n6. 결국, AI 시대에도 집중해야 할 것은 ‘나의 역량성장’\n\n요약하자면, “AI가 개발자를 대체하느냐”라는 물음에 대해 가장 많은 전문가들은 “아니다, 오히려 좋은 도구가 생겼을 뿐”이라고 답합니다. AI가 기본적인 코드 작성을 도와줄수록, 사람 개발자는 더 고차원적인 문제 해결에 집중할 수 있습니다.\n\n하지만 이때, 충분한 기본기와 문제 정의 능력, 도메인 이해, 그리고 커뮤니케이션 역량이 갖춰져 있지 않으면 AI의 잠재력을 제대로 활용하기 어렵습니다. 생성형 AI가 제안하는 코드를 그대로 수용하기만 한다면, 결국 “AI에게 의존하는 단순 반복 담당자”로 전락할 위험이 큽니다. 반대로, AI가 만들어낸 초안(코드나 기획안)을 비판적으로 검토하고, 현실 세계의 요구사항과 맞춰 적절히 재구성할 수 있는 사람이야말로 AI 시대에서 더 높은 가치를 인정받을 것입니다.\n\n이미 토스, 당근, 두잇, 올웨이즈, 모요처럼 성장하는 국내 스타트업들도, 코딩 테스트보다 문제 해결력과 기본기를 더 중시합니다. 이들은 복잡한 비즈니스 요구사항을 제대로 이해하고, 필요한 정보를 AI를 통해 적절히 얻되, 최종적으로 “우리 서비스가 해결하려는 문제”를 완수할 수 있는 분들을 찾고 있습니다. 특정 언어나 알고리즘만 빠르게 공부하는 것은 한계가 있고, 더 나아가 여러 사람과 협업하며 주도적으로 문제를 풀어내는 능력이야말로 귀중한 자산입니다.\n\n인공지능으로 인해 평범한 코딩 업무가 평준화될수록,\n진짜 문제 해결 능력을 갖춘 사람의 가치는 더욱 빛을 발한다.\n\n이 한 줄이야말로 AI 시대를 살아갈 개발자에게 가장 중요한 교훈이 아닐까 싶습니다. 지금 이 글을 읽는 취준생, 주니어 개발자 분들도, “GPT가 다 해줄 거야”라는 막연한 기대가 아닌, “AI를 어떻게 활용하고, 어떻게 검증하고, 어디서 문제를 정의할까?”를 꾸준히 고민해보세요. 기본기에 충실하고, 문제 해결을 즐기는 사람이라면 AI라는 도구와 시너지를 일으켜 지금보다 몇 배 더 성장할 수 있을 것입니다.\n\n결국, 어떤 시대든 개발자의 본질적인 가치는 ‘무엇을 어떻게 해결할 것인가’에서 나옵니다. 문제 해결을 통해 부가가치를 얻을 수 있기 때문이죠. (쉽게 말해 개발자도 밥값을 해야한다는…) AI가 커지더라도 시장에서 취업하고, 또 주도적으로 일하기 위해서는 “기본기 역량”을 갖춰야 한다는 사실을 잊지 마시길 바랍니다. 끊임없이 스스로를 업데이트하고, 실전 프로젝트에 적극 뛰어들어 역량을 성장시키는 여정은 결코 헛되지 않을 것입니다.\n\n7. 4월 14일 21시 AI 시대에 프로덕트 엔지니어로 살아남기 웨비나(무료)\n\n“GPT가 코드를 짜는 시대, 나는 어떤 개발자가 되어야 할까?” 오늘 주제와 관련해 왓에버의 훌륭한 멘토의 이야기를 듣고 나눌 수 있어요.\n왓에버 공식 오픈카톡방에 참여하시면 웨비나 참가 안내사항을 확인하실 수 있습니다! (왓에버 멘토 상시 활동중)\n오카방 합류하기\n\n8. 앞광고, 왓에버가 만든 기본기와 문제 해결능력을 기르는 30Days Sprint\n\n왓에버는 AI 시대에도 살아남을 수 있는 역량성장을 위해서 고민하고 있어요.\n4주간 집중 성장이 필요하다면 아래 과정에 합류해 보세요! (5월 킥오프 집중 모집중)\nReact 100% 이해하고, 탑티어 멘토와 로켓 성장하기\n\nSpring 회사에 입사한 것 처럼 트래픽 대응 레거시 리팩토링하기\n\n왓에버\n왓에버는 더 나은 커리어를 만들어 나가고 싶은 개발자 취업 준비생 및 이직 준비생을 위해 존재합니다. 여러분이 성공적인 커리어를 쌓을 수 있도록 다양한 서비스를 제공하고 있습니다.\n팔로우\n이전 포스트\n2025년 합격하는 개발자 이력서 탬플릿 Part 1\n19개의 댓글\n댓글 작성\n왓에버\n2025년 4월 3일\n\n웨비나 많은 관심 부탁드려요!\n\n답글 달기\n야나으듀\n2025년 4월 3일\n\n좋은 내용 감사합니다!\n\n답글 달기\n개발자 팀\n2025년 4월 3일\n\nAI 시대에도 개발자 취업이 될까요?\n\n답글 달기\nagusze\n2025년 4월 3일\n\n웨비나 기대됩니다!\n\n답글 달기\nDldoemeix\n2025년 4월 3일\n\n글 잘 읽었습니다!\n\n답글 달기\n김재환 (JaeHwan Kim)\n2025년 4월 3일\n\n언제나 좋은글!\n\n답글 달기\nEli\n2025년 4월 3일\n\n웨비나 참석하고 싶어요!\n\n답글 달기\n이니지\n2025년 4월 3일\n\nAI로 전체 개발자 채용 수는 줄어들까요?\n\n답글 달기\nCampusKU\n2025년 4월 3일\n\n감사합니다!\n\n답글 달기\nMgqux\n2025년 4월 3일\n\n감사합니다!\n\n답글 달기\n리루리리\n2025년 4월 3일\n\n결국은 기본기...\n\n답글 달기\n이세진\n2025년 4월 3일\n\n좋은 내용 감사합니다!\n\n답글 달기\nHeejin Ryu\n2025년 4월 3일\n\n재밌게 읽었습니다~\n\n답글 달기\nDheisnc\n2025년 4월 4일\n\n감사합니다!\n\n답글 달기\n데브수진\n2025년 4월 4일\n\n웨비나 참석할게요!\n\n답글 달기\nfront-devs\n2025년 4월 4일\n\n좋은 글 감사합니당\n\n답글 달기\nprofile-devs\n2025년 4월 4일\n\n굿굿!\n\n답글 달기\nInyeong Kang\n2025년 4월 4일\n\n나의 역량은 계속해서 갈고 닦아야 한다..!\n\n답글 달기\n유승완\n2025년 4월 5일\n\n언제나 가장 핵심이 되는 것에 집중해야 하는 것 같아요\n\n답글 달기\n관련 채용 정보\n한글과컴퓨터\nML 모델 개발자\n한컴은 AI 혁신을 통해 더 쉽고 편한 디지털 문서 환경을 만드는 테크 기업으로, OCR 및 이미지 분류 SDK 개발을 맡은 ML 모델 개발자를 찾고 있습니다. PyTorch와 TensorFlow를 활용한 딥러닝 모델 개발 경험이 있다면, 글로벌 빅테크 기업으로 도약할 한컴의 미래에 함께하세요!\n메이아이\nComputer Vision Engineer\nAI 스타트업 메이아이에서 Computer Vision Engineer를 모집합니다! 다양한 머신러닝 모듈을 이용해 고객 동선 데이터를 분석하는 주 역할을 맡고, 국내 대기업과 함께 성장하는 기회를 경험할 수 있습니다.\n에이프리카\nAI Research Engineer & AI consultant\n에이프리카는 클라우드와 인공지능 분야에서 고객의 디지털 혁신을 지원하는 IT 기업으로, MLOps 및 LLM 관련 연구에서 기술력을 발휘하고 있습니다. AI Research Engineer와 Consultant로서 다양한 정보 추출 및 시스템 구현에 참여하며, 실전 경험을 바탕으로 성장할 기회를 제공합니다.",
    "tags": [
      "AI",
      "백엔드",
      "취업시장",
      "프론트엔드"
    ],
    "commentCount": "19"
  },
  {
    "title": "하루콩 제품 분석",
    "description": "오늘 분석해볼 프로덕트의 주제는 “모바일 앱”이다.별점은 ⭐ 4.8점리뷰는 7만개+누적 다운로드는 100만+→ 참고로 Android만 계산했다.하루를 기록하는 가장 간단한 방법, 하루콩이다.하루콩은 2019년, 서울대 자유전공학부 선후배 4명이 시작한 프로젝트다. 이들...",
    "link": "https://velog.io/@hello1234/%ED%95%98%EB%A3%A8%EC%BD%A9-%EC%A0%9C%ED%92%88-%EB%B6%84%EC%84%9D",
    "author": "indie-hacker.log",
    "date": "2025년 4월 6일",
    "comments": "2개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/hello1234/post/2eadead3-7982-44dc-9c81-ccb1ff2f9702/image.png",
    "content": "indie-hacker.log\n로그인\nindie-hacker.log\n로그인\n하루콩 제품 분석\n인디해커·2025년 4월 6일\n팔로우\n29\n\n오늘 분석해볼 프로덕트의 주제는 “모바일 앱”이다.\n\n별점은 ⭐ 4.8점\n\n리뷰는 7만개+\n\n누적 다운로드는 100만+\n\n→ 참고로 Android만 계산했다.\n\n하루를 기록하는 가장 간단한 방법, 하루콩이다.\n\n글이 아닌 이모지로 기록하는 감정 다이어리\n\n하루콩은 2019년, 서울대 자유전공학부 선후배 4명이 시작한 프로젝트다.\n\n이들은 1인 가구의 정서적 지원을 위해 반려로봇을 개발하려 했고, 이를 위해 수많은 1인 가구를 인터뷰했다.\n\n하지만 인터뷰를 거듭할수록 깨달았다.\n\n정작 1인 가구에게 정서적 지원을 하기 위해 필요한 것은 반려로봇이 아니라, 스스로의 감정을 기록할 수 있는 도구였다.\n\n그렇게 탄생한 것이 바로 하루콩이다.\n\n하루콩이 기존 기록 서비스와 가장 크게 차별화되는 점은 '글자가 필요 없다'는 것이다.\n\n하루콩에서는 하루를 구성하는 17가지 카테고리(기분, 식사, 사람, 날씨 등) 중 원하는 것만 선택할 수 있다.\n\n글을 쓰지 않아도, 이모지 아이콘을 클릭하는 것만으로 감정과 하루를 기록할 수 있다.\n\n필요하면 간단한 한 줄 메모나 사진을 추가하는 것도 가능하다.\n\n이렇게 쌓인 기록들은 캘린더에 한눈에 정리되며, 사용자는 자신의 감정 변화를 직관적으로 파악할 수 있다.\n\n이외에도 기능이 많지만 위 내용이 하루콩에서 가장 어필하는 기능이다.\n\n참고로 하루콩은 글로벌 서비스이다.\n\n수익모델\n\n첫 번째 수익원은 광고다.\n\n사용자가 감정을 기록할 때마다 약 10초 정도의 광고를 보게 된다.\n\n매일같이 일기를 쓰는 서비스 특성상,\n\n꾸준한 사용을 유도할 수 있기 때문에 광고 모델이 잘 어울린다고 판단한 것 같다.\n\n구독권\n\n다음은 광고 없이 사용할 수 있는 구독 모델이다.\n\n다른 앱들과 비교했을 가격이 꽤 저렴한 편이다.\n\n부담 없이 결제할 수 있는 수준으로, 진입 장벽을 낮춘 느낌이다.\n\n테마스토어\n\n하루콩의 가장 큰 경쟁력이자 아이덴티티는 '콩'이라는 귀여운 캐릭터다.\n\n이 캐릭터와 테마를 판매하는 스토어 구조는 확장에도 유리하다.\n\n좀 더 구체적으로 말하면,\n\n새로운 콩 디자인이나 테마가 추가될수록 사용자들의 니즈를 충족시키는 동시에,\n\n무료 이용자들이 실제로 구매로 전환될 확률도 높아진다.\n\n또한, 테마나 캐릭터가 업데이트될 때마다\n\n공유 이벤트 같은 바이럴 요소를 붙이면, 신규 고객 유입의 기회로도 활용할 수 있다.\n\n심리상담\n\n아직 서비스되고 있진 않지만,\n\n추후에 심리 상담 서비스를 준비 중이라는 소문이 있다.\n\n만약 실제로 도입된다면, 하루콩에 쌓인 감정 기록 데이터가 상담에 활용될 가능성도 있다.\n\n그리고 이 상담 서비스는, 유료 모델로 연결될 수 있는 새로운 수익원이 될 것이다.\n\nMVP 방법론\n\n이런 리뷰를 보면,\n\n처음부터 완성도 높은 제품을 만든 건 아닌 것 같다.\n\n최소 기능(MVP)만 구현해서 빠르게 시장에 내놓고, 사용자 반응을 보며 개선해온 흔적이 느껴진다.\n\n하루콩이 퍼스트 펭귄이였을까\n\n나도 처음엔 하루콩의 아이디어 발굴 과정을 듣고\n\n“와… 고객이 진짜 필요한 솔루션을 어떻게 이렇게 정확히 도출했지?”\n\n“어떻게 이렇게 공감받는 제품을 만들었을까?” 싶었다.\n\n그런데 Daylio라는 프로덕트를 발견하고 나서 비슷한 선례가 있었구나 싶었다.\n\nDaylio는 1,000만 다운로드를 넘긴 서비스다.\n\nMVP 구조만 놓고 보면, 하루콩과 꽤 비슷하다.\n\nDaylio의 출시일: 2015. 8. 17.\n\n하루콩의 출시일: 2021. 2. 25.\n\n🤔… 퍼스트 펭귄은 아닐 수도 있다.\n\n하지만 그렇다고 해서 의미가 퇴색되는 건 아니다.\n\n누가 먼저 했느냐보다, 누가 더 잘 전달하느냐가 더 중요하니까.\n\n하루콩 카피앱들\n\n하루콩과 비슷하게 이모지를 통해 감정을 기록하는 앱들은 정말 많았다. (10개+)\n\n블루시그넘을 살펴보자\n\n라고 한다.\n\n하루콩 말고도 만드는 “정신건강을 혁신”하기 위해 만드는 앱들이 많았다. (7개+)\n\n기술스택\n하이브리드: iOS와 Android를 동시에 개발\n네이티브: iOS, Android를 각각 따로 개발\n\n채용 공고를 보니 iOS, Android 개발자를 각각 따로 뽑고 있었다.\n\n즉, 하이브리드 앱이 아니라 네이티브 앱을 주로 개발하고 있다는 뜻이다.\n\n그런데 일부 앱에서는 Flutter도 사용하고 있었다.\n\n안정적으로 자리잡은 앱은 네이티브로 개발하고,\n\n실험이 필요한 앱은 하이브리드로 빠르게 만들어보는 방식인 것 같다.\n\n~~가 하고 있다던데요.\n\n어떤 창업가가 열정적으로 아이디어를 피칭하고 있었다.\n\n그 밑에 달린 댓글 하나.\n\n“이거 ~~가 이미 하고 있던데요.”\n\n세상에 안 되는 이유는 진짜로 무한정 많다.\n\n“시장 작다”, “돈 안 된다”, “~~가 먼저 했다”, “너무 어렵다”...\n\n안 되는 이유로만 따지면, 이 세상에 존재할 제품이 몇 개나 되겠냐.\n\n근데 웃긴 건,\n\n오늘 소개한 사례에서도 그렇듯\n\n꼭 퍼스트 펭귄이어야 성공하는 건 아니다.\n\n중요한 건 누가 제일 먼저 했냐가 아니라,\n\n누가 제일 잘 풀었냐다.\n\n나는 창업 초반에 이런 생각을 자주 했다.\n\n“~~가 이미 하고 있는데, 내가 이걸 해도 될까?”\n\n“이건 이미 정답이 나와 있는 시장 아닌가?”\n\n근데 깨달았다.\n\n이런 가설은 틀릴 때가 훨씬 더 많다.\n\n누가 하고 있다고 해서 내가 못 하는 건 아니고,\n안 좋은 조건이라고 해서 불가능한 건 더더욱 아니다.\n\n시장에서 이미 뭔가 하고 있다는 건\n\n그만큼 문제가 분명히 존재한다는 증거일 수도 있다.\n\n그 사람은 그 사람의 방식대로, 나는 내 방식대로 풀면 된다.\n\n그래서, “이미 누가 하고 있다던데요”는 무조건 안 해야 할 이유는 아니다.\n\n여러분의 피드백을 기다리고 있어요 👀\n\n이번 글, 어떻게 보셨나요?\n\n아래 항목 중 마음 가는 대로 편하게 남겨주세요!\n\n좋았다면 의사를 꼭 표시해주세요!\n\n반응이 좋지 않다면, 없애려고 합니다 🥹\n\n설문 하러가기\n\n매번 보내주시는 피드백이 정말 큰 도움이 돼요. 감사해요! 🙏\n\n뉴스레터\n\n추가로 뉴스레터를 구독한다면 비슷한 글을 메일로 받아볼 수 있어요!\n\nhttps://maily.so/indiehacker\n\n인디해커\n많은 사람들이 사용하는 SW 서비스를 만드는 것이 꿈입니다.\n팔로우\n이전 포스트\n유튜브로 시간 낭비 안하는 방법\n2개의 댓글\n댓글 작성\n알엔\n2025년 4월 6일\n\n재미있게 봤습니다 ~!\n\n답글 달기\n호랑달팽\n2025년 4월 6일\n\n👍\n\n답글 달기\n관련 채용 정보\n노머스(원더월)\niOS 엔지니어\n노머스는 아티스트 IP를 활용해 혁신적인 엔터테인먼트 솔루션 '프롬'과 '원더월' 서비스를 제공합니다. iOS 개발자로서 팬과 아티스트를 연결하는 플랫폼을 함께 만들어가며, 유연한 소통과 팀 성장 문화를 경험하세요!\n힐링페이퍼(강남언니)\nAndroid 개발자\n강남언니는 의료서비스 혁신을 위한 IT 플랫폼을 제공하며, 개발자는 협업을 통해 복잡한 문제를 해결합니다. Kotlin을 기반으로 한 안드로이드 개발 경험이 있는 인재를 찾고 있으며, 동료와의 소통을 중시하는 문화가 특징입니다.\n토스뱅크\nAndroid Developer\n토스뱅크의 Android 개발 팀에 합류하여, 다양한 직군과 협업하며 천만 사용자에게 새로운 기능을 빠르게 제공하는 기회를 누려보세요. 자율적인 환경에서 Kotlin과 UI/UX 가이드라인을 바탕으로 개발해 나가며, 뛰어난 동료들과 함께 성장할 수 있는 특별한 문화가 기다립니다.",
    "tags": [],
    "commentCount": "2"
  },
  {
    "title": "React의 Context API 뜯어보기",
    "description": "Context API는 어떻게 동작할까? 렌더링 시나리오를 통해 내부 동작을 알아보자.",
    "link": "https://velog.io/@koreanthuglife/React%EC%9D%98-Context-API-%EB%9C%AF%EC%96%B4%EB%B3%B4%EA%B8%B0",
    "author": "Deep Diver🤿",
    "date": "2025년 4월 6일",
    "comments": "8개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/koreanthuglife/post/4736569e-e1cc-468f-b152-89b345bda123/image.png",
    "content": "Deep Diver🤿\n로그인\nDeep Diver🤿\n로그인\nReact의 Context API 뜯어보기\n최기환·2025년 4월 6일\n팔로우\n22\nReact\nReact 딥다이브\n목록 보기\n3/3\n\nReact 개발자라면 누구나 한 번쯤은 Cotext API를 사용해 봤을 것이다. 하지만 많은 개발자들이 Context API를 단순히 상태 관리 도구로 생각하고 있는 경우가 많다. 오늘은 이에 대해 얘기하고, Context API의 진짜 목적과 내부 구현을 파헤쳐 보려 한다.\n\nContext API란 무엇일까?\n\n나는 Context API가 상태 관리 도구보다는 의존성 주입(Dependency Injection) 도구라 생각했다. 적어도 상태 관리 도구라 생각하는 것보다는 좋은 답변이라 생각한다. 다만 이 글의 결론에도 적어뒀지만, 이 글을 적으며 그 관점에 변화가 생겼다. 내부 동작을 분석하며 의존성 주입의 도구에 그치지 않고 컴포넌트 렌더링 사이클과 동기화시켜 안정적으로 사용할 수 있게 관리해주는 API 정도의 개념으로 이해하게 되었다. 이 이유에 대해서는 결론 부분에 자세히 적어뒀다.\n\nReact의 기본 데이터 흐름은 부모에서 자식으로 props를 통해 전달되는 단방향이다. 그러나 여러 중첩 레벨에 걸쳐 동일한 데이터를 전달해야 하는 경우(예: 테마, 언어 설정, 인증 정보 등) 이 방식은 번거로워진다. Context API는 이런 \"prop drilling\" 문제를 해결하기 위한 도구다.\n\nReact 공식 문서에서도 Context는 \"컴포넌트 트리를 통해 데이터를 명시적으로 전달하지 않고도 공유할 수 있는 방법\"이라고 설명한다. 여기서 핵심은 \"데이터 공유\"이지 \"상태 관리\"가 아니다.\n\n위 그림에서 currentValue는 뭔지 valueStack은 무엇인지 복잡해보이는 Context 구조에 의문이 들 수 있다. 왜 내가 이런 형태의 그림을 그렸는지는 함께 Context API의 세부 구현을 뜯어보다보면 알게 될거라 생각한다.\n\n시나리오로 살펴보는 Context API의 동작 원리\n\nContext API의 내부 동작을 이해하기 위해 실제 시나리오를 통해 단계별로 살펴보자. 아래와 같은 간단한 카운터 예제를 기준으로 설명하겠다:\n\nimport {createContext, useContext, useState} from 'react'\n\n// 1. Context 생성\nconst CounterContext = createContext<{\n  count: number;\n  setCount: React.Dispatch<React.SetStateAction<number>>;\n} | null>(null);\n\n// 2. 중첩된 카운터 컴포넌트\nconst NestedCounter = () => {\n  const context = useContext(CounterContext);\n  \n  if (!context) {\n    throw new Error(\"Context must be used within a Provider\");\n  }\n  \n  const { count, setCount } = context;\n  \n  return (\n    <div>\n      <h2>Nested Counter</h2>\n      <p>Count: {count}</p>\n      <button onClick={() => setCount(count + 1)}>+</button>\n      <button onClick={() => setCount(count - 1)}>-</button>\n    </div>\n  );\n};\n\n// 3. 메인 카운터 컴포넌트\nconst Counter = () => {\n  const context = useContext(CounterContext);\n  const [localCount, setLocalCount] = useState(20);\n  \n  if (!context) {\n    throw new Error(\"Context must be used within a Provider\");\n  }\n  \n  const { count, setCount } = context;\n  \n  return (\n    <div>\n      <h1>Main Counter</h1>\n      <p>Count: {count}</p>\n      <button onClick={() => setCount(count + 1)}>+</button>\n      <button onClick={() => setCount(count - 1)}>-</button>\n      \n      {/* 중첩된 Provider */}\n      <CounterContext.Provider value={{\n        count: localCount,\n        setCount: setLocalCount\n      }}>\n        <NestedCounter />\n      </CounterContext.Provider>\n    </div>\n  );\n};\n\n// 4. 앱 컴포넌트\nfunction App() {\n  const [count, setCount] = useState(0);\n  \n  return (\n    <CounterContext.Provider value={{count, setCount}}>\n      <Counter />\n    </CounterContext.Provider>\n  );\n}\n\n이제 이 코드가 실행될 때 내부적으로 어떤 일이 일어나는지 순서대로 살펴보자.\n\n1단계: createContext 호출 시점\nconst CounterContext = createContext<{\n  count: number;\n  setCount: React.Dispatch<React.SetStateAction<number>>;\n} | null>(null);\n\ncreateContext의 내부 구현은 다음과 같다.\n\nexport function createContext<T>(defaultValue: T): ReactContext<T> {\n  // TODO: 두 번째 인자로 사용되던 선택적 'calculateChangedBits' 함수에 대한 경고를 \n  // 미래 사용을 위해 예약해두어야 할까?\n\n  const context: ReactContext<T> = {\n    $$typeof: REACT_CONTEXT_TYPE,\n    // 여러 동시 렌더러를 지원하기 위한 해결책으로,\n    // 일부 렌더러를 primary(주)로, 나머지를 secondary(부)로 분류합니다.\n    // 최대 두 개의 동시 렌더러만 예상됩니다:\n    // - React Native(주)와 Fabric(부)\n    // - React DOM(주)와 React ART(부)\n    // 부 렌더러들은 context 값을 별도의 필드에 저장합니다.\n    _currentValue: defaultValue,\n    _currentValue2: defaultValue,\n    // 단일 렌더러 내에서 현재 context가 지원하는 동시 렌더러 수를 추적합니다.\n    // 예: 병렬 서버 렌더링\n    _threadCount: 0,\n    // 순환 참조를 위한 필드들\n    Provider: (null: any),\n    Consumer: (null: any),\n  };\n\n  if (enableRenderableContext) {\n    context.Provider = context;\n    context.Consumer = {\n      $$typeof: REACT_CONSUMER_TYPE,\n      _context: context,\n    };\n  } else {\n    (context: any).Provider = {\n      $$typeof: REACT_PROVIDER_TYPE,\n      _context: context,\n    };\n    (context: any).Consumer = context;\n  }\n  \n  return context;\n}\n\ncreateContext는 단순하게 Contexct 타입의 리액트 엘리먼트를 생성해 반환한다. 이 과정에서 리액트의 버전에 따라 Provider가 Context 그 자체가 되거나, Consumer가 Context 그 자체가 된다(레거시).\n\n중요한 포인트는 Context 타입의 리액트 요소를 생성해 반환하고, defaultValue를 _currentValue 필드에 저장한다는 것이다. 즉, 요약하면 다음과 같다:\n\nCounterContext 객체가 생성된다.\n_currentValue와 _currentValue2에 기본값 null이 설정된다.\nProvider와 Consumer 속성이 설정된다. (최신 React에서는 일반적으로 enableRenderableContext = true)\n이 시점에서 아직 값이 주입되지 않았다. 단지 Context 객체가 생성되었을 뿐이다.\n\n2단계: 첫 번째 Provider 마운트 시점 (App 컴포넌트)\n<CounterContext.Provider value={{count, setCount}}>\n  <Counter />\n</CounterContext.Provider>\n\nApp 컴포넌트가 렌더링되면서 첫 번째 Provider가 마운트될 때 React는 beginWork 함수에서 updateContextProvider 함수를 호출한다:\n\nfunction updateContextProvider(current, workInProgress, renderLanes) {\n  let context = workInProgress.type;  // CounterContext\n  const newProps = workInProgress.pendingProps;\n  const newValue = newProps.value;    // {count: 0, setCount: function}\n  \n  // Provider 값 설정\n  pushProvider(workInProgress, context, newValue);\n  \n  // 자식 노드 처리\n  const newChildren = newProps.children;\n  reconcileChildren(current, workInProgress, newChildren, renderLanes);\n  return workInProgress.child;\n}\n\n우선 각 변수 및 파라미터에 대해 알아보자:\n\ncurrent: 현재 렌더링 되어있는 Fiber노드(즉, 구버전의 Fiber 노드)\nworkInProgress: 현재 렌더링을 진행하고 있는 Fiber노드(즉, 새버전의 Fiber 노드)\nnewValue: Provider의 value로 전달한 값(count, setCount)\n\n핵심은 pushProvider 함수다:\n\nexport function pushProvider<T>(\n  providerFiber: Fiber,\n  context: ReactContext<T>,\n  nextValue: T,\n): void {\n  if (isPrimaryRenderer) {\n    // 1. 현재 값을 스택에 저장\n    push(valueCursor, context._currentValue, providerFiber);\n    // 2. 새 값으로 업데이트\n    context._currentValue = nextValue;  // {count: 0, setCount: function}\n  } else {\n    // 보조 렌더러 처리 (React Native 등)\n    push(valueCursor, context._currentValue2, providerFiber);\n    context._currentValue2 = nextValue;\n  }\n}\n\nfunction push<T>(cursor: StackCursor<T>, value: T, fiber: Fiber): void {\n  index++;  // 스택 포인터 증가\n  valueStack[index] = cursor.current;  // 이전 값(null)을 스택에 저장\n  cursor.current = value;  // 커서 값 업데이트\n}\n\n보다싶이 valueStack이라는 스택 자료구조에, Provider에서 전달받은 값을 저장하고, Context의 currentValue 값을 새로운 값으로 갱신한다.\n\n이 과정을 통해:\n1. valueStack에 이전 값(null)이 저장된다.\n2. CounterContext._currentValue가 {count: 0, setCount: function}으로 설정된다.\n\n이렇게 Provider는 해당 Context의 현재 값을 설정하고, 이전 값을 스택에 저장하는 역할을 한다.\n\n3단계: 첫 번째 useContext 호출 시점 (Counter 컴포넌트)\nconst context = useContext(CounterContext);\n\nCounter 컴포넌트가 렌더링될 때 useContext 훅이 호출되면, React는 내부적으로 readContext 함수를 호출한다:\n\nexport function readContext<T>(context: ReactContext<T>): T {\n  return readContextForConsumer(currentlyRenderingFiber, context);\n}\n\nfunction readContextForConsumer<T>(\n  consumer: Fiber | null,\n  context: ReactContext<T>,\n): T {\n  // 1. 현재 렌더러에 맞는 값 가져오기\n  const value = isPrimaryRenderer\n    ? context._currentValue  // {count: 0, setCount: function}\n    : context._currentValue2;\n\n  // 2. 컴포넌트와 Context 간의 의존성 등록\n  const contextItem = {\n    context: ((context: any): ReactContext<mixed>),\n    memoizedValue: value,\n    next: null,\n  };\n\n  if (lastContextDependency === null) {\n    // 첫 번째 의존성인 경우\n    lastContextDependency = contextItem;\n    consumer.dependencies = {\n      lanes: NoLanes,\n      firstContext: contextItem,\n    };\n    consumer.flags |= NeedsPropagation;\n  } else {\n    // 추가 의존성인 경우\n    lastContextDependency = lastContextDependency.next = contextItem;\n  }\n  \n  return value;  // {count: 0, setCount: function} 반환\n}\n\n이 과정에서 일어나는 일:\n1. CounterContext._currentValue에서 현재 값({count: 0, setCount: function})을 읽어온다.\n2. Counter 컴포넌트와 CounterContext 간의 의존성이 등록된다.\n3. 이 의존성 정보는 나중에 Context 값이 변경될 때 어떤 컴포넌트를 리렌더링할지 결정하는 데 사용된다.\n\n여기서 중요한 점은 의존성 추적이다. React는 어떤 컴포넌트가 어떤 Context를 사용하는지 추적하여, Context 값이 변경될 때 해당 컴포넌트만 효율적으로 리렌더링할 수 있다. 컨텍스트의 값을 읽는것 자체는 단순히 Context의 _currentValue 값을 반환할 뿐이다.\n\n4단계: 두 번째 Provider 마운트 시점 (Counter 컴포넌트 내부)\n<CounterContext.Provider value={{\n  count: localCount,\n  setCount: setLocalCount\n}}>\n  <NestedCounter />\n</CounterContext.Provider>\n\nCounter 컴포넌트 내부에 중첩된 Provider가 렌더링될 때, 다시 updateContextProvider와 pushProvider 함수가 호출된다:\n\n// pushProvider의 동작\n// 1. 현재 값({count: 0, setCount: function})을 스택에 저장\npush(valueCursor, context._currentValue, providerFiber);\n// 2. 새 값으로 업데이트\ncontext._currentValue = {count: 20, setCount: setLocalCount};\n\n이제 valueStack과 _currentValue의 상태는 다음과 같다:\n\nvalueStack: [null, {count: 0, setCount: function}]\nCounterContext._currentValue: {count: 20, setCount: setLocalCount}\n\n이처럼 중첩된 Provider는 Context 값을 오버라이드하며, 이전 값은 스택에 보존된다.\n\n5단계: 두 번째 useContext 호출 시점 (NestedCounter 컴포넌트)\nconst context = useContext(CounterContext);\n\nNestedCounter 컴포넌트에서 useContext가 호출되면, 다시 readContext 함수가 실행된다:\n\n// readContextForConsumer의 동작\nconst value = isPrimaryRenderer\n  ? context._currentValue  // {count: 20, setCount: setLocalCount}\n  : context._currentValue2;\n\n이 시점에서 CounterContext._currentValue는 가장 가까운 Provider에서 설정한 값인 {count: 20, setCount: setLocalCount}이므로, NestedCounter는 이 값을 사용한다.\n\n동시에 NestedCounter 컴포넌트와 CounterContext 간의 의존성도 등록된다.\n\n6단계: 두 번째 Provider 언마운트 시점\n\nCounter 컴포넌트가 언마운트되거나 리렌더링될 때, 중첩된 Provider도 언마운트된다. 이때 popProvider 함수가 호출된다:\n\nexport function popProvider(context: ReactContext<any>): void {\n  if (isPrimaryRenderer) {\n    pop(valueCursor); // valueStack에서 이전 값 복원\n    context._currentValue = valueCursor.current;\n  } else {\n    pop(valueCursor);\n    context._currentValue2 = valueCursor.current;\n  }\n}\n\nfunction pop<T>(cursor: StackCursor<T>): void {\n  cursor.current = valueStack[index];  // {count: 0, setCount: function}\n  valueStack[index] = null;\n  index--;\n}\n\n이 과정을 통해:\n1. valueStack에서 이전 값({count: 0, setCount: function})을 꺼낸다.\n2. CounterContext._currentValue를 이전 값으로 복원한다.\n3. valueStack의 상태: [null]\n\n이렇게 Provider가 언마운트되면 스택에서 이전 값을 복원하여 Context 값의 계층 구조를 유지한다.\n\nContext의 데이터 구조와 핵심 메커니즘\n\n지금까지 살펴본 시나리오를 바탕으로 Context API의 핵심 메커니즘을 정리해보자.\n\nvalueStack: 중첩된 Provider 관리\n\nReact는 valueStack이라는 배열을 사용하여 중첩된 Provider의 값들을 관리한다:\n\nconst valueStack: Array<any> = [];\nlet index = -1;\n\n이 스택은 LIFO(Last-In-First-Out) 방식으로 작동한다:\n\nProvider가 마운트될 때: 이전 값이 스택에 저장되고, 새 값이 설정된다.\nProvider가 언마운트될 때: 스택에서 이전 값을 꺼내어 복원한다.\n\n이러한 스택 기반 구조 덕분에 중첩된 Provider가 올바르게 동작할 수 있다.\n\n의존성 추적: 링크드 리스트 구조\n\n컴포넌트가 Context를 소비할 때, React는 의존성을 링크드 리스트 형태로 추적한다:\n\nconst contextItem = {\n  context: context,\n  memoizedValue: value,\n  next: null\n};\n\n여러 Context를 사용하는 경우, 이 의존성들은 링크드 리스트로 연결된다:\n\n// 첫 번째 의존성\nlastContextDependency = contextItem1;\nconsumer.dependencies = {\n  firstContext: contextItem1\n};\n\n// 두 번째 의존성\nlastContextDependency = lastContextDependency.next = contextItem2;\n// 결과: contextItem1 -> contextItem2\n\n이러한 의존성 추적 덕분에:\n1. Context 값이 변경될 때 해당 Context를 사용하는 컴포넌트만 리렌더링된다.\n2. 컴포넌트가 여러 Context를 사용해도 모든 의존성을 효율적으로 관리할 수 있다.\n\n결론\n\n나는 Context API를 의존성 주입도구라 생각했다. 다만 이번에 내부 구현을 동작하며 조금은 달리 생각하게 되었다. 어쩌면 전역 변수나, 외부 의존성을 주입해주고, 내가 원하는 범위 만큼의 리액트 라이프 사이클과 동기화 시키며, 사이드 이펙트를 대신 관리해주는 역할로 생각하게 되었다. 그도 그럴게 Provider는 단순히 _currentValue라는 값을 업데이트 하고, 업데이트 히스토리를 관리하는 역할을 하며, useContext는 컴포넌트와 Context간의 의존 관계를 관리하고, 단순히 Context의 _currentValue값을 반환하는 함수이기 때문이다.\n\n다만 valueStack을 통해 Provider의 상태에 따른 적절한 값을 읽을 수 있게 관리하며, linked-list 기반의 의존성 추적을 통해 의존하는 컴포넌트가 적절히 리렌더링 될 수 있도록 해준다. 그렇기에 의존성 주입도구에서 의존성 주입 그 이상의 무언가 라는 관점의 변화가 생긴거 같다.\n\n이게 옳바른 방향인지 아닌지는 아직 잘 모르겠다. 여전히 고민하고 있고, 고민해 봐야 알것만 같다.\n\n최기환\n프론트엔드 개발자\n팔로우\n이전 포스트\nReact의 createPortal 뜯어보기\n8개의 댓글\n댓글 작성\nant\n2025년 4월 6일\n\n좋은글 감사합니다!\n다시 한번 context api를 보게된 글이었어요.\n\n한가지 의견이 있습니다.!\nconst context = useContext(CounterContext);\n이렇게 값을 바로 넣어주는 것 만으로도 의존성을 주입해준다고 생각합니다.\n\n어떻게 보면 헬퍼처럼 보일 수도 있겠지만 props를 통해 값을 주입 받지 않고 useContext를 통해서 값을 주입 받고 있으니 이것만 해도 의존성 주입이라고 생각 합니다.\n\n1개의 답글\n정소윤\n2025년 4월 6일\n\n기환님의 딥다이브 시리즈 잘 읽고 있습니다👍 몇 가지 질문이 있어서 슬쩍 남겨놓겠습니다\n\n중간중간 있는 이미지들은 어떤걸로 만드시는걸까요??\n의존성 주입보다는 추적의 역할이 크기 때문에 전역 변수 헬퍼라고 생각하시는 걸로 이해하면 될까요?\n1개의 답글\n원정\n7일 전\n\n좋은 글 감사합니다!\n저도 최근에 좋은 코드를 보는 습관을 들이려고 오픈 소스를 뜯어보려고 하는데, 너무 어렵더라구요!\n나중에 기회가 된다면 기환님의 깊이 있는 학습법 배우고 싶습니다!👍\n\n혹시 context랑 Provider를 저는 외부에서 선언해서 가져와서 사용하는데, 딱히 이유가 있는 건 아니고 처음 학습하면서 접했던 아티클이 그렇게 사용 중이라서 이렇게 쓰나보다 해서 사용하게 됐는데, 컴포넌트 내부에서 사용하시는 이유가 있으실까요??\n\n1개의 답글\n배성규\n4일 전\n\n좋은 글 쓰시느라 고생하셨습니다~bb\n단순하게 리코일처럼 전역 상태로 쓰는 도구로만 알고있었는데 기환님 글 읽으면서 다시 생각해보는 계기가 되었습니다 ㅎ ㅎ\n\n1개의 답글\n관련 채용 정보\n디웨일\n[인턴] 프론트 엔드 개발자 (React)\n건강한 조직문화를 통한 긍정적 성장을 실현하는 CLAP 서비스에서 프론트 엔드 개발자를 찾습니다. React 경험을 바탕으로 고객 문제 해결을 위한 혁신적인 웹 개발에 함께해요!\n브레이브모바일(숨고,Soomgo)\nFront-end Engineer\n숨고는 1,000만 사용자를 가진 생활 솔루션 마켓플레이스로, 혁신적인 연결을 통해 새로운 가치를 창출하고 있습니다. Front-end 엔지니어로서 Next.js, Typescript를 활용하여 서비스 퀄리티를 높이며, 동료와의 협업을 통해 기술적인 성장을 경험할 수 있습니다.\n컬리\n풀필먼트 프론트엔드 개발자\n컬리는 배송 혁신을 주도하는 풀필먼트 프로덕트에서 React 기반 웹 서비스 개발자로 참여해보세요. 고객과 비용 모두 만족시키는 유연한 시스템 구축으로 여러분의 기술을 현실에 적용할 기회를 제공합니다.",
    "tags": [
      "React"
    ],
    "commentCount": "8"
  },
  {
    "title": "앱 화면 같은 웹뷰 만들기",
    "description": "웹뷰에서 앱처럼 부드러운 화면 전환을 만들기 위해 고민했던 과정들을 적었습니다.",
    "link": "https://velog.io/@jang_expedition/%EC%95%B1-%ED%99%94%EB%A9%B4-%EA%B0%99%EC%9D%80-%EC%9B%B9%EB%B7%B0-%EB%A7%8C%EB%93%A4%EA%B8%B0",
    "author": "부리부리몬의 머니코드 💰",
    "date": null,
    "comments": "2개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/jang_expedition/post/8fb6fc0e-9ab2-418a-8e9e-24572d06bd04/image.jpg",
    "content": "부리부리몬의 머니코드 💰\n로그인\n부리부리몬의 머니코드 💰\n로그인\n앱 화면 같은 웹뷰 만들기\n원정·3일 전\n팔로우\n8\nstack웹뷰\n💰 기 (발단)\n\n지금 하고 있는 사이드 프로젝트는 웹뷰 기반으로, 웹과 앱 모두에서 제공되는 서비스를 만들고 있다.\n웹뷰는 처음이지만, 앱 개발자 분과 메시지 규격도 맞춰가며 나름 재미있게 협업 중이다.\n\n게시글 작성 과정은 제목 -> 이미지 첨부 -> 내용 -> 타입, 카테고리 선택 -> 완료 순서로 구성되어 있다.\n아직 개발 중이지만, 전반적인 기능은 원하는 대로 잘 동작하고 큰 문제 없이 구현되고 있었다.\n하지만 개발하면서 한 가지 아쉬운 점이 있었는데, 앱처럼 화면이 스무스하지 않는 점이었다.\n\n💵 화면 전환이 끊기는 이유\n\n앱처럼 화면이 슬라이딩 되면서 넘어가지 않는 이유는 리액트의 기본 라우팅 방식이 페이지 컴포넌트를 언마운트하고 새로 마운트하기 때문이다.\n\nA 페이지에서 B 페이지로 이동한다고 하면 A 페이지를 언마운트 하고 B 페이지를 마운트 하기 때문에 전환 시에 애니메이션을 넣을 수 없다.\n\n그렇다는 말은 이전 페이지를 갖고 있으면 애니메이션 효과를 넣을 수 있다!\n\n💵 Stackflow\n\n이를 해결하기 위해 고민하다가 당근의 Stackflow를 발견했다.\n오픈 소스를 파보고 싶었지만, 오픈 소스를 읽는 건 왜이리 힘든지...\n일단 구현이 우선이니 깊게 파보는 건 나중에 하고 간단하게 써보고 대략적인 아이디어만 가져오기로 했다.\n\nStackflow는 말 그대로 스택에 페이지 컴포넌트에 해당하는 Activity를 쌓아서 관리한다.\n스택에 A 페이지 위에 B 페이지를 올리기 때문에 A를 유지한 채로 B를 보여줄 수 있기 때문에, 슬라이딩 효과를 넣거나 이전 페이지를 복원할 수도 있다.\n\n💵 Stackflow를 사이드 프로젝트에 적용하기 어려운 점\n\n그러면 Stackflow를 쓰면 해결이 될까?\nStackflow는 리액트 라우터를 대체하는 라이브러리라서 기존 라우터와 병행해서 사용하긴 어렵다.\n이미 프로젝트에 많은 부분(라우터 가드, 프로바이더 등)에서 리액트 라우터를 사용하고 있고, 개인 프로젝트가 아니기 때문에 독단적으로 바꾸기는 어려웠다.\n\n💵 Stackflow 아이디어 가져오기\n\n전체 라우터를 바꾸는 게 아니라, 게시글 작성처럼 하나의 프로세스 안에서만 Stackflow 구조를 흉내내면 되지 않을까?\n게시글 작성 페이지에서 스택을 관리하고 각 단계를 Activity처럼 사용하면 되지 않을까?\n\n그림으로 표현해보면 위와 같다.\n페이지 컴포넌트에서 스택을 관리하고, 스택의 가장 윗 부분의 컴포넌트를 사용자에게 보여준다.\n(물론 공식 문서나, 소스를 자세하게 뜯어본 건 아니라서 틀릴 수도 있다. 아님 말구 ㅋ)\n\n💰 승 (구현 과정)\n\n어떻게 구현해야 할까?\n일단 냅다 훅으로 만들고 보자.\n\nimport { useState } from 'react';\n\ntype Activity = {\n  key: string;\n  element: React.ReactNode;\n};\n\nexport const useStack = () => {\n  const [stack, setStack] = useState<Activity[]>([]);\n\n  const push = (activity: Activity) => {\n    setStack((prev) => [...prev, activity]);\n  };\n\n  const pop = () => {\n    setStack((prev) => prev.slice(0, -1));\n  };\n\n  const init = (activities: Activity[]) => {\n    setStack(activities);\n  };\n\n  const clear = () => {\n    setStack([]);\n  };\n\n  return { stack, push, pop, clear, init };\n};\n💵 Context API로 관리하기\n\n훅으로 만든 다음 적용하려고 보니, 문제가 될 만한 점이 생각났다.\n각 페이지에서 다음 또는 이전을 눌러서 이동할 때 push, pop 메서드를 사용해야 한다.\n\n페이지 컴포넌트와 Activity는 한 뎁스 차이라서 props로 넘겨줘도 괜찮을 것 같지만, 만약 Activity가 추가된다면 매번 props에 push와 pop을 받을 수 있게 처리해야 한다.\nprops 두 개 쯤은 상관없을 수도 있지만, 스스로 생각해낸게 기특해서 이 악물고 ContextAPI를 사용했다.\nContextAPI를 써도 어차피 페이지에서 매번 호출해야 되긴 하지만 구조가 훨씬 깔끔해진다.\n\nimport { createContext, useContext } from 'react';\nimport { Activity } from '@/types';\n\nexport interface StackStateContextType {\n  stack: Activity[];\n}\n\nexport interface StackActionContextType {\n  push: (activity: Activity) => void;\n  pop: () => void;\n  clear: () => void;\n  init: (activities: Activity[]) => void;\n}\n\nexport const StackStateContext = createContext<StackStateContextType | undefined>(undefined);\nexport const StackActionContext = createContext<StackActionContextType | undefined>(undefined);\n\nexport const useStackStateContext = () => {\n  const state = useContext(StackStateContext);\n  if (state === undefined) {\n    throw new Error('useStackStateContext must be used within an StackStateContextProvider');\n  }\n  return state;\n};\n\nexport const useStackActionContext = () => {\n  const actions = useContext(StackActionContext);\n  if (actions === undefined) {\n    throw new Error('useStackActionContext must be used within an StackActionContextProvider');\n  }\n  return actions;\n};\nimport { StackActionContext, StackStateContext } from '@/hooks';\nimport { Activity } from '@/types';\nimport { useMemo, useState } from 'react';\nimport { Outlet } from 'react-router-dom';\n\nexport const StackContextProvider = () => {\n  const [stack, setStack] = useState<Activity[]>([]);\n\n  const push = (activity: Activity) => {\n    setStack((prev) => [...prev, activity]);\n  };\n\n  const pop = () => {\n    setStack((prev) => prev.slice(0, -1));\n  };\n\n  const init = (activities: Activity[]) => {\n    setStack(activities);\n  };\n\n  const clear = () => {\n    setStack([]);\n  };\n\n  const stateValue = useMemo(() => ({ stack }), [stack]);\n  const actionValue = useMemo(() => ({ push, pop, clear, init }), [push, pop, clear, init]);\n\n  return (\n    <StackStateContext.Provider value={stateValue}>\n      <StackActionContext.Provider value={actionValue}>\n        <Outlet />\n      </StackActionContext.Provider>\n    </StackStateContext.Provider>\n  );\n};\n\n이제 각 페이지들을 스택에서 관리해보자.\n\n💵 애니메이션 겹쳐보이는 문제\n\n먼저 스택에 내용이 바뀔 때, 즉 페이지가 전환될 때 애니메이션을 보여줄 수 있는 컴포넌트를 먼저 작성했다.\n아마 Stackflow에서 AppScreen이 이 역할을 하는 컴포넌트가 아닐까 싶다.\n\nimport { useStackStateContext } from '@/hooks';\n\nexport const StackRenderer = () => {\n  const { stack } = useStackStateContext();\n\n  return (\n    <div className=\"w-full min-h-screen relative overflow-hidden\">\n      {stack.map((activity, i) => (\n        <div\n          key={activity.key}\n          className=\"absolute top-0 left-0 w-full h-full transition-transform duration-300\"\n          style={{\n            transform: `translateX(${(i - stack.length + 1) * 100}%)`,\n            zIndex: i,\n          }}\n        >\n          {activity.element}\n        </div>\n      ))}\n    </div>\n  );\n};\n\n스택에 여러 페이지가 쌓여 있을 때 어떻게 마지막 페이지를 사용자에게 보여줄 수 있을까?\n여기서 핵심은 (i - stack.length + 1) * 100 이 부분이다.\n이 수식이 스택의 가장 마지막 요소를 translateX(0%)로 만들어, 화면의 중심에 오도록 한다.\n\n만약 스택에 페이지가 하나만 있다면, 보여줘야 할 페이지 인덱스는 0이고, (0 - 1 + 1) * 100이 되어 0이 된다.\n스택에 두 페이지가 있고, 두 번째 페이지를 보여줘야 된다면?\n(1 - 2 + 1) * 100으로 translateX(0%)가 된다.\n\n스택의 모든 페이지를 렌더링하기 때문에, 이전 페이지를 갖고 있고, 현재 보여질 페이지를 보여주면서 이전 페이지를 슬라이딩하게 넘길 수 있다.\n\n추가로 'Provider에 한 번에 작성하면 되지 않을까?'라는 고민도 했었는데, Provider는 스택의 상태를 제공해주는 역할이고 Renderer는 애니메이션 효과를 주는 역할로, 서로의 역할이 다르다고 생각해서 분리했다(이렇게 생각한 나 자신 조금 뿌듯쓰).\n\nconst CommunityPostPage = () => {\n  const { push, pop, init } = useStackActionContext();\n  const { setFile } = useCommunityFormActionContext();\n\n  const handleAlbumDataFromRN = (event: MessageEvent) => {\n    // RN에서 앨범 데이터를 받아 처리하는 함수\n  };\n\n  const handleWebFileSelection = () => {\n    // 웹에서 파일 선택을 처리하는 함수\n  };\n\n  const handleImageSelection = () => {\n    // RN과 웹 환경에 따라 적절한 이미지 선택 방식을 처리하는 함수\n  };\n\n  useEffect(() => {\n    const getActivity = (key: string): Activity => {\n      switch (key) {\n        case 'write':\n          return {\n            key: 'write',\n            element: <Write onNext={() => push(getActivity('title'))} />,\n          };\n        case 'title':\n          return {\n            key: 'title',\n            element: (\n              <Title\n                onNext={() => {\n                  handleImageSelection();\n                  push(getActivity('description'));\n                }}\n                onExit={() => pop()}\n              />\n            ),\n          };\n        case 'description':\n          return {\n            key: 'description',\n            element: <Description onNext={() => push(getActivity('preview'))} onExit={() => pop()} />,\n          };\n        case 'preview':\n          return {\n            key: 'preview',\n            element: <Preview onNext={() => push(getActivity('complete'))} onExit={() => pop()} />,\n          };\n        case 'complete':\n          return {\n            key: 'complete',\n            element: <Complete />,\n          };\n        default:\n          throw new Error(`Unknown activity key: ${key}`);\n      }\n    };\n\n    init([getActivity('write')]);\n\n    const handlePopState = () => {\n      pop();\n    };\n\n    window.addEventListener('popstate', handlePopState);\n    window.addEventListener('message', handleAlbumDataFromRN);\n    window.history.replaceState({ step: 0 }, '', window.location.href);\n\n    return () => {\n      window.removeEventListener('message', handleAlbumDataFromRN);\n      window.removeEventListener('popstate', handlePopState);\n    };\n  }, []);\n\n  return <StackRenderer />;\n};\n\nexport default CommunityPostPage;\n\n페이지 컴포넌트가 렌더링 되면 스택에 첫 번째 페이지에 해당하는 컴포넌트를 스택의 초기값으로 넣어준다.\n그리고 각 페이지 별로 다음 화면에 넘어갈 때 getActivity(\"다음 페이지 key값\")을 호출하여 페이지를 이동한다.\n\n적용하면 위와 같이 페이지 전환 시에 애니메이션이 발생한다.\n하지만 문제가 있다.\n다음 화면으로 넘어갈 때, 이전 화면은 좌측으로 넘어가는 애니메이션이 발생하지만 그 위에 현재 페이지가 바로 나와 애니메이션이 무색해진다.\n쉽게 설명하면, 이전 페이지는 슬라이딩 애니메이션이 들어가지만, 다음 페이지는 애니메이션 없이 떨어진다.\n\n💵 현재 페이지에 애니메이션 넣기\n\n이 문제를 해결하려면 다음 페이지에 애니메이션 효과를 넣어줘야 한다.\n다시 translateX를 결정하는 수식을 보면서 생각해보면, 이전 페이지는 0% -> -100%가 되면서 슬라이딩 효과가 발생한다.\n하지만 다음 페이지는 0%로 고정이 되기 때문에 슬라이딩 효과없이 떨어지는 것이다.\n\n그러면 마지막 페이지, 즉 보여지고 싶은 페이지를 100% -> 0%로 되게끔 변경해주면 될까?\n그럴경우 push에는 대응할 수 있을 것 같은데, pop에는 대응할 수 없다.\n\n사용자가 뒤로 가기를 눌러서 pop이 실행될 경우, 스택에서는 현재 페이지가 없어진다.\n그러면 전 페이지를 보여줘야 하는데, 이게 스택의 마지막이므로 오른쪽에서 등장하게 된다.\n뒤로 가기를 눌렀는데, 페이지가 오른쪽에서 등장하면 좀 당황스러울 것 같지 않나?\n\n뭐 머리로만 생각한 거라서 실제 구현해보면 조금 다를 수도 있다.\n아무튼 pop이 대응 안 된다고 생각했는데, 그러면 어떻게 할 수 있을까?\n\nexport type TransitionState = 'current' | 'animating';\nexport type TransitionDirection = 'left' | 'right';\n\nexport interface Activity {\n  key: string;\n  element: React.ReactNode;\n  transition: TransitionState;\n  direction: TransitionDirection;\n}\n\n먼저 Activity가 상태를 갖도록 설정했다.\n저렇게 타입을 선언하기까지 많은 우여곡절이 있었지만... 결론만 말하면 저렇다.\n\nTransitionState는 사용자에게 보여지는 페이지를 current로, 움직이거나 움직인 페이지를 animating으로 정했다.\n\n음... TMI로 우여곡절을 좀 설명하면, push될 때, pop될 때 상태를 따로 두다가 굳이 분리해야 되나 싶어서 하나로 합쳤다.\n\n하지만 이미 움직인 상태와 움직이고 있는 상태가 모두 animating이라는 상태로 관리되는 게 이상하다고 생각했다.\nanimating이라고 하면 움직이고 있는 상태라고 생각이 들기 때문이다.\nexited라는 상태를 둬서 구분을 해볼까 했지만, 움직인 이후에 상태를 바꿔줘야 하는 로직을 추가해야 하기 때문에 오히려 로직이 복잡해질 것 같아서 제외했다.\n\nconst push = (activity: Omit<Activity, 'transition' | 'direction'>) => {\n  const newActivity: Activity = {\n    ...activity,\n    transition: 'animating',\n    direction: 'right',\n  };\n\n  setStack((prev) => [...prev, newActivity]);\n\n  requestAnimationFrame(() => {\n    setStack((prev) =>\n             prev.map((item, i) =>\n                      i === prev.length - 1\n                      ? { ...item, transition: 'current' }\n                      : item.transition === 'current'\n                      ? { ...item, transition: 'animating', direction: 'left' }\n                      : item\n                     )\n            );\n  });\n};\n\nconst pop = () => {\n  setStack((prev) => {\n    const newStack = [...prev];\n    const current = newStack[newStack.length - 1];\n    const prevPage = newStack[newStack.length - 2];\n\n    if (current) {\n      current.transition = 'animating';\n      current.direction = 'right';\n    }\n    if (prevPage) {\n      prevPage.transition = 'animating';\n      prevPage.direction = 'left';\n    }\n\n    return newStack;\n  });\n\n  requestAnimationFrame(() => {\n    setStack((prev) =>\n             prev.map((item, i) =>\n                      i === prev.length - 2 && item.transition === 'animating' ? { ...item, transition: 'current' } : item\n                     )\n            );\n  });\n\n  setTimeout(() => {\n    setStack((prev) => prev.slice(0, -1));\n  }, 300);\n};\n\nconst init = (activities: Omit<Activity, 'transition' | 'direction'>[]) => {\n  if (activities.length === 0) {\n    setStack([]);\n    return;\n  }\n\n  const newStack = activities.map((activity, i) => {\n    const isLast = i === activities.length - 1;\n    return {\n      ...activity,\n      transition: isLast ? ('current' as TransitionState) : ('animating' as TransitionState),\n      direction: isLast ? ('right' as TransitionDirection) : ('left' as TransitionDirection),\n    };\n  });\n\n  setStack(newStack);\n};\n\nProvider 쪽의 코드도 바꿔줬다.\n중요하게 볼 점은 push, pop이다.\n\n공통적으로 requestAnimationFrame을 사용한다.\n사용하는 이유는\n\nsetStack((prev) => [...prev, newActivity]);\n\nsetStack((prev) =>\n         prev.map((item, i) =>\n                  i === prev.length - 1\n                  ? { ...item, transition: 'current' }\n                  : item.transition === 'current'\n                  ? { ...item, transition: 'animating', direction: 'left' }\n                  : item\n                 ));\n\n만약 requestAnimationFrame 없이 위와 같이 사용된다면 리액트의 Batching으로 마지막 상태만 화면에 반영된다.\n상태가 동적으로 변함에 따라 애니메이션이 구현되어야 하는데, 상태가 바뀌지 않아서 원하는 대로 동작하지 않게 된다.\n\nrequestAnimationFrame은 브라우저가 다음 프레임을 그리기 직전에 콜백을 실행하기 때문에, 애니메이션 시작 시점을 명확하게 분리할 수 있다.\n\n추가로 pop에서는 나간 페이지에 애니메이션을 보여준 뒤 스택에서 없애기 위해 setTimeout을 활용했다.\n\nimport { useStackStateContext } from '@/hooks';\nimport clsx from 'clsx';\n\nexport const StackRenderer = () => {\n  const { stack } = useStackStateContext();\n\n  return (\n    <div className=\"w-full min-h-screen relative overflow-hidden\">\n      {stack.map((activity, i) => {\n        const { transition, direction } = activity;\n\n        const translateClass =\n          transition === 'animating'\n            ? direction === 'right'\n              ? 'translate-x-full'\n              : '-translate-x-full'\n            : 'translate-x-0';\n\n        return (\n          <div\n            key={activity.key}\n            className={clsx(\n              'absolute top-0 left-0 w-full h-full',\n              'transition-transform duration-300 ease-in-out',\n              translateClass,\n              transition === 'animating' ? 'pointer-events-none' : 'pointer-events-auto',\n              `z-[${i}]`\n            )}\n          >\n            {activity.element}\n          </div>\n        );\n      })}\n    </div>\n  );\n};\n\nRenderer에서 현재 상태에 따른 translateX 값을 동적으로 넣어 애니메이션 효과가 보이도록 했다.\n\n적용 결과를 보면 원하는 대로 앱처럼 넘어가는 웹 화면이 구현됐다.\n\n💰 전결 (마무리 ㅋ)\n\n추가적으로 해결해야 하는 문제들이 있다.\n새로고침 시에 현재 페이지를 유지하게 한다거나(로컬 스토리지에 저장하면 될듯?!), 뒤로 가기에 반응 한다거나(push, pop 시에 popstate를 넣어주면 될듯?!) 등.\n\n그리고 현재는 getAcitivity 함수 내부에 스택에 보여질 페이지들이 명시적으로 적혀있지만, 훅으로 빼서 사용하는 쪽에서 추가하도록 개선할 수도 있을 것 같다.\n\n이 내용들을 전에 담고 결로 회고를 쓰려고 했지만, 길어지니 힘도 빠지고 주제에 벗어나는 것 같아서 그건 그냥 내가 따로 해보기로 했다.\n\n아무튼 기존 라이브러리에서 아이디어를 얻어서 생각나는 대로 구현해보니, 구현 과정에서 생각과 다른 점들도 많고, 미처 고려하지 못한 상황들도 나왔지만 구현하는 과정이 재밌었다.\n\n원정\n팔로우\n이전 포스트\nTCP/IP\n2개의 댓글\n댓글 작성\nant\n3일 전\n\n기승전결로 나눠주셔서 이해하기 너무 좋았습니다.\n라우터 구현하신 것도 잘 추상화 하신거 같아요\n\n1개의 답글\n관련 채용 정보\n정리습관\n프론트엔드개발자(0~5년)\nAI 기반 정리습관 서비스의 프론트엔드 개발자를 모집합니다. React.js 및 Next.js 경험을 활용해, 고객 맞춤형 공간 정리 솔루션을 함께 설계해보세요!\n현대오토에버\n[FE Engineering] 개발/운영 및 Governance 체계 수립 - Frontend Engineer\n현대오토에버에서 완성차 운영 서비스를 개발하며 프론트엔드 기술 거버넌스를 수립할 기회를 잡아보세요. JavaScript와 React 등의 전문성을 발휘할 수 있는 창의적인 환경이 여러분을 기다리고 있습니다.\n두어스\n프론트엔드 엔지니어\n크리에이터와 브랜드를 연결하는 혁신적인 마케팅 플랫폼, 지비지오에서 프론트엔드 엔지니어를 모집합니다. React Native와 NextJS를 활용한 유저 경험 극대화에 집중하며, 지속 가능한 성장을 추구하는 팀에 합류해보세요!",
    "tags": [
      "stack",
      "웹뷰"
    ],
    "commentCount": "2"
  },
  {
    "title": "결혼식 사진을 XXX 스타일로 바꿔줘",
    "description": "링크메리 모바일 청첩장 서비스에 요즘 유행하는 XXX 스타일로 바꿔줘 기능을 넣어보자!",
    "link": "https://velog.io/@yeseong0412/%EA%B2%B0%ED%98%BC%EC%8B%9D-%EC%82%AC%EC%A7%84%EC%9D%84-XXX-%EC%8A%A4%ED%83%80%EC%9D%BC%EB%A1%9C-%EB%B0%94%EA%BF%94%EC%A4%98-f3ozbqsx",
    "author": "나는 세상을 조금 더 나은 곳으로 바꿀꺼야",
    "date": "2025년 4월 2일",
    "comments": "6개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/yeseong0412/post/93696123-9c4c-4ef4-a042-346e1f5dbecf/image.png",
    "content": "나는 세상을 조금 더 나은 곳으로 바꿀꺼야\n로그인\n나는 세상을 조금 더 나은 곳으로 바꿀꺼야\n로그인\n결혼식 사진을 XXX 스타일로 바꿔줘\n양예성·2025년 4월 2일\n팔로우\n20\nchatGPT링크메리모바일 청첩장\nLinkmarry\n목록 보기\n2/2\n들어가며\n\n링크메리 서비스를 리뉴얼 하며 서비스에 많은 변화가 있었다.\n기존에 MVP 버전에서 세웠던 가설이 실패함에 따라 방향성을 틀기로 하였고 디자인, 기능 개선 후 다시 서비스를 제공하려고 한다. (사실 말만 다시 제공이지 아직 서비스는 제공하고 있다)\n\n그래서 이번엔 리뉴얼 하며 바뀐 부분과 신규 기능에 대하여 여러분들의 피드백을 받고자 이 글을 작성하게 되었다.\n\n(사실 바이럴임)\n\n링크메리?\n\n고딩들이 만든 모바일 청첩장 사이트 글을 안보신 분들은 우리가 어떤 서비스를 제공하는지 모를 것이다.\n\n우리는 특별한 순간 특별한 초대, 링크메리와 함께라는 목표하에 다양한 디자인과 간편한 청첩장 제작 서비스를 제공하고 있다.\n\n실제로 600명 정도의 사용자들이 1달만에 방문을 했고 (광고 X 오로지 Velog, 검색등..)\n어느정도 서비스에 대한 검증이 되었다 생각하여 리뉴얼을 하게 되었다.\n\n(서비스 포트폴리오도 만들었다. 2025 AI Expo 참가용 포트폴리오긴 하지만)\n\n서비스 리뉴얼?\n\n사실 MVP 버전은 사용자 호응이 있나 판별하기 위하여 많이 제작하는데\n한달만에 빠르게 사용 가능할 정도(거의 프로프로프로토타입으로 만들었음) 만들고\n반응이 있어서 리뉴얼 하기로 결정하였다.\n\n(리뉴얼 된 에디터 모습)\n\n가장 큰 차이점은 아무래도 청첩장 제작 에디터 부분에 변경이 많이 되었고 전체적인 디자인 디테일 수정도 리뉴얼 버전에선 하게 되었다.\n\n사실 이렇게 보면 잘 모른다.\n그러니 당장 세상에서 가장 간편한 청첩장 에디터를 사용해봐라!\n\n(여기에요)\n\n추가 프리뷰 디자인(템플릿)도 있고, 온보딩 뷰도 변경되었다.\n\n모청 예시 링크\n\n결혼식 사진을 XXX으로 바꿔줘\n\n사실 오늘 제목으로 어그로끈 신규 기능이다.\n\n바로 요즘 바이럴 중인 지브리, 짱구, 심슨.... 스타일로 커플 사진 바꿔줘! 이다.\n\n어느날 팀원 중 한명의 친구가 릴스를 보냈다.\n신규 업데이트로 극한의 그림을 생성할 수 있도록 바뀐 지피티로 XXX 스타일로 사진 바꿔줘 릴스를 보냈다.\n\n이걸 보고 별 생각없이 오~ 좋은데! 답장을 보내고 별 생각이 없었다.\n\n근데 갑자기 생각하니까 꽤 괜찮은 기능 같아 보였다.\n\n바로 개발 할 수 있는지 GPT API 사이트로 찾아가 문서를 읽어보기 시작했다.\n\n하지만 어림도 없지... GPT4o 신규 버전의 API 는 제공하지 않고 있었고 포럼에선 2~3주 뒤에 릴리즈 계획이란 (카더라) 통신이 있었다.\n\n이대로 포기할 순 없었고, 비슷한 기능을 제공중인 구글 Gemini에도 기능이 있는지 찾아보았다.\n\nGemini 2.0 flash 에서 이미지 생성 기능을 제공해서 이걸로 한번 기능을 구현해보고자 했다.\n\n인생은 실전이야 친구야.\n\n빠르게 프롬포트 몇번 건들고 사진 넣고 돌려봤다.\n\n뭔가.... 많이 아쉽다.............하......\n\nGPT 대비 Gemini 의 이미지 생성 기능이 조금 많이 부족했다. 그래서 최대한 프롬포트로 살려보려 노력했고.\n\n깎고 또 깎아서 겨우 어느정도 봐줄만한 결과를 뽑았다.\n\n(지브리 스타일로 그려달라함)\n\n에디터에 AI 이미지 변환 기능을 넣고 출시를 하려고 하는데.... 문제가 있다.\n\n사실 아직 ChatGPT-4o 만큼의 변경 성능을 못낸다.\n\n프롬포트도 결국 사용자 입력값에 따라 결과값이 달라지기 때문에 사용자가 만족할만한 이미지를 얻을 수 있을지 미지수이다....\n\n그래서 여러분들의 도움을 받으려한다.\n\n여러분들의 의견은 어떤가요?\n\n사실 완벽한 제품을 늘 출시할 순 없다.\n\n하지만 시장에서 사랑받지 못하는 제품을 출시하는건 어쩌면 시장을 외면하는 짓이 아닐까?\n\n고로 이번 글이 인기를 얻는다면 빠르게 이미지 변환 서비스를 탑제한 링크메리 리뉴얼을 제공하고자 한다.\n\n(사실 2주 뒤면 다 해결되는 문제긴 함...ㅋㅋ Gemini -> GPT-4o)\n\n그래서 말인데요...\n\n형 누나 이모 삼촌\n\n댓글로 의견 남겨주시면 안돼요?\n\n감사합니다 ㅎㅎㅎㅎㅎㅎㅎ\n\nETC\n\n빠르게 가설을 실행하고 검증하기\n\n저번 글에 남겼던 내 가설과 결과를 남기고자 한다.\n\n내 가설은 모바일청첩장을 준비하는 시점은 결혼 3~5개월 전일 것이고, 그전에 우리가 미완성된 기능들을 완성한다면, 이미 구매한 사람은 수정이 가능하고 수정 후 결혼 1~2달전에 모청을 뿌릴꺼니 지금 있는 기본 기능들로만 MVP를 구성하고 배포를 해도 사람들이 사용해 줄 것 이라고 생각하였다.\n\nMVP라 부르지만 타 서비스에서 제공하는 기본기능들과 우리의 기본기능들은 모두 존재하기 때문이다.\n\n반은 맞고, 반은 틀렸다.\n\n사용자들은 완벽한 서비스를 좋아한다.\n모바일 청첩장 같은 인생에 어쩌면 단 한번뿐인 기회에선 더더욱 검증된 서비스를 사용하고 싶어한다.\n\n고로 가설은 수정되여야 한다.\n\n사용자들이 좋아하는 서비스를 만들자. 라고\n\n양예성\n팔로우\n이전 포스트\n고딩들이 만든 모바일 청첩장 서비스\n6개의 댓글\n댓글 작성\n김건우\n2025년 4월 2일\n\n지브리 말고 다른 버전들도 추가되면 좋을 것 같네요, 잘 봤습니다.\n\n1개의 답글\n박재민\n2025년 4월 2일\n\n멋있어요! ' \"___ 스타일\" 형식으로 입력해 주세요 ' 외에도 해시태그처럼 유저에게 특정 키워드를 추천해주는 방식도 괜찮아 보입니다ㅏ\n\n1개의 답글\n관련 채용 정보\n미리디\n[미리캔버스] 백엔드 개발자\n디자인 생태계를 혁신하는 미리디에서 전세계 사용자에게 더 나은 디자인 경험을 제공하는 백엔드 개발자를 찾습니다. Java, Spring, AWS 기술과 함께 글로벌 서비스 최적화, AI 추천 시스템 개발에 참여하며 성장할 수 있는 기회를 놓치지 마세요.\n씨디알아이(CDRI)\n백엔드 개발자\nCDRI는 화장품 인증을 위한 혁신적인 솔루션 'CERTICOS'를 개발하여 B2B 서비스를 통해 브랜드사의 성공을 지원합니다. Java Springboot 및 AI 통합 개발 경험이 있는 백엔드 개발자를 찾으며, 유연한 근무 환경과 성장 지원으로 함께할 미래를 기대합니다.\n넷마블\n플랫폼 백엔드 개발자\n넷마블에서 글로벌 인증 서비스 개발로 재미있는 게임 생태계를 만들어갑니다. Java 및 Spring 관련 경험이 있는 개발자를 찾으며, 탄탄한 기술력으로 전세계 사용자에게 즐거움을 선사하는 기회를 놓치지 마세요!",
    "tags": [
      "chatGPT",
      "링크메리",
      "모바일 청첩장"
    ],
    "commentCount": "6"
  },
  {
    "title": "접속 대기열 시스템과 실시간 통신",
    "description": "인터파크는 어떻게 수만 명을 줄 세우는 걸까?",
    "link": "https://velog.io/@saewoohan/%EC%A0%91%EC%86%8D-%EB%8C%80%EA%B8%B0%EC%97%B4-%EC%8B%9C%EC%8A%A4%ED%85%9C%EA%B3%BC-%EC%8B%A4%EC%8B%9C%EA%B0%84-%ED%86%B5%EC%8B%A0",
    "author": "saewoo.log",
    "date": "2025년 4월 5일",
    "comments": "0개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/saewoohan/post/19bbf8ee-9073-4b84-8cc2-76cca8a4659b/image.png",
    "content": "saewoo.log\n로그인\nsaewoo.log\n로그인\n접속 대기열 시스템과 실시간 통신\nsaewoohan·2025년 4월 5일\n팔로우\n25\nredissorted set대기열 시스템시스템 디자인실시간 통신\n시스템 디자인\n목록 보기\n3/4\n\n얼마 전, 야구 직관을 위해 예매를 하려고 인터파크에 접속한 적이 있었습니다. 예매 오픈 시간과 동시에 수많은 사용자가 한꺼번에 몰렸고, 화면에는 “현재 대기자 수는 12,123명이며, 당신은 8,432번째입니다”라는 메시지가 떠 있었습니다. 이 순간 문득 궁금해졌습니다.\n\n“인터파크는 어떻게 수만 명의 사용자에게 실시간으로 순번을 매기고, 순서대로 입장시킬 수 있을까?”\n\n이러한 대기열 시스템은 단순히 누가 먼저 왔는지를 판별하는 것 뿐 아니라, 예약 화면에 한꺼번에 입장시키지 않고 순차적으로 진입을 제어하면서, 대기 중인 사용자에게는 실시간으로 “당신은 몇 번째입니다”라는 정보를 제공해야 합니다. 이러한 시스템은 일반적으로 작성하는 API 구조로는 불가능한 복잡한 구조를 가지고 있을 것 이라고 생각이 들었습니다.\n\n그럼 차라리 그냥 모두를 한꺼번에 예약 화면으로 들이면 되지 않을까? 라고 생각할 수도 있는데, 오히려 그 방식이 더 큰 문제를 일으킵니다. 모든 사용자가 동시에 입장해서 예약을 시도하게 되면 서버는 엄청난 양의 동시 요청을 감당해야 하고, 같은 좌석을 여러 명이 동시에 클릭하는 상황이 벌어져 중복 처리, 충돌 방지, 트랜잭션 롤백 같은 복잡한 동시성 제어가 필요해집니다.\n\n즉, 인터파크 티케팅처럼 한 시점에 접속하는 예약 시스템에서 진짜 핵심은 예약을 처리하는 것이 아니라, 그 예약 요청을 알맞게 줄세우고 안정적으로 처리할 수 있도록 도와주는 “예약 대기열 시스템”에 있다는 생각이 들었습니다. 요청을 전부 즉시 처리하려고 애쓰는 대신, 일단 순서를 정리해서 대기열에 저장하고, 정해진 인원만 예약 화면에 들여보내는 구조가 꼭 필요한 것입니다.\n\n그래서 저는 이런 구조를 실제로 어떻게 구현할 수 있을지 궁금해졌고, 동시 예약 대기열 시스템을 직접 간단하게 구현해보면서 실험해 보기로 했습니다.\n\n대기열 자료구조\n\n안정적인 동시 예약 시스템을 구현하려면 클라이언트의 요청을 즉시 처리하는 것이 아니라 대기열에 차곡차곡 모아두어야 합니다. 이때, 대기열이 필요할 기능은 다음과 같습니다.\n\n요청을 순서대로 대기열에 저장\n각 유저는 자신이 몇 번째 순위인지 알 수 있어야함\n대기열에 저장된 순서대로 가능한 자원의 수 만큼 대기열을 처리\n\n즉, 대기열 시스템은 예약 시도 자체를 조절해야 하는 시스템입니다. 즉, 요청을 순서대로 정리하고, 그 순서에 따라 일부 사용자만 예약 화면에 진입할 수 있도록 제어해야 합니다.\n\n이를 통해 도출한 전체적인 흐름은 아래와 같습니다.\n\n클라이언트는 요청을 보내기만 하고, 서버는 이 요청들을 대기열에 저장해두었다가, 순차적으로 꺼내서 참가열로 이동시켜 예약 기회를 부여하는 방식입니다. 이렇게 하면 서버 부하를 줄이면서도, 요청 순서에 따라 공정하게 처리하는 구조를 만들 수 있습니다.\n\n이러한 상황에서 자연스럽게 마주할 고민은, “대기열을 무엇을 사용해서 구현할까?”입니다.\n\nMessage Queue\n\n자연스럽게 Kafka, RabbitMQ, SQS와 같은 메시지 큐 시스템들이 대기열의 후보로 떠올랐습니다.\n\n대용량 메시지 처리에 특화되어 있고, 이미 안정성을 입증받은 구조이기도 했습니다. 하지만 그 메시지 큐가 적절할지 고민하는 과정에서 저는 필요한 기능 중 하나를 떠올렸습니다.\n\n메시지 큐는 “얼마나 많은 요청을 빠르게, 안정적으로 처리할 수 있는가”에 초점이 맞춰져 있습니다. 하지만 예약 대기열 시스템은 사용자가 자신이 몇 번째 대기자인지 확인할 수 있어야 하고, 대기 순서가 정확하게 보장되어야 합니다. 이러한 조건을 메시지 큐 시스템으로 충족시키는 것은 쉽지 않습니다.\n\nKafka나 RabbitMQ는 내부적으로 FIFO 구조를 보장하며 메시지를 순차적으로 처리할 수 있지만, 큐에 들어간 특정 메시지가 지금 큐의 몇 번째에 위치하고 있는지는 확인할 수 없습니다. 즉, 메시지는 큐 안에 존재할 뿐, 그 메시지의 상대적 순위를 클라이언트가 알 수는 없는 구조입니다.\n\n결국 사용자에게 실시간으로 “당신은 현재 243번째입니다”와 같은 피드백을 주는 UI 요구사항과는 어울리지 않습니다.\n\n그리고 결정적으로 Message Queue는 시스템 구축과 운영에 많은 비용이 소요됩니다. 이미 Message Queue를 사용하고 있는 시스템이라면 큰 문제가 되지 않겠지만, 그렇지 않은 상황에서는 많은 시간과 비용을 지출해야합니다.\n\nRedis\n\n가볍고 빠르며, 구조가 단순하고 운영이 쉬운 메시지 처리 방식이 필요했습니다. 여기서 떠오른 것이 바로 Redis였습니다. Redis는 인메모리 기반의 저장소로, 단순한 key-value 저장소 이상의 기능을 제공하는 강력한 도구입니다. 특히 Redis는 다양한 자료구조(List, Hash, Set, Sorted Set 등)를 제공하고 있어, 목적에 따라 다양한 기능을 구현할 수 있습니다.\n\n처음에는 Redis의 List 구조를 사용하는 것이 적절할 것 같다고 생각이 들었습니다. 하지만, 곧 “List로는 특정 사용자가 큐에서 몇 번째인지 빠르게 알 수 없다.”라는 사실을 알았습니다. Redis의 List는 FIFO 구조에는 적합하지만, 특정 값의 위치를 찾는 연산은 O(n)입니다. 수천 명이 동시에 대기하고 있는 상황에서 이 연산을 계속 호출하기에는 성능과 비용 면에서 부담이 클 수밖에 없습니다.\n\n그래서 저는 Redis Sorted Set을 떠올렸습니다.\n\nRedis Sorted Set\n\nRedis의 Sorted Set은 단순한 Set과는 다르게, 각 요소마다 score라는 숫자 값을 함께 저장하고, 이 score를 기준으로 요소들을 자동으로 정렬해주는 자료구조입니다. 구성은 다음과 같습니다.\n\nZADD reservation:queue 1712478912312 user123\nreservation:queue: Sorted Set의 이름\n1712478912312: score, 보통 timestamp를 사용\nuser123: 실제 저장할 값\n\n요소는 삽입 순서가 아닌, score 값을 기준으로 정렬되며, 동일한 값을 다시 넣으려고 하면 덮어쓰기되므로 중복 방지도 자연스럽게 처리됩니다. 또한, ZADD의 시간복잡도는 O(logN)으로 효율적입니다.\n\n그리고 Sorted Set을 사용하면 다음과 같은 명령어를 통해 현재 사용자의 순위를 즉시 계산할 수 있습니다.\n\nZRANK reservation:queue user123\n\n이 명령은 해당 유저가 지금 큐에서 몇 번째인지 알려주며, 시간 복잡도는 O(log N)으로 매우 효율적입니다.\n\n즉, 수천 명이 몰려도 실시간으로 “당신은 538번째입니다”라는 메시지를 안정적으로 제공할 수 있습니다.\n\n결국 이 자료구조를 사용하면 대기열에서 사용자의 순위를 정확하게 확인할 수 있을 뿐만 아니라, 예약 가능 수량을 기준으로 상위 N명만 예약을 확정짓고, 나머지는 제거하거나 대기 상태로 유지하는 흐름도 간단하게 구현할 수 있습니다. 예를 들어, 좌석이 100개라면 다음과 같은 로직으로 동작할 수 있습니다.\n\nZRANGE reservation:queue 0 99  # 상위 100명만 추출\nZREM reservation:queue user123  # 예약 확정 시 제거\n\n처음엔 단순한 큐잉 구조를 고민했지만, 결국 “사용자 피드백”과 “서버 안정성”이라는 두 가지를 동시에 만족시키는 구조를 간단하게 만족시킬 수 있는 것은 Redis Sorted Set이었습니다.\n\n실시간 대기열 피드백?\n\nSorted Set을 사용해 사용자의 대기열을 구성하는 구조를 만든 후, 자연스럽게 다음과 같은 고민을 하였습니다.\n\n“사용자가 자신의 대기 순서가 바뀌었을 때, 그걸 어떻게 실시간으로 알려줘야 할까?”\n\n단순히 요청 시 한 번 응답만 주고 끝내는 구조라면 상관없겠지만, 티케팅 대기열처럼 순위가 수시로 바뀌고, 순위에 따라 예약창에 진입을 하는 구조에서는 사용자에게 실시간으로 상태를 알려주는 기능이 UX의 핵심이 됩니다.\n\n이를 해결하기 위한 실시간 통신 방식은 대표적으로 다음 네 가지가 있습니다.\n\n1. Polling\n\n가장 단순하고, 가장 많이 쓰이는 방식\n\nPolling은 말 그대로 주기적으로 서버에 요청을 보내는 방식입니다.\n\n예를 들어 클라이언트에서 3초마다 서버에 자신의 순위를 요청하는 API를 호출하는 식입니다.\n\nsetInterval(() => {\n  fetch('/api/queue/rank?userId=user123');\n}, 3000);\n\n장점\n\n구현이 매우 간단하고 어디서나 동작합니다.\n별도의 연결 유지가 필요 없어 서버/클라이언트 모두 부담이 적습니다.\n\n단점\n\n순위가 바뀌지 않아도 계속 요청을 보내게 되므로 불필요한 네트워크 사용이 발생합니다.\n실시간성은 약간 떨어지며, 업데이트 주기를 클수록 반응이 늦어집니다.\n\n구현이 가장 쉽고, 정해진 주기로만 업데이트가 필요하다면 Polling으로도 충분합니다.\n\n2. Long Polling\n\nPolling보다는 똑똑하지만, 여전히 한계가 있음\n\nLong Polling은 요청을 보내고, 서버가 이벤트가 생길 때까지 응답을 지연시키는 방식입니다.\n\n이벤트가 발생하면 서버는 응답을 반환하고, 클라이언트는 다시 요청을 보내는 구조입니다.\n\n장점\n\n일반 Polling에 비해 불필요한 요청 수가 줄어듭니다.\n실시간성도 꽤 높습니다.\n\n단점\n\n연결 유지 시간이 길기 때문에, 서버 리소스 사용량이 증가합니다.\n실질적으로는 Polling보다 관리가 어렵고, 상태 복잡도가 높아집니다.\n\n실시간 피드백이 필요한 상황에서는 어느 정도 유효하지만, 대기열처럼 단순한 상태를 주기적으로 조회하는 구조에서는 과한 설계라고 생각이 들었습니다.\n\n3. SSE (Server-Sent Events)\n\n단방향 실시간 알림이 필요하다면 가장 균형 잡힌 선택\n\nSSE는 서버에서 클라이언트로 단방향으로 지속적인 이벤트 스트림을 제공하는 방식입니다.\n\nHTTP 기반으로 동작하며, 연결을 유지한 채 필요할 때만 데이터를 푸시할 수 있습니다.\n\n장점\n\n클라이언트는 한 번만 연결하고, 이후로는 서버가 데이터가 있을 때만 전송하므로 효율적입니다.\nWebSocket보다 간단하게 실시간 통신을 구현할 수 있습니다.\n대부분의 브라우저에서 기본적으로 지원합니다.\n\n단점\n\n단방향이기 때문에 클라이언트에서 서버로의 통신은 별도로 처리해야 합니다.\n브라우저나 프록시 환경에 따라 연결이 끊기는 경우, 재연결 로직이 필요할 수 있습니다.\n\n실시간 피드백이 필요한 상황에서 가볍고 효율적인 구조입니다. 특히 예약 대기열처럼 특정 주기 혹은 상황에서 서버가 클라이언트에게 변화를 알려주면 되는 요구사항에는 잘 맞습니다.\n\n4. WebSocket\n\n진짜 실시간 양방향 통신이 필요할 때\n\nWebSocket은 클라이언트와 서버가 연결을 계속 유지한 채로, 양방향 실시간 통신을 할 수 있는 방식입니다. 실시간 게임, 실시간 채팅, 주식 거래 시스템 등에서 자주 사용됩니다.\n\n장점\n\n실시간성이 가장 뛰어납니다. (데이터가 생기면 바로 전송)\n서버 → 클라이언트, 클라이언트 → 서버 모두 자유롭게 전송 가능\n초당 수십 회 이상의 업데이트가 필요한 경우에도 안정적으로 처리할 수 있습니다.\n\n단점\n\n구현이 복잡하며, 연결 유지와 상태 복구를 위한 코드가 추가로 필요합니다.\n인프라 측면에서도 WebSocket 연결을 처리하기 위한 로드밸런서 설정이나 스케일링 전략이 추가로 필요할 수 있습니다.\n\n실시간 UX가 가장 중요한 경우라면 WebSocket이 최고의 선택이지만, 예약 대기열 시스템에는 과도한 선택처럼 보였습니다.\n\n적합한 통신 방식\n\n제가 만들고 있는 시스템은 실시간 대기열 시스템이지만, 사용자에게 순위가 바뀌었는지 주기적으로 서버에서 클라이언트에게 단방향으로 알려주기만 하면 되는 구조를 가지고 있습니다.\n\n즉, 빠른 실시간 반응보다는 정기적인 상태 피드백이 더 중요했습니다. 그래서 저는 구현이 간단한 Polling과 단방향 실시간 통신에 적합한 SSE 두 가지를 적합한 선택지로 두었습니다.\n\n데모 시스템 구현에서는 제가 이제까지 사용해보지 않은 SSE를 경험삼아 사용해보면 좋을 것 같아 사용해보았습니다.\n\n대기열 시스템 구현\n\n지금까지 Redis Sorted Set 기반 대기열 시스템의 개념과 아키텍처, 통신 방식까지 정리해 보았습니다.\n\n그렇다면 실제로 이러한 구조를 어떻게 구현할 수 있을까요? 이번에는 NestJS 서버와 Redis를 사용하여 이 대기열 시스템을 간단하게 구현해보겠습니다.\n\n전체 데모 코드는 reservation-queue-demo에서 확인하실 수 있습니다.\n\n대기열 진입\n\n우선, 사용자가 /queue/join API를 호출하면, 서버는 Redis의 Sorted Set에 해당 사용자를 저장합니다.\n이때 score로는 Date.now() 값을 사용하므로, 요청이 들어온 시점이 곧 대기열의 순서가 됩니다.\n이렇게 저장된 사용자에 대해서는 ZRANK 명령을 통해 즉시 현재 순위를 조회할 수 있고, 이 결과는 클라이언트에 전달되어 “현재 당신은 83번째입니다”와 같은 메시지를 표시하게 됩니다.\n\n이러한 연산들을 보다 원자적으로 처리하고 싶다면 Redis의 Lua 스크립트를 활용해, ZADD → ZRANK를 하나의 트랜잭션처럼 실행해 동시성 환경에서 더욱 안정적인 처리가 가능합니다.\n\nasync joinQueue(userId: string): Promise<number> {\n    const timestamp = Date.now();\n    await this.redis.zadd(QUEUE_KEY, timestamp.toString(), userId);\n    const rank = await this.redis.zrank(QUEUE_KEY, userId);\n    if (rank === null) {\n      throw new Error('Failed to get rank');\n    }\n\n    return rank + 1;\n  }\n\nDate.now()는 정말 안전할까?\n\n위 코드에서 추가로 생각해볼 문제가 하나 있습니다. “과연 Date.now()로 정확한 순서를 보장할 수 있을까?”입니다.\n\nDate.now()는 millisecond(1/1000초) 단위의 정수 값을 반환합니다. 그래서 대부분의 경우엔 충분히 정렬 기준으로 사용될 수 있지만, 인터파크 티케팅과 같이 아주 짧은 시간 안에 수백~수천 명이 동시에 요청하는 경우, 같은 millisecond에 여러 요청이 들어올 수 있습니다.\n\n예를 들어 아래와 같은 상황이 발생할 수 있습니다.\n\nuser123 → 1712478912312\nuser456 → 1712478912312\n\n이처럼 score가 동일한 경우, Redis는 멤버 값의 사전순을 기준으로 순서를 정합니다. 따라서 user123이 user456보다 먼저 처리되는 결과가 나올 수 있지만, 이 순서는 값에 따라 의도하지 않은 순위가 될 수도 있습니다.\n\n이를 해결하기 위한 방법에는 크게 2가지 방식이 있습니다.\n\nscore에 소수점 랜덤값을 더해 분산시키기\nconst timestamp = Date.now() + Math.random();\n\n같은 millisecond에 여러 요청이 들어와도 Math.random()을 더해줌으로써 score가 겹칠 확률을 낮추는 방식입니다. 하지만, 동시 요청이 굉장히 많다면 완벽한 순서 보장은 어렵습니다.\n\nuserId에 timestamp를 포함시켜 정렬 확보\nZADD reservation:queue 1712478912312 \"1712478912312:user123\"\n\nscore는 그대로 두되, member 값에 timestamp를 포함하면 동일한 score일 경우에도 사전순 정렬 기준이 명확해집니다.\n\n실시간 순위 업데이트\n\n단순히 사용자가 대기열에 들어간 시점의 순위만 알려주는 것만으로는 부족합니다. 대기열은 계속해서 변하기 때문에, 앞에 있는 사용자가 처리되면 내 순위도 변하게 됩니다. 따라서 사용자에게 실시간으로 순위가 바뀌고 있다는 것을 알려주는 기능이 필요합니다.\n\n이를 위해 저는 앞서 언급한 SSE를 사용했습니다. SSE는 클라이언트가 서버로부터 단방향 스트림 형태로 실시간 이벤트를 수신할 수 있도록 도와주는 기술입니다. 대기열처럼 가볍고 실시간성이 필요한 경우에는 WebSocket보다 더 간단하고 효과적인 방식이기도 합니다.\n\nNestJS에서는 아래처럼 @Sse() 데코레이터를 활용하여 해당 유저에게 실시간 순위 정보를 전송합니다.\n\n@Sse('events')\ngetEvents(@Query('userId') userId: string): Observable<any> {\n  const confirmedEvent = fromEvent(this.eventEmitter, 'queue.user.confirmed').pipe(\n    filter((event: any) => event.userId === userId),\n    map(() => ({\n      data: JSON.stringify({\n        event: 'confirmed',\n        message: '대기열에서 처리되었습니다.',\n        confirmed: true,\n      }),\n    })),\n  );\n\n  const updateEvent = fromEvent(this.eventEmitter, 'queue.updated').pipe(\n    map(async () => {\n      const rank = await this.queueService.getUserRank(userId);\n      return {\n        data: JSON.stringify({\n          event: 'update',\n          rank,\n          timestamp: Date.now(),\n        }),\n      };\n    }),\n  );\n\n  return merge(confirmedEvent, updateEvent);\n}\n\n위 코드에서는 총 두 가지 이벤트를 스트리밍합니다.\n\nconfirmed: 사용자의 순서가 도달해 예약 화면 진입이 확정되었을 때\nupdate: 전체 대기열이 갱신되었을 때 사용자 순위를 다시 조회해 전송\n\n클라이언트에서는 EventSource 객체를 통해 이 스트림을 수신하고, 다음과 같이 실시간 순위 정보를 반영할 수 있습니다.\n\n useEffect(() => {\n    if (!joined) return;\n\n    const sse = new EventSource(`${serverURL}/queue/events?userId=${userId}`);\n\n    sse.onmessage = (event) => {\n      const data = JSON.parse(event.data);\n      \n      if (data.event === 'update') {\n        // 순위 업데이트 이벤트\n        setRank(data.rank);\n      } else if (data.event === 'confirmed') {\n        // 확정 이벤트\n        setConfirmed(true);\n        sse.close(); // 더 이상 이벤트를 받을 필요가 없음\n      }\n    };\n\n    sse.onerror = (error) => {\n      console.error('SSE Error:', error);\n      sse.close();\n    };\n\n    return () => sse.close();\n  }, [joined, userId]);\n\n대기열 처리\n\nSorted Set에 사용자를 등록하고, 실시간으로 순위를 알려주는 것까지 구현했다면, 이제는 실제로 대기열에서 순서대로 유저를 처리하는 로직이 필요합니다.\n\n이 작업은 단순히 클라이언트에게 순서 것을 넘어, 정해진 인원만 예약 화면에 진입할 수 있도록 제어하는 핵심 로직입니다. 예를 들어 1분에 10명씩만 예약 화면에 진입시켜야 한다면, 백엔드에서는 일정 주기로 Redis 대기열에서 상위 N명의 유저를 꺼내어 처리열로 이동시켜 실제 예약 로직을 수행해야 합니다. 그리고 그 유저에게는 SSE를 통해 예약 대기열에서 벗어났다는 것을 알려주게 됩니다.\n\n데모에서는 간단하게 아래처럼 @Cron 데코레이터를 이용해 배치로 워커가 대기열에서 꺼낼 수 있도록 하였습니다.\n\nasync confirmTopN(n: number): Promise<string[]> {\n    const topUsers = await this.redis.zrange(QUEUE_KEY, 0, n - 1);\n    for (const userId of topUsers) {\n      await this.redis.zrem(QUEUE_KEY, userId);\n    }\n    return topUsers;\n  }\n}\n@Cron(CronExpression.EVERY_MINUTE, {\n  name: 'process-queue-every-minute',\n})\nasync processQueue() {\n  if (this.isProcessing) {\n    return;\n  }\n\n  try {\n    this.isProcessing = true;\n    this.logger.log('Processing queue...');\n\n    const processCount = 10;\n    const confirmedUsers = await this.queueService.confirmTopN(processCount);\n\n    if (confirmedUsers.length > 0) {\n      this.logger.log(\n        `Processed ${confirmedUsers.length} users from the queue`,\n      );\n      \n      // 대기열에서 처리된 사용자들을 처리열로 이동\n\n      for (const userId of confirmedUsers) {\n        this.eventEmitter.emit('queue.user.confirmed', { userId });\n      }\n\n      this.eventEmitter.emit('queue.updated');\n    } else {\n      this.logger.debug('No users to process in the queue');\n    }\n  } catch (error) {\n    this.logger.error(\n      `Error processing queue: ${error.message}`,\n      error.stack,\n    );\n  } finally {\n    this.isProcessing = false;\n  }\n}\n\n이 함수는 1분마다 한 번 실행되며 다음과 같은 역할을 합니다.\n\nRedis Sorted Set에서 상위 N명의 사용자 추출\n해당 사용자들을 예약 확정 처리 (confirmTopN)\n각 사용자에게 queue.user.confirmed 이벤트를 발송하여 SSE를 통해 즉시 예약 진입 안내를 보냅니다.\n전체 사용자에게는 queue.updated 이벤트를 발송하여 순위 정보를 최신 상태로 유지합니다\n\n이 구조를 통해 시스템은 정해진 간격으로 대기열을 순차적으로 소모하게 되고, 클라이언트는 아무런 추가 요청 없이 순위 업데이트와 진입 안내를 실시간으로 수신할 수 있습니다.\n\n대기열 토큰\n\n대기열은 기능 외에도, 보안적으로 반드시 고려해야 할 핵심 포인트가 있습니다. 바로 대기열 우회를 어떻게 막을 것인가입니다.\n\n예를 들어 누군가가 /reservation 같은 실제 예약 페이지의 URL을 미리 알고 있다면 어떨까요?\n\n혹은 대기열을 통과한 친구에게 받은 링크를 그대로 복붙하거나, URL만 조작해서 접근하려 할 수도 있습니다.\n\n이러한 상황에서 대기열 토큰은 사용자에게 정해진 절차(대기열 진입 → 순번 도달 → 예약 진입)을 반드시 따르게 만들기 위한 흐름 강제 장치 역할을 합니다.\n\n그래서 서버는 예약 페이지 진입 시 다음 조건을 만족해야만 진입을 허용합니다.\n\n유효한 토큰이 있고,\n해당 토큰의 순번이 현재 진입 가능한 상태이며,\n토큰이 만료되지 않았고, 이미 사용된 적이 없어야 함\n\n즉, 사용자는 반드시 대기열을 거쳐야만 예약 페이지에 접근할 수 있으며, 이 흐름을 벗어난 모든 시도는 토큰 검증 단계에서 차단됩니다.\n\n실제로 인터파크에서도 대기열 진입 시 아래와 같은 특수한 URL을 발급합니다.\n\nhttps://tickets.interpark.com/waiting?key=1LfF8KdMIojqxIBoa8JkpGk8cba%2F1rJilsOHN6DadkUeVZNfcJmOUTaofViOnRgWNNNRg...\n\n여기서 key= 뒤에 붙는 값이 바로 대기열 토큰입니다.\n\n또한, 토큰을 사용한다면 아래와 같은 보안상의 이점도 얻을 수 있습니다.\n\n보안 강화\n사용자 ID만으로 접근을 제어하면 ID 위조의 위험이 존재합니다.\n반면, 서버에서 발급한 고유한 토큰은 위조가 불가능하며, 요청자가 정당한 대기 참여자인지를 판별하는 수단이 됩니다.\n중복 참여 방지\n동일 사용자가 여러 번 /join 요청을 보내거나, 여러 탭에서 접근하는 것을 효과적으로 제어할 수 있습니다.\n서버는 같은 토큰을 가진 요청만 유효하다고 판단하여 중복 입장을 차단합니다.\n봇 방지 및 요청 인증\n토큰이 없는 요청은 대기열에 진입할 수 없도록 막을 수 있습니다.\n무작위 요청 시도, 스크립트 공격 등도 어느 정도 차단할 수 있는 구조가 됩니다.\n\n이번에 만들어본 간단한 데모에는 토큰 발급과 인증 절차를 추가하진 않았지만, 실제 서비스로 사용되는 대기열 시스템에는 대기열 토큰이 필수적인 기능입니다.\n\n대기열 처리 이후\n\n이번 데모에서는 대기열에서 빠진 사용자에게 단순히 예약 진입 안내를 전송하는 구조까지만 구현했지만, 실제 서비스에서는 그 다음 흐름을 어떻게 구성할지는 서비스 UX에 따라 크게 달라집니다.\n\n예를 들어, 인터파크의 경우에는 대기열을 통과한 사용자가 예약 화면에 진입한 뒤 유효 시간 내에만 예약을 완료할 수 있도록 제한하고 있습니다.\n\n이러한 구조에서는 대기열에서 빠진 사용자를 “참가열”이라는 별도 공간에 등록해두고, 해당 유저가 정해진 시간 안에 예약을 완료하지 못할 경우 자동으로 참가열에서 제거하는 방식이 필요합니다.\n\n이러한 참가열은 Redis의 Sorted Set + TTL, 또는 별도의 Hash + expire 구조를 통해 쉽게 구현할 수 있으며, 예약 진입 시점에 유저가 참가열에 존재하는지를 검사함으로써 유효성을 검증할 수 있습니다.\n\n결론\n\n실제 인터파크에서 티케팅을 하는 경험에서 시작된 호기심이, 결국 하나의 대기열 시스템을 직접 설계하고 구현해보는 계기가 되었습니다.\n\n처음에는 단순히 “누가 먼저 왔는가”만 판단하면 되는 줄 알았지만, 실제 시스템에서는 수많은 사용자에게 공정한 기회를 제공하고, 서버를 보호하며, 실시간으로 사용자와 소통하는 것이 핵심이라는 사실을 체감할 수 있었습니다.\n\n특히 Redis의 Sorted Set과 SSE를 활용한 구조는 생각보다 간단하지만 강력했고, 현실의 복잡한 문제를 기술로 푸는 재미를 다시 한 번 느낄 수 있었습니다.\n\n물론 이번 글에서는 MVP 수준의 구조만 구현했기에, 실제 서비스에 적용하려면 토큰 기반 인증, IP 제한, Bot 방지, 처리열 분리, 장애 대응 등 더 많은 보완이 필요할 것입니다. 하지만 이렇게 작게나마 구조를 설계하고 직접 실험해본 경험은, 이후 더 복잡한 시스템을 설계할 때 큰 밑거름이 될 것이라 생각합니다.\n\n혹시 이 글이 비슷한 고민을 하는 누군가에게 도움이 되거나, 새로운 호기심의 시작점이 된다면 더없이 기쁠 것 같습니다.\n\nsaewoohan\n팔로우\n이전 포스트\n예약 시스템과 동시성 제어 이야기\n다음 포스트\n채팅 시스템 MVP부터 확장까지\n0개의 댓글\n댓글 작성\n관련 채용 정보\n넥스트그라운드\n[인턴] 백엔드 개발자\n넥스트그라운드는 부동산 시장의 정보 비대칭을 해소하는 '집품' 서비스를 운영하며, 빠르게 성장하는 개발 팀에서 백엔드 전문가를 찾습니다. JAVA와 Spring을 활용한 API 설계 및 성능 최적화 업무를 통해 함께 성장할 기회를 제공합니다.\n아키스케치\nSoftware Engineer, Backend\nArchisketch는 AI 기반 3D 인테리어 솔루션을 제공하며, B2BC SaaS 시장에서의 성장을 거듭하고 있습니다. 백엔드 개발자로서 Spring Framework와 Kotlin을 활용해 서비스 개발에 참여하며, 유연한 근무 환경과 전문가들과의 협업 기회를 제공합니다.\n지로\n[두둠] 백엔드 개발자\n영상 제작사와 기업 고객을 연결하는 국내 1위 플랫폼 '두둠' 운영팀에서 백엔드 개발자를 모집합니다. Node.js, AWS 등 다양한 기술을 활용하여 영상 제작 시장의 혁신을 함께 경험해보세요!",
    "tags": [
      "redis",
      "sorted set",
      "대기열 시스템",
      "시스템 디자인",
      "실시간 통신"
    ],
    "commentCount": "0"
  },
  {
    "title": "절대 Cron에서 표준 출력을 사용하지 마세요 - root 볼륨 포화 괴담",
    "description": "cron 작업이 표준 출력을 삭제된 임시 파일로 리디렉션한 채 닫지 않아 루트 디스크가 가득 찬 사례를 다룹니다. 문제 원인 분석과 재현 과정을 담았습니다.",
    "link": "https://velog.io/@skynet/%EC%A0%88%EB%8C%80-Cron%EC%97%90%EC%84%9C-%ED%91%9C%EC%A4%80-%EC%B6%9C%EB%A0%A5%EC%9D%84-%EC%82%AC%EC%9A%A9%ED%95%98%EC%A7%80-%EB%A7%88%EC%84%B8%EC%9A%94-root-%EB%B3%BC%EB%A5%A8-%ED%8F%AC%ED%99%94-%EA%B4%B4%EB%8B%B4",
    "author": "하늘과 바람과 별과 C",
    "date": "2025년 4월 4일",
    "comments": "2개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/skynet/post/3986b28b-89f4-4f2f-a90d-061cd672f759/image.png",
    "content": "하늘과 바람과 별과 C\n로그인\n하늘과 바람과 별과 C\n로그인\n절대 Cron에서 표준 출력을 사용하지 마세요 - root 볼륨 포화 괴담\ncomputerphilosopher·2025년 4월 4일\n팔로우\n5\nlinux\n아침을 깨운 root disk 사용량 알림\n\n오전 6시 40분, 운영 서버 중 하나의 루트 디스크 사용률이 90%가 넘는다는 알림이 발생했다. Critical 레벨 알림이었기 때문에 모든 팀원에게 전화가 발신됐다.\n\n이 서버는 모니터링 데이터를 저장하는 용도로 사용한다. 당연히 모든 데이터는 별도로 마운트한 데이터 볼륨에 저장된다. 루트 볼륨이 이 정도로 가득차는 것은 잘 일어나지 않는 이상한 일이다. 게다가 모니터링 데이터를 확인해보니 하루만에 디스크 용량이 5GiB 가량 증가했고 지금도 빠른 속도로 증가하고 있었다.\n\n디스크 사용량이 빠르게 증가하고 있었으므로 우선 루트 볼륨을 확장해 장애 발생을 막았다. 그러나 원인을 밝히지는 못했다.\n\n유령 파일 사건\n\n/var/log 등 데이터를 많이 차지할만한 공간을 확인해보았으나 허사였다. 결국 du 명령어로 루트 볼륨의 모든 서브 디렉토리를 전수조사 하였지만 디스크 사용량이 증가한 원인을 찾을 수 없었다. du 로 확인한 루트 볼륨의 사용량은 10GB 정도였는데 알 수 없는 5GB가 더 사용되고 있었다.\n\n(참고: du 명령어를 재귀적으로 사용하는 건 I/O 부하가 상당하기 때문에 운영 서버에서 수행하기는 부담스러운 작업이다. nice와 ionice를 이용해 우선순위를 최하로 설정한 뒤 서브 디렉토리를 순차적으로 하나씩 검증하는 등의 방식으로 부하를 분산하였다.)\n\n처음 검증한 가설은 ext4의 예약 공간(Reserved space)가 5GiB를 사용한다는 것이었다. 그러나 예약 공간의 점유율이 전체 디스크 공간의 5% 가량이고 루트 볼륨의 크기가 20GB에 불과하다는 점을 감안하면 가능성이 거의 없었다.\n\n다음 가설은 마운트로 인한 루트 볼륨 파일 누락이었다. 루트 볼륨에서 이미 사용하던 디렉토리에 다른 디스크를 마운트 했을 때, 기존에 디렉토리에 있던 파일들은 여전히 디스크를 점유하지만 du 결과에서는 나타나지 않는다고 한다. 그러나 기존에 사용하던 데이터 볼륨 외에 다른 디스크를 마운트한 적은 없었다.\n\n그 다음으론 삭제 파일이 디스크를 점유하고 있을 가능성이다. 기존 프로세스가 열어 둔 파일은 rm 명령어 등을 이용해 삭제하더라도 디스크를 점유한다고 한다. 파일이 삭제된 사실을 알지 못하는 프로세스가 더 이상 존재하지 않는 파일의 내용을 읽는 것을 방지하기 위함이다. 프로세스가 파일을 닫아야 완전히 디스크에서 제거한다.\n\n그럼 현재 실행되는 프로세스 중 삭제된 파일을 열고 있는 것이 있는지를 검증하면 된다. 사용한 명령어는 다음과 같다.\n\n# nice: CPU 우선순위 최하로 설정\n# ionice: I/O 우선순위 최하로 설정\n# +L1: 링크 수가 1보다 작은 파일\nnice -n19 ionice -c3 sudo lsof +L1\n\n결과를 확인해보니 rsync를 이용해 핫 스토리지에서 웜 스토리지로 파일을 옮기는 cron 프로세스(이하 warmer로 표기)가 /tmp 디렉토리의 삭제된 파일을 열어두고 있었다. 크기도 사라진 5GB와 엇비슷했다. 디스크 사용량이 계속 증가하고 있었으므로 파일의 크기와 디스크 증가량을 면밀히 대조해 볼 여유는 없었다. 직감이 말하는대로 이 프로세스를 kill 하자 즉시 디스크 사용량이 감소했다.\n\n(참고: 핫 스토리지는 조회와 쓰기 부하가 상대적으로 높은, 즉 '뜨거운' 저장소이다. 반면 warm 스토리지는 부하가 상대적으로 낮은 '미지근한' 저장소이다. 일반적으로 웜 스토리지는 핫 스토리지보다 저렴한 타입을 사용한다. 모니터링 데이터는 최근 데이터의 조회 빈도가 훨씬 높기 때문에 hot/warm 구분의 근거가 명확하다.)\n\n범인 검거\n\nwarmer를 다시 실행하자 디스크 사용량이 다시 증가하기 시작했다. lsof 결과도 전과 유사했다. /tmp 디렉토리에 존재했으나 지금은 삭제된 파일을 열어두고 있다는 것이다. 보안 로그를 통해 모든 사용자의 명령어를 검색해보았으나 삭제 명령어를 수행한 사람은 없었다. 결국 사람이 아닌 프로세스가 지운 것이 명확했다.\n\nionotifywait 명령어를 이용해 /tmp 디렉토리를 모니터링 해보니 확실히 변경이 일어나곤 있었다. 그러나 이 명령어로는 어떤 프로세스가 파일을 만들고 삭제하는지 알 수 없었다.\n\n나는 범인으로 rsync를 의심했다. warmer의 주요 업무가 rsync를 실행이었기 때문이다. 조사 결과 rsync는 파일을 복사할 때 임시 파일을 생성한다고 했다. 확신을 얻은 나는 상황을 재현하기 위해 여러 테스트를 했다. 그러나 소득은 내가 틀렸다는 사실을 알았다는 것 뿐이었다. rsync는 임시 파일을 /tmp가 아니라 목적지 디렉토리에 생성했다. 임시 파일을 저장할 디렉토리를 플래그로 따로 지정하면 그렇지 않을수도 있지만, 우리는 디폴트 값을 사용하고 있었다.\n\n그래도 warmer에 대한 의심을 져버릴 수 없었던 나는 /proc 디렉토리에 접근해 파일 디스크립터를 조회했다. 그런데 warmer의 1,2 번 파일 디스크립터가 /tmp 디렉토리의 삭제된 파일을 지시하는 심볼릭 링크였다.\n\n즉 stdout과 stderr가 /tmp 디렉토리에 출력되고 있으나, 파일은 남아있지 않고 삭제되고 있었다. 그러면서도 warmer 디렉토리가 그 삭제된 파일을 계속 열어두고 있는 상황이었다.\n\nwarmer는 crontab으로 실행되고 있었고 stdout과 stderr를 따로 리다이렉트하진 않았다. cron은 터미널을 통해 접속한 사용자가 아니므로 로그를 찍을 곳이 없긴 하다. 그런데 널 디바이스(/dev/null)로 출력을 버리지 않고, '출력을 임시 파일에 저장한 뒤 삭제하되 닫지는 않는다.' 라는 이상한 선택을 한 것이었다.\n\n재현 테스트를 거친 결과 cron이 내가 추측한 방식대로 동작한다는 것을 확신할 수 있었다. 표준 출력에 무의미한 로그를 남기는 shell script를 cron으로 실행한 뒤, 앞서 이야기 한 lsof 명령어 결과와 /proc 디렉토리의 파일 디스크립터를 조회해보면 동일한 현상이 재현되는 것을 확인할 수 있다.\n\n#!/bin/bash\n\nwhile true; do\n  head -c $((50 * 1024 * 1024)) < /dev/zero | tr '\\0' 'A'\n  sleep 10\ndone\n\n(실험 환경: Ubuntu 24.04)\n\n마치며\n\n아직도 cron이 왜 표준 출력을 디스크에 저장하고 추적까지 어렵게 만드는 행동을 하는진 모르겠다. 그러나 cron을 직접 고쳐 쓰기는 현실적으로 어려우니 사용법을 바꿔야 한다. 사실 cron의 실행 결과를 로그로 남기지 않고 버리는 것은 작업의 성공, 실패 여부를 알기 어렵게 만드는 방식이다. 게다가 디버깅 뿐만 아니라 root 디스크 포화를 유발할 수 있는 아주 위험한 방식임이 실험을 통해 검증되었다. cron을 안전하게 수행하려면 다음의 방침을 따라야 한다.\n\n파일에 로그를 남긴다.\n로그 파일은 루트 볼륨이 아니라 데이터 볼륨에 위치시켜야 한다\nlogrotate 등의 수단을 이용해 크기가 무한정 커지지 않도록 제어해야 한다.\ncomputerphilosopher\n팔로우\n이전 포스트\nPDF만 던져주면 끝날줄 알았다 - GPTs RAG 적용 실패기\n2개의 댓글\n댓글 작성\n정현우\n2025년 4월 4일\n\n재미있는 글 잘 읽었습니다 :) root cause 의 결은 다른데 비슷한 경험이, nohub 으로 돌리던 프로세스가 기록하던 로깅폴더를 지웠져서 알수없는 용량 10G 로 두려움에 떨었던 기억이 있네요 ㅎㅎ\n\n답글 달기\nbiz.ken\n2025년 4월 4일\n\n전통적으로 많은 cron 구현체는 리다이렉션되지 않은 출력을 MAILTO 환경 변수에 지정된 사용자나 crontab 소유자에게 메일로 보내려고 시도합니다. 이는 출력을 어딘가에 '남기려는' 기본적인 시도입니다.\n\n메일 시스템이 없거나 설정되지 않았거나, MAILTO가 비어있는 경우 cron 데몬은 다른 방법을 찾아야 합니다. 이때 글에서 설명된 것처럼 임시 파일에 출력을 저장하는 방식을 사용할 수 있습니다.\n\n임시 파일 생성: 출력을 담을 곳이 필요하니 임시 파일을 만듭니다.\n파일 핸들 유지: 프로세스가 계속 출력을 쓸 수 있도록 File Descriptor를 열어 둡니다.\n파일 삭제 (Unlink): /tmp 디렉토리가 지저분해지는 것을 막고, 작업 종료 시 자동으로 공간이 회수되도록 (프로세스가 파일 핸들을 닫으면) 파일 시스템에서 파일 이름을 제거합니다(unlink). 이것이 lsof +L1에서 (deleted)로 표시되는 이유입니다.\n답글 달기\n관련 채용 정보\n와드(캐치테이블)\nB2B Back_End Developer (3~5년차)\n캐치테이블은 외식업 전문 통합 플랫폼을 운영하며 디지털화를 선도하고 있습니다. 백엔드 개발자로 성장할 기회를 제공하며, Java, Spring을 활용한 혁신적인 서비스 개발을 지원합니다.\n씨제이이엔엠(CJ ENM)\n[Mnet Plus] 백엔드 개발\nMnet Plus는 글로벌 KPOP 플랫폼 개발을 통한 K-Culture 소비자와의 연결을 목표로 합니다. Java 또는 Kotlin 경험이 있는 백엔드 개발자를 찾으며, 다양한 서비스 개발로 글로벌 비즈니스 기회를 창출하는 것이 특징입니다.\n라포랩스(퀸잇)\n서버 엔지니어 (비즈니스 트라이브)\n퀸잇을 운영하는 라포랩스에서 서버 엔지니어를 찾습니다. Kotlin, Spring 등으로 비즈니스 성장을 이끄는 인프라를 개발하고, 임팩트 있는 도전의 주인공이 되어보세요!",
    "tags": [
      "linux"
    ],
    "commentCount": "2"
  },
  {
    "title": "UX 관점에서 보는 로딩 상태",
    "description": "로딩 상태에 숨겨진 심리학과 설계 원칙.",
    "link": "https://velog.io/@chlruddlf73/UX-%EA%B4%80%EC%A0%90%EC%97%90%EC%84%9C-%EB%B3%B4%EB%8A%94-%EB%A1%9C%EB%94%A9-%EC%83%81%ED%83%9C",
    "author": "최씨",
    "date": "6일 전",
    "comments": "1개의 댓글",
    "likes": "16",
    "thumbnailUrl": "https://velog.velcdn.com/images/chlruddlf73/post/8439f678-c50c-4a27-866d-224ee1953311/image.png",
    "error": "Navigation timeout of 60000 ms exceeded"
  },
  {
    "title": "🚨3분만에 Next.js 서비스 장애 대응 대응하기: GitHub Actions + AWS ECS + CodeDeploy 롤백 시스템",
    "description": "aws의 ecs code deploy 와 git action을 활용한 rollback 구축 경험을 공유 합니다.",
    "link": "https://velog.io/@rewq5991/aws-ecs-rollback",
    "author": "rewq5991.log",
    "date": "2025년 4월 3일",
    "comments": "4개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/rewq5991/post/1c9b03b5-9e73-4c38-abd5-e1aff5fecee1/image.png",
    "content": "rewq5991.log\n로그인\nrewq5991.log\n로그인\n🚨3분만에 Next.js 서비스 장애 대응 대응하기: GitHub Actions + AWS ECS + CodeDeploy 롤백 시스템\nant·2025년 4월 3일\n팔로우\n5\nawsecrnext.jsroolback\nmonorepo-operations\n목록 보기\n3/3\n0. 프롤로그\n\n이번글에서는 지난번까지 구축한 ECS 환경에서, 오류 발생 시 애플리케이션을 안정적으로 롤백하는 방법에 대해 다뤄보겠습니다.\n특히 GitHub Actions, AWS CodeDeploy를 활용하여 자동화된 배포 및 롤백 프로세스를 구현하는 방법을 중심으로 설명드릴 예정입니다.\n\n문제 설명\n\n평화로운 정기 배포의 날, 늘 그랬듯 배포 버튼을 누르고 커피 한 잔의 여유를 즐기며 배포 완료를 기다렸습니다.\n커피를 다 마시고 나서야 배포 완료 메시지를 확인하며 \"오늘도 무사히 넘어갔구나\"라는 안도의 한숨을 내쉬었습니다.\n\n그러나 약 2시간 후, 한 고객으로부터 \"특정 기능 사용 시 페이지가 다운된다\"는 신고가 접수되었습니다.\n해당 기능은 당일 새롭게 배포된 것으로, 상황의 심각성을 더했습니다.\n\n문제의 원인을 조사한 결과, 백엔드와 사전에 협의한 API 배포 일정이 내부 커뮤니케이션 오류로 인해 진행되지 않은 상태임을 확인할 수 있었습니다.\n백엔드에서는 아직 개발이 진행 중이었으나, 프론트엔드에서는 이미 배포된 상황이었기에 긴급하게 롤백을 결정하게 되었습니다.\n\n배포했던 브랜치를 재확인하고 빌드부터 배포까지 진행하는 데 총 30분이 소요되었습니다.\n\n비록 당장의 위기는 해소되었으나, 이러한 상황이 재발될 경우를 대비하여 보다 신속하고 효율적으로 대응할 수 있는 시스템의 필요성을 절실히 느끼게 되었습니다.\n이에 따라, 롤백 시스템의 개선을 결심하게 되었습니다.\n\n1. 현재 문제 설정\n\n필요한 배포 버전 선정 및 결정\n\n필요한 버전을 노션에 작성된 배포트레커를 통해 찾는다.\n해당 merge pr를 찾는다.\n코드를 읽고 필요한 내용인지 검토 한다.\n\n※ 특히 2번과 3번 단계에서는 소요 시간이 많고, 실수가 발생할 가능성도 있음을 유념해야 합니다.\n\n빌드 및 배포\n\n\n빌드 (약 6분 소요):\n이미 ECR에 등록된 이미지가 존재함에도 불구하고, 상황에 따라 재활용하지 않고 새롭게 빌드를 진행 합니다.\n배포 (약 3분 소요):\n빌드 완료 후 배포 절차를 진행합니다.\n2. 개선 목표\n\nesc 에 code deploy 가 연동 되어 있으면 task definition을 새로 만들어 올리면 해당 테스크를 새로 수행 합니다.\n이를 이용하여 롤백을 구현 합니다.\n\n효율적인 버전 선정 및 롤백 절차\n\n버전 관리를 체계화하여 필요한 배포 버전을 쉽고 빠르게 확인할 수 있도록 개선합니다.\n코드 검토, 빌드, 배포 전 과정에서 불필요한 시간 낭비를 줄이기 위해 자동화된 검증 절차를 추가합니다.\n\n배포 시간 단축\n\nECR 이미지를 재활용할 수 있는 환경을 마련하여, 빌드 시간을 가능한 한 단축합니다.\n불필요한 프로세스를 제거하여 배포에 걸리는 시간을 줄입니다.\n\n문제 발생 시 빠른 대처\n\n롤백이 신속히 실행될 수 있도록 기존 스크립트 및 설정을 간소화합니다.\n문제 발생 시 알림 및 관련 정보를 빠르게 제공하는 시스템을 연계 도입합니다.\n3 개선 방법\n\n효율적인 버전 선정 및 롤백 절차\n\n버전 관리 시스템 개선\n\n배포 하기 전에 노션에 배포 트레커에 내용과 버전을 적어 내용을 바로 확인 하도록 하기\n\n배포 시 package.json에 있는 versoin을 사용해 ecr에 해당 버전과 latest를 둘다 push 한다.\n\n  - name: 'VERSION 추출 및 검증'\n    id: set-version\n    run: |\n    # package.json에서 version 추출\n    VERSION=$(jq -r '.version' apps/web1/package.json)\n    VERSION=\"v${VERSION}\"\n\n    # 버전 값이 올바른지 검증\n    if [[ ! $VERSION =~ ^v[0-9a-zA-Z._-]+$ ]]; then\n    echo \"유효하지 않은 버전 형식입니다: $VERSION\"\n    exit 1\n    fi\n\n    echo \"VERSION=$VERSION\" >> $GITHUB_ENV\n    echo \"확정된 버전: $VERSION\"\n\n  - name: '도커 이미지 빌드 & ECR 푸쉬 '\n    id: build-image\n    run: |\n    DOCKER_BUILDKIT=1 docker build  \\\n    docker build \n    docker tag ${{ secrets.AWS_ECR_REPOSITORY_NEXT }}:latest ${{ secrets.AWS_ECR_REPOSITORY_NEXT }}:${{ env.VERSION }}\n    docker push ${{ secrets.AWS_ECR_REPOSITORY_NEXT }}:${{ env.VERSION }}\n    docker push ${{ secrets.AWS_ECR_REPOSITORY_NEXT }}:latest\n\n버전 조회 자동화\n\ngit action의 workflow을 통해서 사용하고자 하는 vesion을 입력 받습니다.\n workflow_dispatch:\n   inputs:\n     version:\n       description: '버전 번호를 입력하세요 ex) v1.0.0'\n       required: true\n       default: 'latest'\n특정 버전의 image가 ecr에 있는 지 확인 합니다.\n - name: 'ECR image tag 확인'\n   run: |\n   aws ecr describe-images \\\n   --repository-name web1 \\\n   --image-ids imageTag=${{ env.VERSION }} \\\n   >/dev/null 2>&1 && echo \"Image found\" || { echo \"Image not found\"; exit 1; }\n\n롤백 절차 최적화\n\ntask-definition 내 이미지 태그를 지정된 버전으로 업데이트 합니다.\n - name: 'task-definition 업데이트'\n   run: |\n   sed -i -e 's|\\(web1\\)\"|\\1:${{ env.VERSION }}\"|g' \\\n   -e 's|\\(web1\\)\"|\\1:${{ env.VERSION }}\"|g' \\\n   ./deploy/ops/web1/task-definition.json\necs deploy를 사용하여 배포를 수행 합니다.\n - name: '[ROLLBACK] ECS 롤백 배포'\n   run: |\n   aws ecs deploy \\\n   --task-definition ./deploy/ops/web1/task-definition.json \\\n   ~~ 나머지 arg\n4. 수행 결과\n\n문서화된 글을 확인하여 배포 하므로 코드를 보고 내용을 확인 안 해도 되며\n이미 ecr에 등록된 이미지를 재사용함으로 빌드 시간을 줄일 수 있습니다.\n\n그래서 배포 시간(3분)만 있으면 안정적인 롤백을 수행 할 수 있습니다. 심지어 특정 개발자에게 의존하지 않고 누구든 롤백을 수행 할 수 있게 되었습니다.\n\n이제 다시 마음 놓고 테스크를 수행하러 갈 수 있게 되었습니다.(정말?)\n\n5. 아쉬운 부분\n\n저희 서비스 코드는 모노레포로 구성되어 있어 tag를 활용한 버전관리 자동화가 어려운 상황입니다. 이로 인해 버전 관리를 여전히 수동으로 수행해야 한다는 점이 아쉽습니다.\n\n혹시 이 글을 읽는 독자분들 중에 해당 문제를 겪으시거나 해결책을 아시는 분은 댓글 부탁드립니다.\n\n6. 느낀점\n\n이번 개선 작업을 통해 배포 프로세스의 효율성과 안정성이 크게 향상되었습니다. 특히, ECR 이미지의 재활용과 자동화된 버전 관리를 통해 빌드 및 롤백 시간을 단축할 수 있었던\n점이 만족스럽습니다.\n그리고, 누구나 쉽게 롤백을 수행할 수 있도록 시스템을 간소화한 것이 이번 작업의 큰 성과 중 하나였습니다.\n다만, 모노레포 구조로 인해 태그 기반 버전 관리 자동화가 어려운 점은 여전히 숙제로 남아 있습니다.\n이를 해결하기 위한 추가적인 연구와 노력이 필요하며, 앞으로도 계속해서 개선 작업을 진행해야 한다고 느꼈습니다.\n\nant\n팔로우\n이전 포스트\necs와 code deploy를 활용한 next.js 배포하기\n4개의 댓글\n댓글 작성\n정소윤\n2025년 4월 6일\n\n문제 설명을 읽으면서 마치 그 순간에 있는듯한 느낌을 받았습니다😂\n단순히 문제 해결 후 끝!이 아니라 해결 과정에서 느꼈던 불편함을 개선하기 위해 개선 목표부터 방법을 정리하고 결과까지 도출해낸 부분이 인상깊었습니다 :) 좋은 글 감사합니다!\n\n1개의 답글\n김도운\n4일 전\n\n저도 예전에 QA에서 미처 잡지못한 버그가 프러덕션에서 발견돼서 급하게 롤백하다 식은땀났던 경험이 있는데 확실히 이렇게 롤백할 수 있는 구조를 잡아놓으면 나중에 유용하겠네요 좋은 글 감사합니다 👍\n\n1개의 답글\n관련 채용 정보\n컬리\n풀필먼트 프론트엔드 개발자\n컬리는 배송 혁신을 주도하는 풀필먼트 프로덕트에서 React 기반 웹 서비스 개발자로 참여해보세요. 고객과 비용 모두 만족시키는 유연한 시스템 구축으로 여러분의 기술을 현실에 적용할 기회를 제공합니다.\n아이포트폴리오\n프론트엔드 개발자\n'올바른 영어 교육 방법으로 비효율적인 영어 교육 시장을 혁신하는 iPortfolio에서 프론트엔드 개발자를 찾습니다. TypeScript와 React를 활용해 고객 맞춤형 영어 학습 플랫폼을 개발하고 글로벌 서비스를 확장하며 성장할 기회를 놓치지 마세요!'\n뱅크샐러드\n웹 프론트엔드 엔지니어\n뱅크샐러드는 금융과 건강 데이터를 연계하여 혁신적인 서비스를 제공하는 플랫폼입니다. 프론트엔드 엔지니어로서 React를 활용한 개발 및 크로스 플랫폼 환경에서의 최적화 작업에 참여하게 됩니다.",
    "tags": [
      "aws",
      "ecr",
      "next.js",
      "roolback"
    ],
    "commentCount": "4"
  },
  {
    "title": "Next.js 15에서 변경된 params 처리 방식: Promise와 React.use() 이해하기(with React 19)",
    "description": "최근 Next.js 15가 출시되면서 라우팅 파라미터를 처리하는 방식에 중요한 변화가 생겼습니다. 기존에는 params 객체에 직접 접근할 수 있었지만, 이제는 Promise로 래핑되어 새로운 접근 방식이 필요합니다. 이 글에서는 이러한 변화의 배경과 해결 방법에 대해...",
    "link": "https://velog.io/@seochan99/Next.js-15%EC%97%90%EC%84%9C-%EB%B3%80%EA%B2%BD%EB%90%9C-params-%EC%B2%98%EB%A6%AC-%EB%B0%A9%EC%8B%9D-Promise%EC%99%80-React.use-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0",
    "author": "seochan99.log",
    "date": null,
    "comments": "1개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/seochan99/post/97945fd6-62be-4f51-bbba-6cc68988bad7/image.png",
    "content": "seochan99.log\n로그인\nseochan99.log\n로그인\nNext.js 15에서 변경된 params 처리 방식: Promise와 React.use() 이해하기(with React 19)\n서희찬·3일 전\n팔로우\n10\nReactnext\n들어가며\n\n최근 Next.js 15가 출시되면서 라우팅 파라미터를 처리하는 방식에 중요한 변화가 생겼습니다. 기존에는 params 객체에 직접 접근할 수 있었지만, 이제는 Promise로 래핑되어 새로운 접근 방식이 필요합니다. 이 글에서는 이러한 변화의 배경과 해결 방법에 대해 알아보겠습니다.\n\n문제 상황: A param property was accessed directly with params\n\nNext.js 15로 업그레이드한 후 다음과 같은 경고 메시지를 받은 경험이 있을 것입니다:\n\nA param property was accessed directly with `params.jobId`. `params` is now a \nPromise and should be unwrapped with `React.use()` before accessing properties \nof the underlying params object. In this version of Next.js direct access to \nparam properties is still supported to facilitate migration but in a future \nversion you will be required to unwrap `params` with `React.use()`.\n\n즉, 기존의 방식처럼 params.id나 const { id } = params와 같이 직접 접근하면 더 이상 작동하지 않는다는 의미입니다.\n\n왜 이런 변화가 생겼을까?\n\nNext.js 15는 React의 최신 기능들을 더 적극적으로 활용하기 시작했습니다. 특히 Suspense와 같은 동시성 기능을 더 효과적으로 지원하기 위해 params와 searchParams를 Promise로 변경했습니다.\n\n이러한 변화는 다음과 같은 이점을 제공합니다:\n\n성능 최적화: 라우팅 파라미터를 비동기적으로 로드하여 초기 렌더링 속도 향상\n서버 컴포넌트와의 일관성: 서버 컴포넌트에서 데이터 흐름과 클라이언트 컴포넌트의 일관성 향상\n향후 React 동시성 모드와의 호환성: React의 미래 방향성과 일치\n해결 방법: React.use() 활용하기\n\n이 문제를 해결하는 가장 권장되는 방법은 React의 use() 함수를 활용하는 것입니다.\n\n'use client';\n\nimport { use } from 'react';\n\nexport default function Page({ params }: { params: Promise<{ id: string }> }) {\n  const { id } = use(params); \n  return <div>Product ID: {id}</div>;\n}\n\n위 코드에서 주목해야 할 부분은 두 가지입니다:\n\nparams의 타입을 Promise<{ id: string }>으로 정의\nuse(params)를 통해 Promise를 언래핑\n실제 적용 예시: 자격 시험 페이지\n\n다음은 실제 프로젝트에서 적용한 예시입니다:\n\n'use client';\n\nimport React, { use, useEffect, useState } from 'react';\n// 기타 import 문...\n\nexport default function QualificationTestPage({\n    params,\n}: {\n    params: Promise<{ jobId: string }>;\n}) {\n    const { jobId } = use(params);\n    const [job, setJob] = useState<JobData | null>(null);\n    const [isLoading, setIsLoading] = useState(true);\n    \n    useEffect(() => {\n        const fetchJobData = async () => {\n            // jobId를 사용한 데이터 페칭 로직\n        };\n        \n        if (jobId) {\n            fetchJobData();\n        }\n    }, [jobId]);\n    \n    // 이하 렌더링 로직...\n}\nuse() 함수란 무엇인가?\n\nReact의 use() 함수는 Promise, Context 등의 소스에서 값을 읽어오는 새로운 React 훅입니다. 특징은 다음과 같습니다:\n\nuseState, useEffect와 같은 다른 훅들과 달리 조건문 내에서도 사용 가능\nPromise가 해결될 때까지 렌더링을 일시 중단(suspend)\n서버 컴포넌트와 클라이언트 컴포넌트 모두에서 사용 가능\n\nuse()는 React 18에서 도입되었으며, Next.js 15에서 본격적으로 활용되기 시작했습니다.\n\n주의사항\nuse() 호출 시 컴포넌트가 suspend될 수 있으므로, 필요에 따라 Suspense 경계를 설정하는 것이 좋습니다.\n타입스크립트에서는 반드시 params의 타입을 Promise<{ ... }>로 명시해야 합니다.\n클라이언트 컴포넌트에서 사용할 때는 파일 상단에 'use client'; 지시문을 잊지 마세요.\n다른 대안들\n\nuse()를 사용하는 것 외에도 다음과 같은 방법들이 있습니다:\n\n서버 컴포넌트에서 await 사용:\n\nexport default async function Page({ params }: { params: Promise<{ id: string }> }) {\n  const { id } = await params;\n  return <div>Product ID: {id}</div>;\n}\n\n서버/클라이언트 컴포넌트 분리:\n\n// 서버 컴포넌트\nexport default async function Page({ params }: { params: Promise<{ id: string }> }) {\n  const { id } = await params;\n  return <ClientPage id={id} />;\n}\n\n// 클라이언트 컴포넌트\n'use client';\nexport function ClientPage({ id }: { id: string }) {\n  return <div>Product ID: {id}</div>;\n}\n\n하지만 클라이언트 컴포넌트만으로 간결하게 구현하고 싶다면 use()를 활용하는 것이 가장 좋은 방법입니다.\n\n결론\n\nNext.js 15에서의 params 처리 방식 변화는 React의 동시성 모델로의 진화를 반영합니다. 비록 초기에는 익숙해지는 데 시간이 걸릴 수 있지만, 이러한 변화는 더 나은 성능과 사용자 경험을 위한 중요한 발전입니다.\n\nReact.use()를 활용한 접근 방식을 통해 미래 지향적인 코드를 작성하고, Next.js와 React 생태계의 진화에 발맞춰 나가시기 바랍니다.\n\n이 글이 Next.js 15의 새로운 params 처리 방식을 이해하는 데 도움이 되었기를 바랍니다. 질문이나 피드백이 있으시면 언제든지 댓글로 남겨주세요!\n\n참고\n\nhttps://react.dev/reference/react/use\n\nhttps://stackoverflow.com/questions/79465960/react-a-param-property-was-accessed-directly-with-params\n\n서희찬\nCarnegie Mellon University Robotics Institute | Research Associate | Developing For Our Lives, 세상에 기여하는 삶을 살고자 개발하고 있습니다\n팔로우\n이전 포스트\n다사다난 2024 회고 - 4월[적당한 스압]\n1개의 댓글\n댓글 작성\naisha85adams\n어제\n\nThis article provides a well-structured overview of the recent changes in Next.js 15, particularly how params are now wrapped in a Promise. It does a great job explaining the reasoning behind this shift, emphasizing React’s evolving concurrency model for better performance and consistency. The practical examples, especially the use of use() for unwrapping params, make it easy for developers to understand and implement the new approach.\n\n답글 달기\n관련 채용 정보\n기아\n[ICT] Frontend Developer\nUI/UX 혁신을 통해 사용자 경험을 극대화하는 프론트엔드 개발 기회! React와 VueJs를 활용해 앱과 웹의 경계를 허물어 보세요 – 진정한 소프트웨어 아티스트가 될 수 있습니다!\n케이존\n프론트엔드 개발자(신입~5년차)\n케이존은 반품과 악성재고 문제를 해결하며 글로벌 B2B SaaS 서비스로 성장하는 플랫폼입니다. 프론트엔드 개발자로 React 및 최신 웹 기술을 활용하여 혁신적인 온라인 커머스 솔루션을 개발해보세요.\n이지시큐\nReact FrontEnd 개발자\n정보보호 전문 컨설팅 기업인 이지시큐에서 안정적인 환경 속에서 React 프론트엔드 개발자로 성장하세요. 유연한 업무와 성장을 지원하며, SECURIST 플랫폼의 기능 개발에 참여할 기회를 제공합니다.",
    "tags": [
      "React",
      "next"
    ],
    "commentCount": "1"
  },
  {
    "title": "앱 개발(RN) 중 겪은 화나는 API 호출 오류와 해결법",
    "description": "모바일에서 Localhost는 어떻게 작동할까",
    "link": "https://velog.io/@seorim6417/%EC%95%B1-%EA%B0%9C%EB%B0%9CRN-%EC%A4%91-%EA%B2%AA%EC%9D%80-%ED%99%94%EB%82%98%EB%8A%94-API-%ED%98%B8%EC%B6%9C-%EC%98%A4%EB%A5%98%EC%99%80-%ED%95%B4%EA%B2%B0%EB%B2%95",
    "author": "My Island",
    "date": "2025년 3월 31일",
    "comments": "6개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/seorim6417/post/030f88f2-27d3-41f2-ae06-a579ff7f2e2b/image.png",
    "content": "My Island\n로그인\nMy Island\n로그인\n앱 개발(RN) 중 겪은 화나는 API 호출 오류와 해결법\n섬·2025년 3월 31일\n팔로우\n16\n앱 개발 중 겪은 API 호출 오류와 해결법\n문제 상황\n\nReact Native와 Expo로 앱 개발을 시작한 지 얼마 안 된 초보 개발자로서, 처음으로 혼자서 프로젝트를 관리하게 되었습니다. React는 어느 정도 알지만 앱 개발은 처음이라 여러 시행착오를 겪었습니다.\n\n프로젝트에서는 백엔드와 프론트엔드를 모두 혼자 관리하는 상황이었습니다. 백엔드 API를 개발하고 테스트하는 과정에서 이상한 문제가 발생했습니다. 백엔드에서 API를 호출하면 정상 작동하는데, 프론트엔드 앱에서 호출하면 계속 실패하는 현상이었습니다. 콘솔에는 다음과 같은 에러 메시지만 계속 출력되었습니다.\n\nDetailed API Error: {\"code\": \"ERR_NETWORK\", \"message\": \"Network Error\", \"response\": undefined, \"status\": undefined}\n삽질의 시작\n\n처음에는 API 주소가 잘못된 건가 의심했습니다. 그래서 API URL을 여러 번 확인했지만 문제는 해결되지 않았습니다.\n\n첫 번째로 시도한 것\n\n은 URL 인코딩 문제를 의심하는 것이었습니다. API 경로에 하이픈(-)이 포함된 competition-id-123 같은 부분이 있어서 인코딩 문제일 수도 있다고 생각했죠.encodeURIComponent를 적용해봤지만 여전히 같은 에러가 발생했습니다.\n\n다음으로는 CORS 설정을 의심\n\n했습니다. 백엔드 서버의 CORS 설정을 확인하고 모든 출처를 허용하도록 설정도 해봤지만 여전히 해결되지 않았어요.\n\nHTTP 헤더도 다양하게 시도했습니다. Content-Type, Accept 등의 헤더를 추가하고, axios 인스턴스를 새로 생성해 baseURL과 타임아웃 설정도 변경해봤지만 계속 같은 에러가 발생했습니다.\n\n증거 수집\n\n\"내가 뭘 놓치고 있는 걸까?...(눈물)\" 생각하다가 백엔드 서버가 정말 정상 작동하는지 확인해보기로 했습니다. 썬더클라이언트를 사용해 백엔드 API를 직접 호출해봤더니 정상적으로 응답이 오는 것을 확인 할수 있었습니다. 이로써 백엔드 서버는 정상 작동 중이라는 것은 확인했지만, 여전히 앱에서는 API 호출이 실패했습니다. 머리를 싸매고 고민하던 중, 문득 생각이 떠올랐습니다.\n\n모바일 앱에서 localhost는 어떻게 동작하는걸까?\n\n모바일 디바이스에서 localhost는 디바이스 자체를 가리키기 때문에 개발 컴퓨터에서 실행 중인 백엔드 서버에 접근할 수 없었습니다. 해결책은 간단했습니다,,!\n\n개발 컴퓨터의 실제 IP 주소를 사용해서 호출해보기\n\nconst url = `http://1~~.1.234:3000/api/events/event-123/matches`;\n\n내 컴퓨터의 로컬 네트워크 IP 주소를 사용하니 모바일 앱에서도 백엔드 API를 정상적으로 호출할 수 있게 되었습니다. 저는 이 경험을 통해 몇 가지 중요한 교훈을 얻었네요....\n\n환경에 따른 차이점 이해하기: 모바일 앱 개발 시 localhost는 디바이스 자체를 가리키므로, 컴퓨터에서 실행 중인 서버에 접근하려면 실제 IP 주소를 사용해야 합니다.\n\n+) 여담이지만 이건 바보 이슈인데 testAPI를 만들때 쿼리키를 똑같이 해서 계속 정상 데이터가 반환되는 이슈도 있었습니다 ^_^,,\n\n플랫폼별 설정 알아두기\n\niOS 시뮬레이터: localhost\n실제 디바이스: 개발 컴퓨터의 IP 주소\n\nAPI 통신 문제가 발생하면 서버 상태, 네트워크 연결, 요청/응답 헤더 등을 차례대로 확인해야 합니다.이렇게 간단한 IP 주소 변경으로 몇 시간을 헤맸던 문제가 해결되었습니다. 초보 개발자로서 혼자 프로젝트를 진행하면서 겪은 값진 경험이었다고 생각합니다. 앞으로 비슷한 상황에 처한 개발자들에게 도움이 되길 바랍니다!\n\n모바일은 변수가 너무 많아................항상 너무 어렵다고 느껴지네요.\n\n혼자 프로젝트를 맡게 되어 정신이 없어 오랜만에 글을 썼는데, 앞으로 프로젝트 하면서 만난 다양한 에러들을 블로그에 가볍게 꾸준히 써볼 예정입니다. ^^\n백엔드 관련 블로그도 있으니 놀러오세요!\n\n섬\nMy Island\n팔로우\n이전 포스트\ni18n json 파일 코딩으로 구글시트에 자동으로 삽입하기\n6개의 댓글\n댓글 작성\nYoonkeee\n2025년 4월 1일\n\n오랜만의 글 반갑습니다. 앞으로 자주 써주세요ㅠ\n\n1개의 답글\n.\n2025년 4월 1일\n\n해결하시는데 너무 고생많으셨어요. 정말 멋지세요 ><\n\n1개의 답글\n예진\n5일 전\n\n맞아요 ㅜㅜ 그래서 이걸로 한달 삽질했었던 것 경험이 있어서 남일 같지 않네요\n\n1개의 답글\n관련 채용 정보\n뱅크샐러드\n웹 프론트엔드 엔지니어\n뱅크샐러드는 금융과 건강 데이터를 연계하여 혁신적인 서비스를 제공하는 플랫폼입니다. 프론트엔드 엔지니어로서 React를 활용한 개발 및 크로스 플랫폼 환경에서의 최적화 작업에 참여하게 됩니다.\n케이존\n프론트엔드 개발자(신입~5년차)\n케이존은 반품과 악성재고 문제를 해결하며 글로벌 B2B SaaS 서비스로 성장하는 플랫폼입니다. 프론트엔드 개발자로 React 및 최신 웹 기술을 활용하여 혁신적인 온라인 커머스 솔루션을 개발해보세요.\n카카오뱅크(kakaobank)\n웹 프론트엔드 개발자 - 신사업\n카카오뱅크 신사업팀에서 웹 프론트엔드 개발자로 혁신적인 금융 서비스를 현실로 만드는 기회를 제공합니다. JavaScript 및 React 경험을 활용해 다양한 신사업 아이템들을 개발하며, 유연근무제와 성장 지원 등 다양한 복지를 누릴 수 있습니다.",
    "tags": [],
    "commentCount": "6"
  },
  {
    "title": "우아한테크코스 레벨 1 회고",
    "description": "우테코에서 바라는 것은 단 하나, \"출석은 해라\". 근데 난 왜 이렇게 바쁘지?",
    "link": "https://velog.io/@songsunkook/%EC%9A%B0%EC%95%84%ED%95%9C%ED%85%8C%ED%81%AC%EC%BD%94%EC%8A%A4-%EB%A0%88%EB%B2%A8-1-%ED%9A%8C%EA%B3%A0",
    "author": "ssg.log",
    "date": null,
    "comments": "9개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/songsunkook/post/efb474e6-2845-4d07-9431-313d1659309d/image.png",
    "content": "ssg.log\n로그인\nssg.log\n로그인\n우아한테크코스 레벨 1 회고\n송선권·4일 전\n팔로우\n10\n우아한테크코스회고\n우아한테크코스 7기\n목록 보기\n2/2\n배경\n\n우아한테크코스 7기 레벨 1이 벌써 끝났다. 정말이지.. 눈코 뜰 새 없이 바빴다. 😂\n하지만 바쁜만큼 재미도 있었고 유익한 시간을 보낼 수 있었다. 나는 레벨 1동안 어떤 활동들을 했을까?\n\n많이도 했네..\n\n우테코 생활\n\n우테코에 와서 가장 충격받은 것은 바로 일과 시간이다. 지금까지 내가 경험한 학교는 대부분의 시간을 수업시간으로 보내고, 아주 짧은 쉬는시간이 주어졌다. 하지만 우테코는 반대였다. 대부분의 시간이 쉬는시간이고, 수업시간은 아주 짧았다. 주에 2~3시간 교육을 2~3회밖에 안하고, 나머지 시간은 전부 알아서 해라였다. 일과시간이어도 졸리면 빈백에서 자거나 산책다녀오거나 해도 아무도 뭐라하지 않는다.\n\n우테코에서 우리에게 바라는 것은 단 하나, 출석은 해라 뿐. 아무것도 강제하지 않는다.\n\n그럼 모든 행동에 자율성이 보장되는 이 곳에서 나는 왜 이렇게 바쁘게 살아왔던 것일까? 오른편에 목차를 한번 슥 훑어보자. 바쁠 수밖에 없었다. 😇\n\n백엔드 미션\n\n백엔드 미션으로는 총 4개(로또, 출석, 블랙잭, 장기) 미션을 수행했다. 각 미션은 페어 프로그래밍을 통한 1단계 PR 제출을 하고, 2단계부터는 혼자 리팩토링(or 추가 구현)하는 방식으로 진행한다.\n\n자바\n\n레벨 1 백엔드 미션의 주제는 자바였다. 지금까지 자바를 따로 공부한 적은 없었지만 많이 다뤄봤기에 큰 문제는 없을 거라고 생각했다. 하지만 지금까지 자바를 사용하면서 객체지향이나 TDD, 설계에 대해 깊게 고민해본 적이 없었던 만큼 이부분에서 종종 부딪히기도 했다.\n\n페어 프로그래밍\n\n페어 프로그래밍, 이게 참 재밌다. 사실상 우테코 레벨 1, 2의 꽃이라고 생각한다.\n\n랜덤으로 배정된 크루와 둘이 함께 프로그래밍을 하게 되는데, 서로의 주장을 들으며 설득을 주고받는 과정이라 할 수 있다. 이렇게만 보면 마냥 재밌어보이는데 꼭 그렇지만도 않다. 내 의견과 다른 상대방의 의견을 듣고 설득당하기란 생각보다 쉽지 않다. 상대방의 의견을 무차별적으로 수용하면 내 주관이 사라지고, 내 주관이 강하면 상대방의 의견을 수용하기 힘들어진다. 그 사이에서 적절한 줄을 타는 것이 중요하다고 생각하는데, 역시 쉽지 않다.\n\n페어 프로그래밍을 하면서 메타인지가 많이 되었다. 내가 작성하는 코드가 근거가 명확한지를 생각해보게 만들기도 하고, 정말 최선이 맞는지 돌아보게 만들기도 한다. 관성적으로 사용하던 패턴에 대해 경각심을 가져보기도 하고, 같은 로직을 새로운 관점에서 바라보게 하기도 한다. 정말 유익한 활동임은 분명하지만 자신의 주관을 가지면서도 열린 자세를 유지하기란 쉽지 않은 것 같다.\n\n리뷰 반영\n\n미션의 각 단계 구현이 끝나면 PR을 올리고 피드백을 받아 반영해야 한다. 리뷰어가 대부분 이전 기수 분들 중 현직자 분들인데, 그래서 그런지 처음에는 쫌 무서웠다..\n\n리뷰를 반영하는 과정에서도 페어 프로그래밍 때처럼 메타인지가 많이 되었다. 보통 리뷰어분들은 정답을 바로 알려주기보다 힌트를 주는 느낌(ex. 어느 쪽이 좋을까요~?)으로 많이 리뷰해주시는데, 그 답을 스스로 찾아나가면서 나만의 주관을 결정내리는 과정이 유익했다.\n\n우테코에서는 리뷰어분들을 최대한 괴롭히면서 배우라고 하는데, 난 아직 그정도는 힘든 것 같다. 유익한 방법이라고 생각하지만 실천하기는 쉽지 않은 것 같다. 😅\n\n소프트스킬\n연극\n\n우테코는 들어오면 모든 크루는 연극부터 하고 시작한다. 일종의 신고식이랄까..?\n\n(차마 얼굴은.. 안된다..)\n\n처음보는 크루들과 조를 맺어 연극을 진행했다. 사람들 앞에 나서는 데 거부감이 줄어든 상태였기에 크게 긴장하지는 않았는데, 그래도 많이 힘들었다. 지금와서 생각해보면~ 음. 힘들었다. ㅎㅎ\n\n테스트 환경에서는 준비한 자료가 잘 동작했는데 실제 연극에 가서 노트북이 맛이 가버렸다. 결국 자료도 대차게 말아먹고 의도치 않게 사생활이 크루들에게 전부 노출되어버렸다.\n\n??: 모코 건조기 돌리는 시간 잘봤어~ ㅎㅎ\n\n그래도 연극 준비하면서 조원들과 많이 친해졌던 것 같다. 이전 기수 선배들이 남긴 피드백처럼 다음 기수도 꼭!! 연극을 했으면 좋겠다. 아니면 뭐 뮤지컬도 좋고~\n\n대니: 머랭인턴, 머랭쿠키는 완성됐어요?\n머랭: 배포 끝나면 딱 맛있을 것 같습니다!\n\n연극 대본 중에서 가장 마음에 들었던 부분이다. 그 때는 머랭이랑 이렇게 친해질 줄 몰랐는데 신기하다. 😙\n\n유연성 강화 스터디\n\n우테코에서는 유연성 강화 스터디(줄여서 유강스)를 필수로 참여하게 했다. 정~말 유익하다고 생각한다. 개발만 잘해서는 좋은 개발자가 될 수 없기에 소프트스킬을 함께 기르는 것이 좋은데, 여기에 유강스가 정말 큰 도움이 되었다.\n\n사실 레벨 1동안 유강스를 진행하면서 다른 크루들을 보고 부러운 마음이 들기도 했다. 다른 크루들은 유강스를 진행하는 과정에서 여러 어려움을 겪고 내적 성장을 이뤄나가는 모습이 눈에 보이는데, 나에게는 그런 모습이 크게 보이지 않았다. 좋게 생각하면 원활하게 유강스 목표를 달성했다고 할 수도 있겠지만, 냉정하게 보면 꼭 필요한 목표였을까? 하는 생각이 들기도 한다. 다음 번에는 유강스 목표를 더 도전적인 걸로 잡아보고 싶다.\n\n이와는 별개로 유강스 자체는 매우 만족스러웠기 때문에 레벨 2에 가서도 할 생각이고, 우테코를 수료하고 나서도 사람들을 모아 계속할 의향이 있다.\n\n유강스에 대해서는 별도 회고를 작성했으니 관심이 있다면 여기로 가보자.\n\n유연한 자세 함께 기르기\n\n테코톡\n\n우테코를 수료하기 위한 조건 중 하나는 반드시 테코톡을 진행하는 것이다. 예외는 없다.\n\n테코톡은 우테코에서 진행하는 말하기 역량과 소프트스킬을 기르기 위한 활동으로, 자신이 관심있는 주제에 대해 발표하는 자리다. 아무래도 발표이고 유튜브에도 올라가다보니 다들 하기를 꺼려하는 분위기였다. 발표자 모집 공고가 올라왔지만 나도 나중에 하지 뭐~ 지금은 뭐 발표할 것도 없고 바쁘잖아~라는 생각을 가지고 있었다.\n\n하지만 테코톡 발표자 마감 하루 전, 리마인드 공고가 올라오고, 스레드에 달린 코치님의 댓글을 보고 마음이 바뀌었다.\n\n앞으로 계속 바빠질텐데 지금이 제일 한가하지 않나? 매도 일찍 맞는 게 낫다고 빨리 끝내버리는 게 좋지 않을까? 다들 레벨 1 때 할 걸 후회한다고 하면 정말 지금 하는 게 좋지 않을까?\n\n결국 고민끝에 돌아가는 지하철에서 후다닥 발표 신청을 넣었던 기억이 난다. 마땅한 주제가 떠오르지 않았고 stream이 그나마 많은 사람들의 관심사일 것 같다고 생각했는데, 이미 매 기수마다 stream으로 테코톡이 올라와있었다. 하지만 stream이 그만큼 중요하다는 뜻이다. 나만의 색깔을 입혀 발표하면 되지 않겠냐?라는 지인의 말을 듣고 그대로 신청을 넣어버렸다.\n\n물론 테코톡을 대충 할 생각은 없었기에 stream에 대해 열심히 찾아보았고, 재밌는 발표가 하고 싶어서 보통은 다루지 않는 부분을 다뤄보고 싶었다. 그러던 중 해외 컨퍼런스 영상을 접했고 너무 유익해서 번역기까지 돌려가며 1시간짜리 영상을 몇 시간에 걸쳐 시청했다. 그리고 그 내용을 기반으로 테코톡을 준비한 결과 테코톡에서 좋은 반응을 얻을 수 있었다. 그리고 발표 시간보다 긴 시간동안 쏟아진 질문에 거의 모두 답할 수 있었다. 처음보는 크루들이 잘 봤다는 인사를 남겨주었고, 테코톡 스타라는 말을 듣기도 했다.\n\n테코톡이 숙제로 느껴질 수도 있겠지만 그 기회를 학습의 기회로 활용하면 좋겠다. 유튜브에 올라가는 발표라는 압박감을 역으로 이용하면 스스로 깊이 학습하도록 강제할 수 있다고 생각한다. 그리고 일찍 테코톡을 진행한 스스로를 칭찬👍해주고 싶다. 나만의 색깔을 입힌 훌륭한 테코톡이었다.\n\n아직 테코톡 영상이 유튜브에 올라가지 않아 볼 수 없다. 그리고 올라간다고 해도 발표 내용뿐만 아니라 질의응답에 나온 내용까지 포함해야 발표가 완성되었다고 볼 수 있다(한정된 발표 시간으로 인해 질문을 유도하고자 발표 자료에 모든 내용을 담지 않았다).\n\n하지만 걱정마시라!! 블로그 글에 (거의)모든 내용을 담아두었으니 테코톡 내용이 궁금하다면 지금 바로 확인할 수 있다! 😎\n\nJava Stream API (feat. The Performance Model of Streams in Java 8 - Angelika Langer)\n\n레벨 인터뷰\n\n레벨 1 마지막주, 레벨동안 무엇을 배웠는지 점검하는 레벨 인터뷰를 진행했다.\n\n레벨 인터뷰는 학습을 충분히 진행했는지에 대한 메타인지를 할 수 있도록 도와주지만, 면접 준비의 느낌도 강했다. 나는 인터뷰 시작 전 체크인 단계에서 모르는 내용에 대한 질문이 들어왔을 때 대응하는 경험을 해보고 싶다라는 말을 했다. 이 말 때문인지는 모르겠지만 솔라는 다른 크루들에게는 객체지향이나 TDD에 대해 질문하다가 갑자기 나에게는 파일 입출력을 할 수 있는가? 내부 동작 원리를 설명해달라라는 상상도 못한 질문을 던졌다. 결국 내 바람을 이룰 수 있었고(?) 탈탈 털리는 경험을 할 수 있어서 유익했다.🤯\n\n그 외에도 상속이 왜 객체지향적이라고 생각하는가?라는 질문에 대해 적절한 답변을 내놓지 못했다. 솔직히 상속보다 조합을 더 선호해서 답변하기 힘들었던 것도 있지만, 상속이나 조합이 왜 객체지향적이라고 생각하는지에 대해 깊게 고민해본 적이 없었다.\n\n결국 중요한 건 어떤 경험을 해봤다. 보다는 왜 그 경험을 하게 되었고, 그 과정에서 어떤 고민을 했으며, 어떤 결론을 내릴 수 있었는지 말할 수 있는 게 중요하다고 생각한다. 다시말해, 어떤 주제에 대해 나만의 철학을 완성하고 설명할 수 있어야 한다고 생각한다.\n\n스터디\n\n우테코에 가면 주도적인 자세를 가지고 싶다고 생각했다. 주도적으로 스터디나 세미나를 주도해보고 싶다고 생각했다. 그래서 내가 감당 가능한 선에서 스터디를 다양하게 진행해보았고, 기회가 있는 한 주도적으로 행동하고자 노력했다.\n\nAction Vim\n\n평소 vim을 즐겨쓰는 나는 다른 크루들에게 vim을 전도할 겸, 고착화된 나의 vim 습관에서 벗어나기 위해 vim 스터디를 열었다. 나를 포함해 총 7명의 크루가 모였고, 매주 30분씩 모여 각자의 vim 사용 꿀팁을 공유했다. 많은 크루들이 스터디가 끝난 이후로도 vim을 사용할 의향이 있다고 밝혔고, 그중 한 명은 해피해킹 키보드 중고 매물이 싸게 올라오자 바로 구매했다. 수십 만원이나 하는 키보드를 바로 구매할 정도의 의지라니, 나의 vim 전도가 성공적이었던 걸로.. ㅋㅋㅋㅋ 🤣\n\n우사인 스터디\n\n함께 데일리 미팅을 가지는 이웃 조에서 스터디를 진행한다길래 냅다 끼고싶다고 난입했다.\n\n인원을 나눠 격주로 블로깅 및 공유하는 자리를 갖자고 했으나 처음 한 번만 이루어지고 무산되었다. 대신 학습 테스트를 같이하거나 미션 코드 리팩토링을 함께 해보며 설계에 대한 고민을 하는 등 유익한 활동을 많이 했다.\n\n그건 그렇고 아직까지도 스터디 이름이 왜 우사인 스터디인지 잘 모르겠다 ㅋㅋㅋㅋ\n\n자수 마스터\n\n어느 날, 머랭이 이펙티브 자바를 읽고 같이 토론해보자고 제안을 해왔다. 우테코 목표 중 하나가 꾸준히 책읽기였던 나는 냅다 수락했고, 그렇게 자수 마스터(자바를 수련하여 마스터하자) 스터디를 만들었다.\n\n지금(방학)까지도 책을 열심히 읽고 매주 2번씩 모여서 스터디를 하고 있다. 악마의 변호사 자처하기를 좋아하는 머랭을 열심히 반박하며 근거에 기반해 설득하는 경험을 많이하고 있다. 또한 자바 내부 코드를 까본다거나 애매한 부분을 테스트해보면서 깊이있는 고민도 종종 하고있다.\n\n가장 최근에 재밌게 했던 경험은 EnumMap 내부를 파헤쳐보며 그 원리를 파악한 것이다. 납득하지 못하는 머랭을 설득시키기 위해 1시간 가량 열심히 설명했지만 결국 머랭이 처음부터 잘못봤던 것이라는 사실을 알았을 때는 허탈하기도 했다. 그래도 설득하는 과정에서 동작 원리를 더 짜임새있게 이해할 수 있어서 유익했다.\n\nEnumMap에 대한 학습 과정은 블로그에 정리해서 올려두었다. 관심있다면 읽어보자!\n\nEnumMap 파헤치기\n\n영말쓰\n\n6기 선배와의 수다타임에서 DH 취업하신 선배분들이 영어공부 열심히 하라는 조언을 하시며 어떻게 영어공부를 했는지 알려주셨다. 우리도 영어공부를 하기 위해 30분씩 일찍 등교해 영어로 이야기하는 영말쓰(영어 말하기 쓰터디)를 시작했다. 비록 나는 졸업 예정자가 아니어서 올해 DH 취업이나 우아한형제들에서 지원하는 영어회화 스터디는 입구컷당했지만 취업 목표가 아니라 내 성장을 위해 앞으로도 영말쓰를 계속해보려고 한다.\n\n기억에 남는 순간들\n주변 개발자와 속도를 맞추는 연습\n\n페어 프로그래밍이 끝나면 페어와 피드백을 주고받는다. 그리고 1번째 미션에서는 다음과 같은 피드백을 받았다.\n\n개발 역량이 높다고 생각합니다. 그래서 제가 모코라면 주변 페어와 속도를 맞추는 연습을 하면 더 좋을 것 같습니다. 주변 페어가 자신의 생각을 잘 이해하고 싱크를 맞추었는지 확인하는 습관을 가지면 더 좋은 개발자가 될 수 있다고 생각합니다.\n\n이후로 다른 미션을 할 때는 이를 인지하기 위해 노력했다. 페어에게 지속적으로 온전히 이해했는지 질문하며 조금은 천천히, 그러나 확실하게 짚고 넘어갔다. 모르는 내용이 있으면 설명해주고 납득할 때까지 기다렸다. 그러자 3번째 미션에서는 다음과 같은 피드백을 받을 수 있었다.\n\n인내심과 토론에 대한 적극성이 독보적인 강점이라고 생각합니다. 어려운 문제에 대한 해답을 찾아나감에 있어서 상대방이 넘겨짚고 가지 않도록 기다려주신 면모에서 함께 학습해가고자 하는 의지가 느껴졌습니다. 코드를 작성하는 과정에서 꾸준히 의견을 물어봐주시고 본인의 의견도 충분한 설명과 함께 전달해주셔서 지식적으로도 그 외적으로도 많이 배울 수 있었습니다. 지금까지 진행했던 페어 프로그래밍 중 가장 깊은 대화를 가장 오랫동안 했는데 힘들다는 생각이 들지 않았을 정도로 긍정적인 경험을 했습니다. 지금처럼 변함없이 페어의 의견을 물어봐주시고 함께 좋은 코드를 작성해나가도록 이끌어주시기만 하셔도 충분할 것 같다는 생각입니다! :D\n\n(피드백 보고 약간 감동받았다 🥹)\n\n나의 TDD는 최선이 아니었다\n\n레벨 1 마지막 미션 페어 프로그래밍이 나에게는 가장 힘들었다. 페어와 나는 (설득을 좋아하고 자기 주관이 확실하고 TDD를 좋아하는)성향이 완전 똑같았지만 TDD를 다루는 방향이 완전히 반대였다.\n\n나는 아무런 사전 설계도 없이 바로 테스트 작성부터 시작해서 차근차근 쌓아올리는 바텀-업 TDD를 선호했지만, 페어는 완벽한 사전 설계(객체 간 관계, 주고받는 메시지, 메서드 시그니처 등)에 기반하여 각 메시지를 TDD하는 탑-다운 TDD를 선호했다.\n\nTDD에 대한 성향이 완전히 반대인 우리는 시작부터 충돌이 매우 심했고, 둘 다 주관이 뚜렷해서 쉽게 한 쪽으로 기울지 않았다. 양쪽의 방식을 부분 수용해서 테스트를 하며 각 설계에 대해 깊게 파고들어보았지만, 기존의 내 방식에서 느려지기만 할 뿐 별다른 메리트를 찾지 못했다(나중에 페어와 회고하며 알게 된 사실로, 당시의 방식은 양쪽의 단점만 모아놓은 방향이었다). 결국 페어를 설득하여 이틀차에 내 방식의 TDD로 미션을 처음부터 다시 시작했다.\n\n미션을 끝낸 후 페어와 회고해보니, 페어는 예상과 달리 설계를 따로 하지 않고 시작했음에도 기존 설계가 바뀌거나 하는 일이 거의 없었음을 긍정적으로 평가했다. 나도 완전한 백지 상태에서 시작하는 내 TDD 방식보다는 조금이라도 설계를 하고 시작하는 방향이 훨씬 효율적일 것이라고 회고했다. 회고를 하면서 우리는 둘의 TDD 성향을 종합하면 더 개선할 수 있겠다고 생각했다. 결국 추상적으로라도 전체적인 그림을 그려본 후, 그 속에서 바텀업 TDD를 해나가는 것이 더 좋겠다는 결론을 내릴 수 있었다.\n\n다만 그 방식으로 아직 개발해보지는 못해서 이 부분이 아쉽다. 레벨 2에는 이 방식을 시도해봐야겠다.\n\n페어의 의견 따라가보기\n\n나는 설득되지 않으면 그대로 넘어가지 못하는 성향이 있다. 때로는 좋을 수도 있겠지만 페어 프로그래밍에서는 좋은 자세가 아니었다. 위의 상황(마지막 페어)에서 이 단점을 크게 체감했다. 내가 이해하지 못하는 방향이라도 일단 따라가보면 상대방이 어떤 생각으로 해당 구조를 선호했는지 직접 느껴볼 수 있다. 그 방향이 더 적절했다면 좋은 것이고, 아쉬운 부분이 있다 하더라도 내 방향이 틀리지 않았음에 대한 근거가 될 수 있는 것이다. 레벨 2에서는 일단 따라가보는 자세도 가져보고 싶다.\n\n체스?🙂‍↔️ 장기!!\n\n레벨 1의 마지막 미션은 악명이 자자한 체스 미션이었다. 선배 기수 분들도 우테코에서 손에 꼽는 어려운 순간 중 하나를 체스 미션으로 꼽았다. 그래서인지 직전 미션 때부터 미리 체스 룰을 공부하고 연습하는 모습을 캠퍼스에서 자주 목격할 수 있었다. 나는 그럴 시간도 없었지만 시간이 있었다 해도 그러지 않았을 것이다. 아무런 설계없이 진행하는 TDD를 선호하는 성향에서 알 수 있듯, 나는 도메인을 이해하는 것도 미션에 포함된다고 생각한다. 그래서 미리 도메인을 학습하고자 한다면 그건 미션 경험을 해치는 것이라고 생각했다.\n\n그리고 마지막 미션이 시작되는 날 아침, 캠퍼스는 유난히 시끌벅적했다.\n\n미션이 바뀌었어!! 체스가 아니라 장기야!!!\n\nㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 😆😆😆\n내가 아는 우테코였다. 당일 아침에 미션을 바꿔버리다니, 역시 내 기대를 져버리지 않았다. 나는 체스를 미리 준비하지 않아서 전혀 상관없었지만, 열심히 준비한 크루들은 많이 당황했을 것 같다.(미리 준비하는 것이 잘못됐다는 말은 절대 아니다! 오히려 칭찬받아 마땅하다고 생각한다)\n\n(지금보니 당일 아침에 미션 변경 완전 발칙하네~ 🤣)\n\n발칙한 시도를 즐기기\n\n레벨 1을 진행하면서 내가 좋아하는 단어가 생겼다. 발칙한이라는 표현이다.\n\n처음 사용했을 때는, 지금껏 생각해보지 못한 새로운 시도를 즐기는 이라는 의미로 사용했다. 패키지 분리와 접근제어 제한을 통해 클래스명을 단축한다거나, inner enum을 만든다거나 하는 것이었다. 발칙한 시도라는 말은 내게 있어 큰 칭찬이었지만, 재밌어하는 크루도 있는 반면 어떤 크루(특히 머랭)는 칭찬 맞냐고 어이없어했다.\n\n사실 발칙하다라는 말은 사전적 의미가 매우 부정적이다. 국립국어원 표준국어대사전을 보면 그 의미가 하는 짓이나 말이 매우 버릇없고 막되어 괘씸하다라고 한다. 처음에는 이걸 보고 깜짝 놀랐지만, 생각해보니 맞는 말이었다. 내가 생각하는 발칙한 시도는 지금껏 생각해보지 못한 것인데 다른 관점에서 보면 버릇없고 막되어 괘씸해 보일수도 있다. 오히려 그렇기에 지금껏 생각해보지 못한 것이고, 버릇없고 막되어 괘씸하다고 해서 꼭 나쁜 것만은 아니라고 생각한다.\n\n이런 내 생각을 정확히 대변해주는 기사를 찾았다.\n\n그들의 ‘발칙함’은 어디서 나왔을까?\n\n일상에서 우리는 ‘발칙하다’라는 말을 쓰곤 한다. 사전에 따르면 ‘발칙하다’는 “하는 짓이나 말이 매우 버릇없고 막되어 괘씸하다”라는 뜻이다. 이 같은 뜻 때문에 ‘발칙하다’라는 말을 부정적으로 생각하는데, 단어의 부정적 의미와는 별개로 ‘발칙함’이 필요한 영역이 존재하다. 바로 ‘예술’이다. 예술의 영역에서는 도발과 직설이 새로움을 만들어내기 때문이다.\n\n나는 프로그래밍도 일종의 예술이라고 생각한다. 정답이 존재하지 않고 코드에 개개인의 철학이 담겨있으며, 자신이 추구하는 방향을 확립해나가는 과정이기 때문이다. 이 과정에서 발칙함은 필수불가결하며, 포비의 반란군을 양성한다라는 말과 비슷한 맥락이라고 생각한다.\n\n레몬 놀리기\n\n하루는 장기 미션 리팩토링 단계에서 레몬 옆자리에서 코딩을 했다. 그러자 레몬이 내게 궁성 내부를 어떻게 구현할지 질문했다. 나는 레몬에게 말했다.\n\n내 방법을 알려주면 그게 정답이 되어버릴 수도 있을 것 같다. 혼자 힘으로 해결하고 다시 오면 그때 내 방법을 알려주겠다.\n\n레몬은 혼자 힘으로 문제를 해결하기 위해 끙끙댔고, 나는 그런 레몬을 옆에서 열심히 놀렸다.\n\n정말이지 너무 재밌었다. 🤣\n레몬도 재밌게 생각했는지 (당시 마니또 중이었는데)그 상황이 내 마니또 미션이라고 오해하고 있었다.\n\n다만 다음날 목에 담이 걸려서 등교 못하고 병원에 갔다는 DM이 왔을 때는 미안한 마음이 들었다.\n에이~ 설마 나 때문이었겠어!? 🙄\n\n기타\n도시락\n\n레벨 1의 대부분은 캠퍼스에 밤늦게까지 남아서 공부하며 보냈다. 하지만 점심 저녁을 모두 밖에서 사먹자니 식비 부담이 장난없었다(서울 물가 😱). 한끼에 10,000원씩 주 10회 총 4주 밖에서 먹으면 한달 식비만 40만 원이 깨진다. 월세 내고 공과금 내고 식비 내고.. 하면 생계가 위험했다.\n\n그래서 도시락을 싸보기로 했다. 하루에 한 끼만 도시락을 먹어도 이론상 한달에 20만원씩은 절약할 수 있었다. 처음은 가볍게 에그마요 샌드위치부터 시작했다. 시간을 덜 들이려고 에그마요 소스를 쿠팡에서 샀지만 딸기잼이나 할라피뇨, 맛살 등 이것저것 같이 사버렸다.\n\n며칠 도시락을 싸오다보니 다른 크루들과도 도시락을 나눠먹고 색다른 요리도 해보고 싶었다. 종종 샌드위치를 나눠먹긴 했지만 이걸 계속하자니 식비 절약에서 멀어지고 오히려 바빠지기만 할 것 같았다. 고민 끝에 크루들에게 의사를 물어보고 종종 재료비를 걷어 맛있는 요리를 해오기로 했다.\n\n평소 요리를 자주하지는 않았지만 좋아하던 도시락을 싸면서 새로운 요리를 많이 시도해볼 수 있었다. 다들 항상 맛있게 먹어줘서 너무 고마웠다. 레벨 2에는 어떻게 될지 모르겠지만 레벨 1에서의 도시락 라이프는 만족스럽게 끝난 것 같다.\n\n도시락 나눠먹기를 처음 추진할 때 주변 크루들은 내가 부담스럽지 않을지 걱정해줬다. 하지만 (지금도 그렇지만 특히)당시의 나는 새로운 시도를 즐기는 학습 마인드셋 러버였기 때문에 아래 생각을 하면서 가볍게 시작할 수 있었다.\n\n일단 해보고 힘들면 그만두지 뭐, 아무한테도 민폐끼치지 않는 거잖아!?\n\n레벨 1동안 준비했던 도시락 메뉴는 다음과 같다.\n\n(에그마요, 불닭에그마요, 치킨, 돈까스)샌드위치 / 제육볶음 / 김치찌개 / 카레 / 마파두부 / 마라샹궈\n\n데일리 크루 피드백\n\n레벨 1이 끝나갈 무렵, 도기가 데일리 미팅 주제로 크루 피드백북을 준비해왔다. 롤링페이퍼처럼 한명씩 돌아가며 크루에게 피드백을 해주는 시간이었다.\n\n조원들은 (다른 크루들에게도 그랬지만)나를 대체로 긍정적으로 평가해주었다. 받은 피드백을 간단하게 추려보면 다음과 같다.\n\n개발을 잘하고 논리적이고 자신의 생각에 대한 확신이 있다.\n소극적으로 보이면서도 뭐든 앞장서서 이끌어가려고 한다.\n무슨 질문을 해도 재미있게 받아주고 질문의 의도를 캐치해서 적절한 답변을 해준다.\n호기심이나 흥미로운 걸 놓치지 않는다.\n항상 바쁘게 뭔가를 하고 있다.\n\n다들 나를 좋게 봐줘서 너무 고마웠고, 열심히 지낸 걸 다른 크루들도 알아줘서 뿌듯했다. 앞으로도 열심히 해야겠다는 동기부여가 되었다.\n\n레벨 1 목표\n\n우테코에 들어오기 전, 우테코에 와서 어떤 목표를 이루고 싶은지 간단하게 정리해봤다. 나는 그 목표들을 잘 달성했을까?\n\n주도적인 자세\n\n레벨 초부터 여러 슬랙 채널을 만들거나 스터디를 만들어 운영하는 등 주도적인 자세를 가지기 위해 꾸준히 노력했다. 데일리 크루들에게 피드백받은 내용에서도 언급되었으니 이정도면 잘 달성했다고 볼 수 있겠다!!\n\n많이 놀아보기\n\n평소 집밖으로 잘 나가지 않고 게임을 좋아한다. 그래도 우테코에서는 여러 사람들과 만날 수 있으니 놀러다닐 기회도 많아질 것 같았다. 하지만 현실은... 넘나 바쁜 것 😭\n\n모르는 크루들과 딱 한 번 보드게임카페를 가본 것 말고는 데일리 크루들과의 회식 제외하고 어디 놀러가본 적이 없다. 그만큼.. 열심히 했다는 뜻이니까.. ㅠㅠ\n레벨 2부터는 더 바빠질텐데 놀러다닐 수 있을지 모르겠다. 아마 우선순위가 높은 목표는 아니라서 그대로 방치당하지 않을까 싶다. 🙄\n\n책 많이 읽기\n\n평소 책읽는 속도가 굉장히 느린 편이어서 책을 통한 지식 습득은 좋아하지만 독서를 꺼려한다. 그래도 우테코 온 김에 책 열심히 읽어보자!! 라고 생각했고, 한 달에 한 권 정도는 읽을 수 있지 않을까?? 싶었다.\n\n하지만 책은 내 생각보다 훨씬 길어서 읽기가 쉽지 않았다. 그래도 이펙티브 자바 스터디를 하며 책을 꾸준히 읽고 있어서 이 목표는 잘 지키고 있다고 생각한다. 책은 빨리 읽는다고 좋은 게 아니니까!!\n\n블로깅 꾸준히 하기\n\n우테코 하면서 놀면서 책도 읽으면서 블로깅까지 하는 건 정말 쉽지 않겠다고 생각했다. 그래서 2주에 한 번 블로깅하기로 목표를 설정했는데 이것마저 지키기 쉽지 않았다.\n\n레벨 1을 보내면서 블로깅한 건 단 하나.. 테코톡 포스팅뿐이다🥲. 그래도 미뤄뒀던 기술부채 포스팅과 레벨 1 회고를 방학들어서 열심히 하고있으니 이걸로라도 위안을 삼아야겠다.\n\n레벨 2에는 한 달에 하나 블로깅하기 정도로 목표 수준을 낮춰야겠다... 🫠\n\n운동하기\n\n진짜 바빴다는 핑계를 대며 도망치겠다. 🏃\n\n그래도 살기위해 운동을 해야할 것 같아서 워니에게 물어보니 생활 속 자그마한 운동을 찾아보라는 피드백을 받았다. 레벨 중후반부터는 집에서 틈틈이 스쿼트를 하고 하교할 때 역에서 집까지 달려가기를 하고있다.\n\n운동.. 해야지 해야지 하는데 진짜 시간이 안난다. 레벨 2에서는 한 번에 팔굽혀펴기 30개 달성하기를 목표로 해보자.\n\n회고\n레벨 1 성장 그래프\n\n우테코에서 레벨 1 회고 시간을 열어줬다. 그 곳에서 다른 크루들과 모여 자신이 어떤 성장을 거쳤는지 가시화해보았다.\n\n(노란색이 소프트스킬, 초록색이 기술적 성장, 파란색은 다른 크루의 피드백이다.)\n\n초반에는 이렇다 할 기술적 성장을 이루지 못했다. 하지만 중반부터 점차 나만의 학습법을 찾아날 수 있었고, 후반부에는 수많은 기술적 성장을 몰아넣을 수 있었다.\n\n다시보니 너무 무난한 우상향 그래프인데 절대 의도한 게 아니다. 과연 레벨 2에도 우상향이 나올 수 있을지, 아니면 크게 한번 바닥을 찍을지 기대된다. 바닥을 찍는 건 무서운 일이지만, 더 큰 성장을 위해 반드시 필요한 과정이라고 생각하기에 걱정은 하지 않는다.\n\n우테코 사람들은 완전 잘하겠지?\n\n우테코에 오기 전까지는 우테코 수료생이라고 하면 막연하게 엄청 대단한 사람들이라고 생각했다. 하지만 막상 직접 와보니 그들은 우리와 같은 평범한 대학생, 취준생이었다. 우테코에는 대단한 사람들만 오는 게 아니다. 우테코에서 살아남은 사람들이 대단한 것이다. 그리고 우테코의 선발 기준은 이런 밀도있는 학습 환경 속에서도 포기하지 않고 끈질기게 버틸 수 있는 사람들을 뽑는 것이었다.\n\n오히려 실력만 평가한다면 우테코 크루들은 다른 1~2년차 취준생에 비해 못할 수도 있다. 하지만 끊임없는 학습 환경 속에서 자신만의 학습법을 찾고 좌절을 겪기도 하는 우테코 크루들은 어느샌가 엄청 대단한 사람이 되어있을 것이다(다른 취준생은 그런 경험이 없을 거라는 뜻이 아니다. 우테코의 경험 밀도가 매우 촘촘하다는 의미이다).\n\n불안감과 동기부여\n\n사람들의 실력이 천차만별인 이곳에서는 많은 크루들(특히 비전공자 분들)이 힘들어하거나 불안해하는 모습을 볼 수 있다. 주변 크루들에 비해 실력이 부족하다는 생각이 든다면 그 크루는 우테코 생활이 많이 힘들수도 있다. 하지만 한편으로는 그런 사람들이 진심으로 부럽다. 힘든만큼 다른 사람들에 비해 훨씬 더 많은 성장을 이룰 수 있을 거라고 확신한다.\n\n이 점을 인지하더라도, 우리는 결국 사람이기에 다른 사람과 자신을 비교하며 비관적인 생각이 들수도 있다. 그럴 때는 타인과의 비교 대신 과거의 나와 비교해보자. 이전보다 성장한 나 자신을 돌아보며 동기부여를 얻자. 최선을 다하고 있다면, 스스로를 너무 옥죌 필요는 없다.\n\n우테코만의 장점\n\n우테코에서는 이런 말을 한다.\n\n물고기를 잡아주지 않는다.\n물고기 잡는 법도 알려주지 않는다.\n물고기를 잡을 수 있는 환경을 만들어줄 뿐이다.\n\n실제로 우테코에서는 우리에게 교육을 많이 시켜준다거나, 짱짱한 교육자료를 거의 주지 않는다. 우테코는 긴 자율시간 속에서 나만의 학습 방법을 찾아나가는 과정이다.\n\n물고기를 잡을 수 있는 환경은 무슨 의미일까? 우테코에는 나보다 훨씬 열정적인 사람들만 수십 명이 모여있다. 이런 사람들과 같은 고민을 하면서 하루종일 함께한다면 어떤 일이 벌어질까? 내가 고민하는 내용을 옆자리 크루도 똑같이 고민하고 있다는 뜻이고, 그 속에서 논의하며 끊임없이 나만의 개발 철학을 부수고 다시 만들어나간다. 우테코만의 가장 큰 장점은 뭐니뭐니해도 같은 고민을 하는 사람들과 논의하기 좋은 환경을 제공하는 것이라고 생각한다.\n\n우테코가 정답인가?\n\n계속 찬양만 한 것 같다. 정말 우테코가 정답이라고 할 수 있을까? 단언컨데 그렇지 않다.\n\n당신이 어느 곳에 있든 상관없다. 의지만 있다면 성장할 방법은 넘쳐난다. 우테코는 그 방법을 찾는 과정을 약간이나마 도울 뿐이다.\n\n만약 당신이 우테코에 오고싶었지만 안타깝게 떨어졌다고 해도 절대 좌절할 필요 없다. 최선을 다한다면 그 곳이 곧 우테코다. 그러니 각자의 위치에서 최선을 다하자.\n\n마지막으로 하고 싶은 말\n\n레벨 1을 보내면서 기술적 성장도 많이 이뤘지만 개인적으로는 소프트스킬이 가장 유익했다.\n\n유연함의 힘 책을 흥미롭게 읽었는데, 그중에서도 학습 마인드셋이 너무 마음에 들었다. 완전 내가 추구하는 마인드셋 그 자체였다. 내가 마주하는 모든 상황은 성과를 증명하는 자리가 아니라, 더 나은 내가 되기 위한 과정이다. 그러니 미래를 걱정하기보다는 먼저 행동해보자. 설령 아쉬운 부분이 있더라도 피드백을 통해 개선하면 된다.\n\n학습 마인드셋을 인식하고 지속적으로 도전을 이어가다 보면, 그것이 마치 무적의 방패처럼 느껴지기도 한다. 물론 잘못 사용하면 무책임함으로 이어질 수 있지만, 올바르게 활용한다면 무엇이든 해낼 수 있게 돕는 든든한 서포터가 되어줄 것이다.\n\n계속해서 도전하자. 스스로를 안전지대 밖으로 밀어내 보자. 그리고 평소라면 하지 않았을 선택에 과감히 도전해 보자.\n\n그 속에서 분명 성장하는 나 자신을 발견할 수 있을 것이다.\n\n송선권\n팔로우\n이전 포스트\n유연한 자세 함께 기르기\n9개의 댓글\n댓글 작성\n주노\n4일 전\n\n밀도가 꽉찬 레벨1이였네요!!\n멋져요 ✨✨\n\n1개의 답글\n허준기\n4일 전\n\n테코톡 기다리는중입니다\n\n1개의 답글\n도기\n4일 전\n\n좋은데요?~\n\n1개의 답글\n강구\n3일 전\n\n🫡\n\n1개의 답글\n멍두\n약 1시간 전\n\n글 잘 썼다\n\n답글 달기\n관련 채용 정보\n월급쟁이부자들\n백엔드 엔지니어(BE) 시니어\n백엔드 엔지니어로 월급쟁이부자들과 함께 성장하며, Java/Kotlin 기반의 백엔드 애플리케이션 개발을 주도할 기회를 잡아보세요. 유니콘 목표의 경제 콘텐츠 플랫폼에서 고객의 행복한 노후를 돕는 실질적인 임무를 수행하며 가치 있는 경험을 쌓을 수 있습니다.\n백패커\n[아이디어스/텀블벅/텐바이텐] 클라우드 엔지니어 (1년 이상)\n아이디어스와 텀블벅이 함께하는 백패커에서 클라우드 엔지니어로의 기회를 잡아보세요. AWS와 Kubernetes를 활용한 효율적인 개발 환경에서 함께 성장하며 창작 생태계를 혁신할 수 있습니다.\n어스얼라이언스\n백엔드 개발자 (신입~2년)\n금융을 콘텐츠로 혁신하는 어스얼라이언스에서 백엔드 개발자를 모집합니다. NestJS 기반의 개발 경험이 있다면, 성장과 함께 금융 콘텐츠 혁신의 주역이 될 수 있는 기회를 놓치지 마세요!",
    "tags": [
      "우아한테크코스",
      "회고"
    ],
    "commentCount": "9"
  },
  {
    "title": "[코드잇] 스프린터의 봄 🌸 : Sprint Conference 2025 참여 후기",
    "description": "🎉 코드잇에서 스프린터들을 위한 컨퍼런스를 개최하였습니다.커리어 코치의 채용관련 특별 강연, 트랙별 커리어 인풋 세션, 직무별 멘토와 네트워킹 QnA세션, 그리고 참여자 전체 네트워킹 세션, 추첨 이벤트 등으로 구성되어 있었습니다.어려운 경제상황 때문에 값 높은 경력...",
    "link": "https://velog.io/@shinminsoo317/%EC%BD%94%EB%93%9C%EC%9E%87-%EC%8A%A4%ED%94%84%EB%A6%B0%ED%84%B0%EC%9D%98-%EB%B4%84-Sprint-Conference-2025-%EC%B0%B8%EC%97%AC-%ED%9B%84%EA%B8%B0",
    "author": "minso0317.log",
    "date": null,
    "comments": "0개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/shinminsoo317/post/2bfebb8b-21ae-45d4-8add-eececffbe599/image.jpg",
    "content": "minso0317.log\n로그인\nminso0317.log\n로그인\n[코드잇] 스프린터의 봄 🌸 : Sprint Conference 2025 참여 후기\n신민수·어제\n팔로우\n6\nCodeitConference2025스프린터의 봄스프린터의봄스프린트컨퍼런스코드잇코드잇스프린트\n🎤 코드잇 특별강연\n목록 보기\n2/2\n\n🎉 코드잇에서 스프린터들을 위한 컨퍼런스를 개최하였습니다.\n\n이번 컨퍼런스의 이름은 스프린터의 봄 🌸 : Sprint Conference 2025 였습니다.\n\n커리어 코치의 채용관련 특별 강연, 트랙별 커리어 인풋 세션, 직무별 멘토와 네트워킹 QnA세션, 그리고 참여자 전체 네트워킹 세션, 추첨 이벤트 등으로 구성되어 있었습니다.\n\n\n개인적으로 개발공부를 시작하게 된지 3개월이 되었고 나름대로 열심히 공부를 하고는 있지만, 첫 번째 정체기가 찾아왔고 공부하는 것에 비해 잘 늘지도 않고 조금 힘든 시간을 보내고 있습니다.🥲 그런 이 타이밍에 컨퍼런스가 개최되어 참여하게 되었고 강연자분들의 좋은 강연 내용과, 다른 트랙의 스프린터 분들의 적극적인 참여를 함께하면서 다시 동기부여를 얻고 힘을 낼 수 있을 것 같습니다!! 한 번 듣고 잊기에 너무 아쉬운 내용이고 참여하고 싶었지만 개인 일정 때문에 참여하지 못하신 스프린터 분들이나, 코드인 스프린트에 참여하고 싶으셔서 알아보고 계시는 분들께 도움이 되고자 블로그에 기재하게 되었습니다. 작성하다보니 생각보다 너무 자세히 작성하게 되었고, 이 모든 내용은 코드잇과 강연자님의 소중한 자작권이기 때문에 문제가 될 경우 비공개 처리를 하거나 글을 수정할 것 같습니다.\n스프린터의 봄 🌸 : Sprint Conference 2025 컨퍼런스의 내용 및 후기를 아래에 정리해 보았습니다.\n\n\n\n⏰ 0교시\n🧐 채용 트렌드\n1. 회사가 왜 신입사원을 뽑는지, 회사 입장에서 무슨 생각을 하는지 파악하자\n어려운 경제상황 때문에 값 높은 경력은 부담되고, 신입사원 교육에 돈을 쓰고 싶지 않은 상황, 주니어를 뽑아 바로 실무에 투입시킬 수 있을까?에 대한 고민\n\n\n당장 대규모 공채를 하기엔 부담스럽고, 제일 급한 인력만 바로바로 채용할 수 있을까?\n\n\n어렵게 신입을 뽑았는데, 금방 퇴사하면 어떡하지?\n\n우리(취준생)가 취업을 하기 위해 고민을 하는 것 처럼 기업도 신입사원을 뽑을 때 많은 고민을 합니다.\n회사가 원하는 신입의 기준, 그에 대한 고민이 곧 그 회사의 채용 트렌드가 될 수 있습니다.\n\n\n\n\n기업들이 신규 채용 관련에 대한 애로사항으로 몇 가지 대답하였는데,\n\n적합한 인재 찾기, 채용 후 이직/퇴사 등으로 인한 조기퇴사자 발생, 채용과정에서 이탈자 발생 등 어렵게 뽑았는데 결국 오래가지 못하는 사람 때문에 걱정을 합니다. 기업도 우리처럼 리스트를 짊어지고 싶어하지 않습니다.\n기업 입장에서 신입을 선별하는 과정에서의 기술, 능력 외에 중요한 한 가지는 내적 동기가 명확한 사람, 기업과 같은 목표 또는 동기로 (가능한 오래)함께 할 수 있는 사람을 원할 것 입니다.\n\n\n\n이를 모티베이션 핏, 컬쳐 핏으로 볼 수 있습니다.\n\n예를들어 기업이 중요하기 여기는 가치와 지원자의 성향이 잘 맞는지, 기존의 조직과 잘 융화될 수 있는 태도 또는 커뮤니케이션을 가지고 있는지?에 대해 가늠하기도 하고, 왜 이 일을 하고 싶은지? 앞으로 어떤 방향으로 성장하고 싶은지? 등 지원자의 목표 등을 체크하여 판단할 것 입니다.\n\n\n\n\n우리는 기업이 신규채용을 하면서 지원자에게 내어놓는 질문을 잘 캐치하고, 질문에 대한 답변을 지금까지 나의 경험을 토대로 증명하면서 내가 기업이 원하는 사람이라는 것을 나타내야 합니다.\n이러한 질문은 채용공고에 꽤나 명확하게 기재되어 있기도 합니다. 즉 무작정 이력서를 작성하고 지원하는게 아니라, 가능하다면 기업이 원하는 대답을 말해주는 이력서, 포트폴리오를 준비하는게 우리의 숙제입니다.\n\n\n\n🎯 취업준비 전략\n📌 부트캠프를 들으면서 내가 해야할 일(1)\n\n왜? 무엇 때문에? 나와 직무에 대한 질문을 끊임없이 던져야 합니다.\n\n내가 취업 이후에도 이 업무에서 버티고 성장한 사람인지(지속 가능성), 얼마나 진심으로 몰입해서 하는지(설득력), 같은 상황에서도 타인과 다른 나만의 이야기가 있는지(차별화) 알아가야 합니다.\n\n\n\n📌 부트캠프를 들으면서 내가 해야할 일(2)\n\n기술적 판단 근거에 대한 질문을 가져야 합니다.\n\n과제/프로젝트를 진행하면서 좋은 결과물을 만들어내는 것에만 집중하는 것이 아니라,\n결과물을 위한 기술 선택과정과 판단기준을 가지면서 사고력키우고, 문제의식과 그에 대한 대응 방식을 통해 능동적인 해결 능력을 가져야 합니다.\n\n다시말해 왜 이 기술을 사용했는지에 대한 이유와 고민, 대답하는 과정을 반복하고 체화시켜야 합니다.\n\n\n\n📌 부트캠프를 들으면서 내가 해야할 일(3)\n\n우리는 이력서를 작성하거나 면접을 볼 때, 우리가 하고싶은 이야기를 합니다. 반면에 듣는 사람은 면접관입니다.\n이말은 내가 하고싶은 말을 하는 것 보단 면접관이 듣고싶은 이야기를 면접관의 언어로 정리하는 연습을 해야합니다.\n\n프로젝트를 진행하면서 우리가 겪는 문제와 갈등은 면접관이 듣고 싶은 이야기를 만들어 낼 수 있는 절호의 기회입니다. 기술에 대해 생각하고 왜 이 기술을 사용하게 되었는지 판단할 수 있고, 팀원과 협업을 하면서 발생하는 다양한 이슈들을 어떻게 해결하는지 이야기할 것 들이 쏟아질 것 입니다.\n\n이 과정들을 그냥 넘기지말고 직면한 문제를 적극 활용하여 어떻게 고민하고 해결하였는지 그 순간을 기록하며 나중엔 면접관의 언어로 정리하면 좋을 것 같습니다.\n\n면접관의 시각으로 미리미리 고민하면서 나에 대해 깊게 탐구해 나가면 부트캠프 후에 더 많은 것들을 얻어가는 나를 발견할 수 있을 것 입니다.\n\n\n\n👩🏻‍💻 커리어 프로그램\n\n코드잇 스프린트 부트캠프는 본 과정부터 수료 후까지, 단계별로 취업준비를 함께 합니다. 이것은 제가 코드잇 스프린트를 선택한 큰 이유 중 하나인데, 실제 지금까지 3개월 정도 진행하면서 개발 커리큐럼 외에도 커리어미션 커리큘럼을 함께 진행하면서 나의 경험을 분석하고 구조화하는 작업들을 하였습니다.\n\n수료 후엔 서류준비, 이력서 멘토링 및 업데이트, 각종 모의 면접 등을 진행하는 커리어 프로그램이 준비되어 있어서, 코드잇은 스프린터들의 취업을 위해 끝까지 함께 달린다고 합니다.\n\n지금까지의 경험(나의 개발, 비개발 경험)을 토대로 어떻게 이야기를 작성하냐에 따라 이력서의 내용은 달라질 것 입니다.\n\n나의 경험, 강점을 분석하여 자기이해를 하고, 경험을 더 효과적으로 만들기 위해 STAR 기법을 활용하여 나의 경험을 유의미하게 정리하고 구조화하여 전달하는 연습을 하는 것이 좋습니다.\n\nSTART기법(Situation 상황 + Task 과제 + Action 행동 + Result 결과 + Takeaway 배운점)\n\n\n\n📌 부트캠프 기간동안에\n\n어떤 목적을 가지고 무엇을 했는지, 어떤 문제를 만나고 어떻게 해결하였는지(기술적 접근, 협업 방식 등), 어떤 결과를 만들었는지\n즉, 갈등/문제 상황에서 무엇을 하였고 어떻게 해결하였는지를 스스로 정리할 수 있어야 하고, 커리어 미션 등을 통해 이러한 부분을 미리 준비하고 연습하면 포트폴리오 작성에 큰 도움이 될 것 입니다.\n\n\n\n📌 커리어 프로그램을 통해\n\n지원하는 직무에 적합한 인재임을 어필하기 위해서 어떤 경험을 강조해야하는지, 앞으로 어떤 것들을 학습하고 보안해야 할지 점검할 수 있고, 탄탄한 취업 멘토링 노하우를 보유하신 현직자 멘토님들과 1:1 맞춤 멘토링으로 이력서 및 포트폴리오를 완성할 수 있다고 합니다.\n\n커리어 프로그램을 진행하면서 서류 합격률을 높이고, 막막한 면접 준비를 체계적인 가이드를 통해 명확한 방향을 잡을 수 있다고 하니 부트캠프 수료 후의 준비과정도 기대가 되고 커리어 프로그램으로 꼭 취업에 성공해보고 싶다는 생각이 들었습니다.\n\n\n\n\n\n\n⏰ 1교시 트랙별 커리어 인풋 세션\n💻 개발자란?\n\n프로그래머는 코딩만하는 사람이 아니다!!\n강연자 추천영상: 배달의민족 CEO에게 뽑고 싶은 개발자를 물어보았다\n\n개발자 == 문제해결사!!\n\n놓여진 문제해결을 위해 무엇을 해야할까?를 기술적으로 고민하고 해결하는 사람\n\n개발자를 코더(coder)라고 하지 않고 프로그래머라고 하는 이유는 단순히 코딩만을 하는 직업이 아닌 문제해결을 위해 고민하고, 알고리즘을 짜고, 어떻게 해결해야 하는지, 현실적인 정책과, 기술적인 문제파악 등 다양한 것을 생각하기 때문에..\n\n\n\n📌 다양한 개발직군\n프론트엔드\t백엔드\t데이터베이스\n사용자가 직접 상호 작용하는 부분을 개발\n유저의 키보드, 마우스, 터치 등에 반응하여 다양한 요구사항 해결\t웹 서비스에 가장 필수적인 직군\n데이터 베이스를 관리하고 데이터를 처리하기 위한 서버부터 인프라 환경까지 구축\t데이터 분석과 예측 모델링, 알고리즘 개발을 하는것을 넘어\n데이터가 흐르는 인프라와 파이프라인 구축\n모바일 앱\n하이브리드앱\n웹\nUX엔지니어\n3D, 그래픽\n게임클라이언트\tAPI 개발\n인프라 개발\nDBA\nDevOps\n보안\n게임 서버\tData Analyst\nData Engineer\nData Scientist\nMLOps Engineer\nBusiness Intelligence\n🚨 취업 컨설팅 주의사항\n멘토, 강사들의 조언을 너무 다 믿으려고 하지 마세요.(모두 각자의 상황은 달랐다. 참고하되 맹신하지는 말아라.)\n오늘 들은 이야기를 일반화하지 마세요.(위와 같은 맥락이다. 상황은 항상 바뀌고 정답은 없다.)\n너무 현실적이거나 슬픈 이야기는 적당히 걸러들으세요.(지레 겁먹고 감정소모하지 말자.)\n열린 마음으로 들어주세요.\n\n▪︎ 취업 특강 같은 이야기를 들으면 시야도 넓어지고 도움이 되는 이야기들이지만 이처럼 무조건 일반화하고 맹신하여 그 틀에 갇히지 않도록 해야할 것 같습니다.\n\n\n\n🫡 취업 성공 전략\n📌 채용 공고 읽기\n\n채용공고의 자격요건에 공통적으로 들어가는 내용들이 있습니다. 그걸 파악하고 준비하도록 합시다.\n\n채용공고, 우대사항 등에 다양한 내용들이 있습니다. 하지만 그것에 대해 과몰입하거나 딴길로 새지말고 진짜 중요한 것이 무엇인지 파악합시다.(예시, 우대사항에 영어, 일본어 등 외국어 업무 진행이 가능한 분 => 이것 때문에 갑자기 외국어 공부 시작..., 최신기술이 내용에 적혀있다고 기본기를 모르는데 최신기술 여러가지를 얕게 공부하는 것 등...)\n\n\n\n📌 채용 공고 해석하기\n\n[자격 요건]\n\n우리 회사에 이력서 넣을 자격\n최소한 우리회사에서 일하려면 이정도는 할 줄 알아야 한다.\nCS(OS, 알고리즘, 자료구조, DB, 네트워크 등)기본 지식\n\n[우대사항]\n\n우리는 못하는데 와서 해주세요\n우리가 하고 있는데 자격요건에 넣기는 어렵지만 배워서 해주세요\n지금 당장은 몰라도 되지만 와서 공부해야되요\n입사하면 할 일\n\n모두 이렇다는 것은 아니지만 해석해서 어떤걸 준비해야하는지 파악할 수 있습니다.\n\n자격 요건에 더 집중하고 우대사항은 과몰입하지 않는 선에서 편하게 해석하는 것이 좋습니다.\n\n\n\n📌 타겟 그룹화\n\n내가 원하는 기업 타겟을 설정합시다.\n\n어떤 회사를 원하는지, 회사를 선택할 때 내가 어떤 것을 우선순위로 중요하게 여기는지(예시: 환경, 근무지, 연봉, 성장, 사수, 복지 등) 파악합시다.\n\n회사가 우리를 파악하는 것 처럼 우리도 회사를 조사하여 자세히 파악해야 합니다.\n\n회사에 대한 정보력을 확보하는 것도 아주 중요합니다.\n\n🛜 정보력 확보에 도움이 되는 사이트\n\nthevc, 크레딧잡, 잡플래닛, 블라인드, 구글링, 링크드인, 혁신의 숲, 동기사랑, 커피챗, IT연합동아리, 취준 면접, 취준 멘토링 등....\n\n\n\n📌 좋은 이력서, 포트폴리오 준비 (기본기만해도 중간은 간다.)\n가독성이 좋아 읽기 좋은 친절한 이력서\n분석 가능한 이력서\n결국 나라는 개발자가 잘 표현된 이력서\n오타, 과장이 없는 이력서\n사례를 기반으로 작성하자\n사이드 프로젝트나 회사 경력도 중요하다.\n하지만 포커스는 나에게 조준하자. 즉 나를 중심으로 가득 채우자.\n좋은 내용을 가져다 쓸 생각만 하지 말고 내가 기여했던 소소한 것들을 다시 떠올려 보자\n스스로 생각했을 때 하찮아 보일 수 있는 것도 타인이 봤을 때는 훌륭할 수 있다.\n최대한 기억을 되살려 보자.\n\n좋은 내용만 쓰려하지 말고, 그래서 거기서 내가 무엇을 하였는가?\n함께 프로젝트를 했어도 내가 그곳에서 뭘 했는지? 뭘 못 했는지? 어떻게 해결했는지? 등을 명시해면 좋습니다.\n\n\n\n📌 나쁜 이력서\n안눌리는 링크, 틀린 URL, 접근 권한 없는 공유.\n기본적인 맞춤법은 꼭 지키자.\n불필요한 내용은 (과감히) 제거하자.\n이력서는 계속 수정하는 것이다. 반응을 확인하며 우선순위, 강조, 제거 등 수정하자.\n\n\n📌 컨텐츠와 일관성이 우선이다.\n일관적인 구성으로 가독성을 챙겨보자.\n분량에 집착해서 소중한 것을 놓치지 말자.\n수중한 것부터 챙기고 분량을 점검해 보자.\n중요하고 소중한 것은 분량이 아니라 담겨져 있는 컨텐츠다.\n내용이 길어도 일관성이나 가독성이 좋으면 잘 읽힌다.\n흥미가 생기는, 재밌는 컨텐츠는 내용이 아무리 길어도 더 보고 싶다.\n\n외적인 것들 보다 내적 컨텐츠의 튼튼함이 더 중요하고 좋은 이력서로 나아가는 요소인 것 같습니다.\n\n\n\n📌 기승전결을 만들자.\n\nWhy => How => Result => Prize\n왜? 어떻게? 결과는? 성과는?\n\nSTART 기법을 활용하자.\n\n내용의 구성을 기승전결을 토대로 튼튼하게 만들어 원인부터 과정, 결과까지 한 번에 나타날 수 있도록 하는 것이 좋습니다.\n\n\n\n🎯 타이밍\n\n이력서/포트폴리오를 완성하고 지원하려다 타이밍을 놓치면 소용없습니다.\n\n완성의 기준, 판단은 어차피 뽑아주는 회사나 면접관이 합니다.\n이것들을 기다린다고 회사 지원을 미루지 말고 놓치기 전에 지원합시다.\n같은 이력서/포트폴리오를 보고도 완성 유무의 기준은 보는 사람마다 모두 다릅니다.\n차라리 많은 사전 과제를 풀어보는 것이 압도적으로 도움이 됩니다.\n타이밍을 놓치지 말고 지원하면서 갈고 닦아야 합니다.\n🔮 운\n\n아무리 노력해도 누군가는 내 이력서를 선호하고, 또 누군가는 선호하지 않을 수 있습니다.\n\n모두를 만족시킬 수 없다면 확률적으로 접근하고 직관을 쌓아 봅시다.\n그래도 모두를 만족시키고 싶다면 다양한 테스트를 하면서 확률을 분석하고 개별 이력서를 만들어서 지원합니다.\n가장 중요한 것은 나라는 개발자를 잘 표현하는 것 입니다.\n⌨️ 실력\n\n공부도 실전이다. 면접부터 보자. 아니면 비슷한 환경을 만들고 체험하자.\n\n원하는 회사에 들어가고 싶다면 그 회사를 대상으로 면접을 보거나 비슷한 환경과 경험을 만들어야 합니다.\n내가 원하는 프로젝트를 하지말고 회사가 요구하는 사전 과제를 풀어봅시다.\n알고리즘은 이제 피할 수 없는 필수 요소입니다.\nAI의 등장으로 라이브 코딩 테스트 검증이 더욱 중요해질 것 입니다.\n많은 면접을 보고 녹음도 하면서 실전 피드백을 받아보고 내가 시장에서 얼마나 경쟁력 있는지 객관적으로 파악하는 것이 중요합니다.\n\n\n⁉️ 1교시 QnA 시간 중\n\nQ: 기술을 개발하는 것 보다 역사, 관련 지식 등을 공부하는 것이 더 재밌고 집중하게 되는데 잘못된 공부 방법 일까요?\n\n\nA: 얕고 다양한 공부를 하는 것 보다 깊이 있는 공부를 하는 것이 중요하다. AI의 발달로 깊이 있는 공부의 중요성은 더욱 더 강조될 것이고 실력을 가늠하는데 밑바탕이 될 것 이다.(기본기의 중요성)\n\n\n\n\n\n\n⏰ 2교시 백엔드 트랙 개발자 세션\n🧐 백엔드는 무엇을 할까?\n\n눈에 보이지 않는 것들을 처리합니다.\n\n서비스 로직, 유효성 검증 같이 전통적인 서버 개발에서 보안, 클라우드 인프라, 데이터 파이프라인, 시스템 아키텍처 설계까지 담당영역이 확대되고 있습니다.\n\n\n\n전통적인 서버 개발\t클라우드 인프라\t시스템 아키텍처 설계\n비지니스 로직 구현 및 API 설계\n서버/DB 성능 최적화\n메모리/CPU 프로파일링 및 병목 현상 해결\nDB 스키마 설계 및 쿼리 튜닝\t클라우드 플랫폼 아키텍처 설계(AWS, GCP, Azure)\n오토스케일링 및 로드밸런싱 설정\n클라우드 비용 최적화 및 관리\nInfrastructure as Code를 통한 인프로 자동화(Terraform, CloudFormation)\tMSA(Microservice Architecture)설계 및 구현\n서비스 간 통신 패턴 설계(동기/비동기)\n장애격리(Circuit Breaker)전략 수립\n캐싱 전략 및 분산 시스템 데이터 일관성 확보\n\n\n📌 오늘날 백엔드 개발자에게 필요한 기술스택\n단순 API 구현을 넘어 다양한 기술 스택에 대한 이해와 활용능력이 중요해졌습니다.\n하지만 본질은 그 기술 스택을 사용하면서 문제를 해결할 능력이 있는지 유무입니다.\n단순히 다양하고 최신 트렌드 기술을 사용할 줄 아는 것이 아니라, 문제를 어떻게 풀 수 있는지 그 문제에 알맞게 활용을 하는 것인지에 대한 인사이트가 중요합니다.\n\n\n📌 현대적인 백엔드 개발 프로세스\n개발부터 배포까지 자동화된 파이프라인과 테스트 기반 개발이 표준이 되었습니다.\n애자일(민첩)한 개발 프로세스로 변화에 빠르게 대응할 수 있게 하여 \"어떻게 하면 고객에게 더 빠르게 다가갈 수 있나?\" 접근합니다.\nCI/CD 파이프라인 구축\t테스트 주도 개발 실전 적용\nJekins, GitHub Actions, GitLab CI를 활용한 자동화 구성\n코드 품질 측정 도구 연동(SonarQube, JaCoCo)\n자동화된 보안 취약점 스캔(OWASP)\n배포전략(Blue/Green, Canary, Rolling)구현\n장애 발생시 롤백 자동화 전략\t효과적인 단위/통합 테스트 작성 방법\nSpring Boost Test 프레임워크 활용 기법\n테스트 커버리지와 품질 사이의 균형 찾기\n테스트 자동화와 수동 테스트 영역 구분\nTDD(Test Driven Development)\n\n\n📌 효과적인 협업 방식과 문제 해결 능력\n다양한 직군과의 협업과 장애 상황 대응 능력이 백엔드 개발자의 핵심 역량입니다.\n특히 서비스 회사의 백엔드 개발자는 소통 능력이 매우 중요합니다.\n\n\n📌 백엔드 개발자 포트폴리오 차별화 전략\n\n단순 CRUD를 넘어 기술적인 깊이를 보여줄 수 있는 포트폴리오를 구성해야 합니다.\n강연자 추천 글: 우아한테크캠프 7기: 데모데이 1위 팀의 로그 매니저 프로젝트를 소개합니다!\n\n여기서 기술적 깊이 != 최신 기술 사용\n기술적 깊이를 증명하기 == 얼마나 깊게 고민하였는지, 본질은 문제해결!\n\n핵심은 최신 기술을 사용하는 것이 아닌 문제를 해결하는 것 입니다.\n\n모든 의사 결정에 왜?가 있고 그에 대한 근거가 마련되어야 합니다.\n\n의사결정에는 근거가 중요합니다. 왜 그렇게 결정하였는지 설득하고 납득시키면 됩니다.\n\n\n\n🧑‍🔧 실제 서비스 운영 관점에서 경험을 포트폴리오에 반영합시다.\n실무 연계성 높이기\t서비스 운영 관점 강조\nJekins, GitHub Actions를 활용한 CI/CD 파이프라인 구축 경험\nDocker/Kubernetes환경 배포 자동화 구현\n모니터링 시스템 구축 및 알람 설정(Prometheus, Grafana)\n로그 중앙화 및 분석 시스템 연동(ELK Stack)\n실제 사용자 피드백 기반 서비스 개선 사례\t트래픽 증가에 따른 스케일링 전략 수립\n보안 취약점 분석 및 대응 경험\n데이터 백업 및 복구 전략 구현\n장애 상황 대응 및 사후 분석 경험\n성능 모니터링 및 병목 현상 해결 사례\n\n\n⁉️ 2교시 QnA 시간 중\n\nQ(나의 질문): 비전공자이고 아직 개발 공부를 시작한지 3개월 밖에 안되어서 어떤 기술을 사용하는 것이 혹은 어떤 코드(문법, 라이브러리 등)를 사용하는 것이 더 효율적이고 개선된 성과를 나타낼 수 있는 것인지를 판단할 줄 모르겠습니다. 이런건 어떻게 알아갈 수 있을까요?\n\nA: 먼저 배우고 있는 것을 제대로 파악하는게 중요하다. 내가 지금 배우고 있는 것을 깊이 파면서 공부하기 시작하고 축척되면 그 기술에 대해 능숙해 질 것이고 하나를 제대로 할 줄 알게되면 다른 기술들을 파악하기에 수월해 질 것이다.(QnA 시간이 부족해서 더 자세한 답변으로 이어지진 못했습니다.)\n\n\nQ: 문제 해결 과정, 의사결정 능력을 따로 훈련했던 방법이 있으신가요?\n\nA: 관련 책을 읽고 참고하였다. 책 하나를 추천하면 '로지컬 씽킹' 맥킨지식 논리적 사고와 구성의 기술 이라는 책을 추천한다.\n강연자 추천서적: 로지컬 씽킹(맥킨지식 논리적 사고와 구성의 기술)\n\n\n\n\n\n⏰ 3교시 트랙 전체 네트워킹 및 컨퍼런스 참여 후기\n\n참여자 전체 네트워킹 시간을 진행하면서 간단한 퀴즈, 아이스 브레이킹, 팀원들과 각 과정을 선택한 이유, 현재 공부하면서 잘하고 있는점, 아쉬운점, 등을 공유하였고 다른 트랙의 스프린터들은 어떤 생각을 가지고 있는지 조금이나마 이야기를 들을 수 있었습니다.\n\n아쉽게도 node.js백엔드 과정에서는 이미 일정이 있어서 분도 계시고 아직 1기가 진행 중인 소수여서 그런지 나밖에 참여자가 없었지만, 다른 과정의 수 많은 스프린터들을 만나고 이야기하시는 것들을 보면서 또 다른 동기부여를 얻을 수 있었습니다.\n\n각 트랙들의 자세한 내용은 모르지만 백 여명의 스프린터 분들 중에서도 적극적으로 이야기하시고 공유하시는 분들을 보면서 큰 인상을 받았습니다. 전체 네트워킹 뿐만 아니라 트랙별 네트워킹 시간에도 적극 참여하시고 다양한 QnA를 공유하면서 정말 열심히 하시는 분들이 많다는 것을 느끼고, 다각도로 문제를 바라보고 깊이 생각하시는 분들을 많이 만날 수 있었습니다.\n\n개인적으론 이번 컨퍼런스의 네트워킹을 기점으로 다시 힘을 낼 수 있을 것 같다는 느낌을 받았습니다. 비전공자에 늦깎이 만학도이고 아예 제로베이스로 시작하다보니 따라가기 위해서 할 수 있는 것은 잠을 줄이고 공부하고 블로그 작성해보는 것 밖에 없었습니다. 그걸 거의 세 달을 하다보니 기초 프로젝트를 마치는 시점부터 지치기 시작하고 개발 공부를 시작하고 첫 번째 정체기, 노잼시기가 찾아왔습니다. 공부를 해도 머리에 남지 않고 귀찮아지고 회복이 아닌 아예 내려놓고 휴식만 하기도 했습니다. 파트 1 멘토님께서도 너무 무리하지 말고 페이스 조절을 해야한다고 조언해 주셨었는데, 직접 겪어보니 무슨 말인지 알게 되었습니다. 이번 네트워킹을 하면서 무작정 공부하려고 앉아있기보다는 이제 곧 중급 프로젝트를 시작하니, 더 고민하고 왜? 라고 질문하면서 깊게 생각하며 비판적으로도 바라보는 방법을 연습해 봐야겠습니다. 팀원 분들과도 상의해서 서로 질문하고 타당한 근거를 바탕으로 서로를 설득하고 납득시키는 연습을 해 보자고 제안해 봐야겠습니다.\n\n토요일 오전 시간이었지만 컨퍼런스를 참여하기 위해 시간을 낸 것이 절대 아깝지 않았습니다. 이전 특별 강연에도 참여했었고, 다음 주 특별 강연에도 참여할 예정인데, 오늘처럼 모든 트랙의 스프린터와 현업 강연자님들이 함께 참여해 주시는 컨퍼런스가 또 다시 열리는 그날을 기다리면서 더 열심히 공부하고 node.js 스프린터 동기분들과도 각자 원하는 목표를 향해 함께 달리도록 공유하고 노력하겠습니다.\n\n신민수\n삐약 삐약🐥💻 아무것도 모르는 비전공자 만학도🧐 늦게 시작했으니 늦게까지 해보자구🏃🏻‍♂️ 저의 글을 읽어 주셔서 감사합니다. 많이 부족합니다. 잘못된 부분, 참고하거나 추가하면 좋은 것, 기타 리플과 피드백 주시면 감사히 듣고 적용해 보도록 노력하겠습니다. 🙇‍♂️\n팔로우\n이전 포스트\n[코드잇 특별강연] 25.02.24.Mon - 내가 신입으로 돌아간다면 적용할 학습 방법과 커리어 방향 설정\n0개의 댓글\n댓글 작성\n관련 채용 정보\n구름\n프론트엔드 개발자 (디자인시스템)\n구름은 클라우드 인프라에 기반한 혁신적 SaaS 솔루션을 제공하며, 사용자 중심의 디자인 시스템 신화를 함께 이끌어갈 프론트엔드 개발자를 찾고 있습니다. TypeScript, React 등 최신 기술을 활용하여 개발자 성장 생태계를 구축하는 핵심 역할을 맡게 됩니다.\n미리디\n[미리캔버스] 프론트엔드 개발자\n미리캔버스는 디자인 생태계를 혁신하는 올인원 플랫폼으로, 1,400만 고객을 위해 프론트엔드 개발을 통해 사용자 경험을 최적화하고 있습니다. React와 Next.js를 활용해 확장 가능한 구조를 설계하며, 빠르게 변화하는 환경에서도 뛰어난 성능을 제공하는 팀의 일원이 되어보세요!\n스터닝\n프론트엔드 개발자(신입)\n프론트엔드 개발자로서 국내 최대 크리에이티브 플랫폼 스터닝에서 UX/UI 협업 및 웹 서비스 개발을 통해 창작자의 가치를 실현하는 데 기여해보세요. React, Typescript, Next.js와 같은 기술을 활용하며 유연한 근무 환경에서 업무에 몰입할 수 있습니다.",
    "tags": [
      "CodeitConference2025",
      "스프린터의 봄",
      "스프린터의봄",
      "스프린트",
      "컨퍼런스",
      "코드잇",
      "코드잇스프린트"
    ],
    "commentCount": "0"
  },
  {
    "title": "드디어 개발자로 취업했다!",
    "description": "부트캠프와 인턴을 마치고, 2월 초에 겨우 완성한 이력서를 들고 본격적인 취업 활동을 시작했다. 거의 매일 원티드에 이력서를 넣었고, 6~7번의 면접을 보며 과제 테스트와 코딩 테스트, 포트폴리오 발표까지 정말 정신없이 바쁜 시간을 보냈다. 매",
    "link": "https://velog.io/@cindycho0423/%EB%93%9C%EB%94%94%EC%96%B4-%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%A1%9C-%EC%B7%A8%EC%97%85%ED%96%88%EB%8B%A4",
    "author": "조cindy의 🐶발일지",
    "date": "2025년 4월 3일",
    "comments": "1개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/cindycho0423/post/e786a48c-628d-4533-a4f8-976e72c437f8/image.png",
    "content": "조cindy의 🐶발일지\n로그인\n조cindy의 🐶발일지\n로그인\n드디어 개발자로 취업했다!\ncindycho_0423·2025년 4월 3일\n팔로우\n9\n신입신입개발자\n📝 회고록\n목록 보기\n5/5\n\n작년 하반기에 부트캠프와 인턴을 마치고, 2월 초에 겨우 완성한 이력서를 들고 본격적인 취업 활동을 시작했다. (코드잇 커리어코칭 프로그램 아니었으면 정말 절대 완성 못했음,,, 너무 쓰기 싫어서 돌아가실 지경이었다. 코드잇 알러뷰🫶)\n\n거의 매일 원티드에 이력서를 넣었고, 6~7번의 면접을 보며 과제 테스트와 코딩 테스트, 포트폴리오 발표까지 정말 정신없이 바쁜 시간을 보냈다. 매일 면접 연습도 하고 새로운 공부도 찾아서 하면서 나름 알차게 지냈던 것 같다😙\n\n\n(듣긴했지만 정말,, 서류 광탈의 연속🥲)\n\n그러던 중, 한 2주간 아무곳에서도 연락이 없어 불안해하던 차에 두 곳에서 면접 제안이 왔다. 기쁜 마음으로 면접 장소를 검색했는데 첫번째 면접을 보는 회사의 면접 장소가 빌라로 나와서 당황했다. 기업 정보도 많지 않았고, 임시 사무실이라고 되어 있어 살짝 걱정이 되기도 했지만 면접 기회를 놓칠 수 없었다.\n\n친구에게 부탁해서 같이 갔는데 알고 보니 옆 건물의 카페를 임시 사무실로 사용하고 계셨었다.(처음에는 빌라 안으로 들어가야 하는 줄 알고 마음 속에서 정말 수많은 갈등이 있었다.. 내 장기 무사하겠지?하며🥹) 면접장에 도착하니 두 분이 반갑게 맞이해 주셨고 면접이 시작되자마자 내 깃허브와 블로그를 다 살펴보셨다고 말씀해주셨다. 지금까지 여러 면접을 봤지만, 이렇게 나의 프로젝트를 깊이 들여다본 면접관 분들은 거의 없었다. (소문으로 이런 곳도 있더라~ 하는 정보만 들었었다.)\n\n정~말 다양한 질문을 받았는데 아쉬웠던 점은 CS 질문에 제대로 답변하지 못한 것이었다. 알고 보니 아침에 내가 스터디에서 머지를 한 pr 내용을 보고 질문하셨던 것이었고, 너무 어려워서 개념 정도만 알고 넘어간 부분에서 질문이 나와서 답을 제대로 못했다😭\n\n면접은 약 한 시간 반 동안 진행되었다.(지금껏 본 면접 중 가장 긴 시간이었다ㅎㅎ) 화이트보드에서 간단한 코딩 테스트도 보고, 브라우저 렌더링 과정에 대한 질문도 답했다. 특히 내 프로젝트에 대해 하나하나 질문해 주시고, 내가 놓쳤던 부분까지 세심하게 알려주셔서 정말 감사했다.\n\n(이게 내가 놓쳤던 부분ㅎㅎ)\n🔗 관련 블로그 글: Next.js와 Firebase 앱에서 API 키 보호하기\n\n면접이 끝난 후에도 마지막까지 친절하게 배웅해 주시기도 하고, 이분들에게 배우면 정말 많이 배울 수 있을 것 같다는 생각이 들어서 집으로 가면서 \"아, 이 회사 너무 가고 싶다!\" 라고 생각했다.\n\n인터뷰가 끝나고 돌아가서 면접에서 나온 문제를 해결하고 감사 인사와 함께 해결 과정과 트러블슈팅 내용을 블로그에 정리해 보냈다. 그리고 다음 날! 원래는 다음 주 수요일에 결과를 알려주신다고 했는데 하루 만에 연락이 와서 연봉도 원하는 만큼 맞춰주시고 다음 주부터 출근 가능하냐고 물어보셨다.\n\n\n바로 가능하다고 답했고 전화를 끊자마자 부모님과 함께 기뻐하며 뛰어다녔다. 친한 친구들에게도 연락해서 이 소식을 전했고 도파민 맥스였다🥹 '드디어 내가 개발자로서 돈을 벌 수 있는 사람이 되었구나!'라는 감정이 몰려오고, 어안이 벙벙하기도 했다ㅎㅎㅎ (글로 쓰니까 상당히 차분한 느낌이지만 당시에 1분에 한 번씩 \"내가 뽑혔어? 내가..?내가..!\"를 반복했다ㅋㅋ)\n\n한참 방방거리다가 정신을 차린 뒤 하루를 정말 바쁘게 보냈다. 사랑니도 뽑고, 안경점에서 가벼운 안경도 맞추고, 미용실에서 머리도 다듬었다. 아직 다 못 들은 배포 강의를 들으려다가, 지금 이 감정을 남기고 싶어서 블로그를 쓰게 되었다. 너무 내 감정과 생각을 막 쓰느라 두서가 없지만ㅎㅎ 나중에 보면 재미있을 것 같다ㅎㅎ\n\n면접을 하고나서 정말 여러가지 생각이 들었지만, 간이 코테(?)를 통과했던게 기억에 남았다. 그동안 코딩테스트에 대한 벽을 느끼며 정말 어려워했는데 스터디원들과 함께 주 3회씩 알고리즘 문제와 개념을 공부했던게 아주 큰 도움이 됐다. 포기하고 싶을 때가 한 두번이 아니었는데 꾸준히 조금씩 해왔던 나에게도 칭찬하고 싶고, 내가 이해를 못할 때마다 그림까지 그려가면서 도와준 친구들에게 감사함을 느끼는 시간이었다😚\n\n그동안 도와준 친구들, 멘토님들에게도 꼭 감사 인사를 전해야겠다.\n현지야, 정말 고생 많았고 앞으로도 잘해보자!\n오늘 하루는 정말 행복하게 보내야지ㅎㅎㅎ ☺️\n\n++ 따뜻한 사람들,,, 간직하고 싶어서 추가\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n내 인생 최대 축하받음. 3개월 수습기간 잘 버텨잉~~~\n\ncindycho_0423\nhttps://linktr.ee/Hyunji_Cho 🐣\n팔로우\n이전 포스트\n백엔드 개발자, 디자이너와 협업하기\n1개의 댓글\n댓글 작성\nastronaut\n4일 전\n\n축하드립니다. 좋은 개발자가 되실거에요\n\n답글 달기\n관련 채용 정보\n퀸라이브\n[재택근무] 프론트엔드 개발자 (2년 이상)\n퀸라이브는 데이터 기반의 폐쇄형 라이브커머스를 운영하며, React 및 Next.js로 사용자 경험을 높이는 프론트엔드 개발자를 찾고 있습니다. 자유롭게 아이디어를 공유할 수 있는 문화 속에서 함께 성장하며 새로운 기회를 얻어보세요.\n현대오토에버\n[FE Engineering] 개발/운영 및 Governance 체계 수립 - Frontend Engineer\n현대오토에버에서 완성차 운영 서비스를 개발하며 프론트엔드 기술 거버넌스를 수립할 기회를 잡아보세요. JavaScript와 React 등의 전문성을 발휘할 수 있는 창의적인 환경이 여러분을 기다리고 있습니다.\n한경닷컴\n프론트엔드 (3~5년)\n경제 미디어의 대표주자 한경닷컴에서 디지털 혁신을 이끌 프론트엔드 개발자를 찾습니다. React와 Next.js로 웹사이트를 개발하며, 동시대 경제 정보를 제공하는 특별한 경험을 누려보세요.",
    "tags": [
      "신입",
      "신입개발자"
    ],
    "commentCount": "1"
  },
  {
    "title": "스택이 매우 커질 수 있다면 힙은 불필요할까",
    "description": "잠을 깨게 해준 유튜브 한편",
    "link": "https://velog.io/@chae0738/%EB%A7%8C%EC%9D%BC-%EC%8A%A4%ED%83%9D%EC%9D%B4-%EB%A7%A4%EC%9A%B0-%EC%BB%A4%EC%A7%88-%EC%88%98-%EC%9E%88%EB%8B%A4%EB%A9%B4-%ED%9E%99%EC%9D%80-%EB%B6%88%ED%95%84%EC%9A%94%ED%95%A0%EA%B9%8C",
    "author": "SIOE9.log",
    "date": "2025년 3월 31일",
    "comments": "0개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/chae0738/post/d31349df-c7ec-47ad-ad9b-ff1e85a5909f/image.webp",
    "content": "SIOE9.log\n로그인\nSIOE9.log\n로그인\n스택이 매우 커질 수 있다면 힙은 불필요할까\nHunn·2025년 3월 31일\n팔로우\n11\nheapstack자료구조\nCS\n목록 보기\n6/8\n재밌는 유튜브 발견✨\n\n최근에 지하철을 타면 피곤해서 잠만자던도중...\n잠을 깨기위해 볼 유튜브를 찾다가 궁금하게 만드는 제목을 발견했다.\n만일 스택이 매우 커질 수 있다면 힙은 불필요할까? 유튜브 링크\n이 제목이 나를 영상으로 이끌었고, 덕분에 지하철의 30분이 시간가는 줄 몰랐다.... 단순한 질문에 대한 답변 뿐만아니라, 어떤걸 묻는지에 대한 분석과 꼬리에 꼬리를 무는 답변까지 보면 30분이 순삭되는 영상이므로 한번씩 보는걸 추천한다.\n댓글도 개발자들의 다양한 시각을 볼 수 있어서 재밌다\n\n이 영상을 보고 배운점들을 정리하고, 궁금한점이 더 생겼기 때문에 블로그 글을 통해 정리하고자 한다.\n\n먼저 이 질문에 답하기 위해서는 먼저 스택과 힙의 근본적인 차이를 이해해야 한다. 스택은 LIFO(Last-In-First-Out) 구조로 정적이고 자동적인 메모리 할당 방식을 사용한다. 반면 힙은 동적으로 메모리를 할당하고 임의의 순서로 해제할 수 있는 유연성을 제공한다.\n\n스택과 힙의 특성\n스택\nLIFO 구조: 가장 최근에 할당된 메모리가 가장 먼저 해제된다.\n\n정적/자동 메모리 할당: 컴파일 시점에 크기가 결정되거나 함수 호출 시 자동으로 할당되고 반환된다.\n\n연속적 메모리 할당: 메모리가 연속적으로 할당되어 파편화가 적다.\n\n빠른 접근 속도: 포인터 연산만으로 빠르게 데이터에 접근할 수 있다.\n\n수명 제한: 함수 호출 범위 내에서만 데이터가 유지된다.\n\n힙\n동적 메모리 할당: 프로그램 실행 중에 필요에 따라 메모리를 할당하고 해제할 수 있다.\n\n불규칙한 할당/해제: 메모리 할당과 해제가 임의의 순서로 이루어질 수 있다.\n\n수명 관리의 유연성: 객체의 수명이 생성 스코프를 벗어나 존재할 수 있다.\n\n비연속적 메모리 할당: 메모리가 비연속적으로 할당될 수 있다.\n\n멀티스레드 환경에서 공유 가능: 스레드 간 데이터 공유가 가능하다.\n\n힙이 필요한 이유\n\n결론적으로, 스택의 크기가 무한히 커진다 하더라도 힙은 여전히 필요하다. 그 이유는 다음과 같다.\n\n데이터 수명 관리\n스택은 함수 호출 범위로 데이터 수명이 제한되지만, 힙은 객체의 수명을 더 유연하게 관리할 수 있다.\n동적 크기의 데이터 구조\n사용자 입력에 따라 크기가 결정되는 배열과 같은 구조는 스택에 적합하지 않다.\n멀티스레드 환경\n스레드 간 데이터 공유에는 힙이 필요하다. (스택은 스레드끼리 공유안함)\n객체 지향 프로그래밍\n객체의 동적 생성과 공유는 힙 없이는 어렵다.\n코드 예제: 스택과 힙\n\n다음 간단한 예제는 스택과 힙의 사용 차이를 보여준다:\n\nvoid stackExample() {     \n    int stackVar = 42;  // 스택에 할당         \n    // 함수 종료 시 stackVar은 자동으로 해제됨 \n} \n\nvoid heapExample() {     \n    Integer* heapVar = new Integer(42);  // 힙에 할당         \n    // 명시적으로 해제하지 않으면 메모리 누수 발생    \n    delete heapVar; \n}\n힙 메모리의 파편화 문제\n\n스택과 힙에 대한 이해가 깊어지면서 자연스럽게 힙 메모리의 파편화 문제에 대해 생각하게 되었다. 힙 메모리 파편화는 메모리 할당과 해제의 반복 과정에서 발생하는 현상으로, 크게 두 가지 유형이 있다:\n\n1. 외부 파편화(External Fragmentation)\n\n여러 개의 작은 메모리 블록들이 할당된 메모리 사이에 흩어져 있어, 개별적으로는 작지만 합치면 큰 메모리 블록을 할당할 수 있는 상황이다.\n\n예를 들어:\n\n[ 사용 중 10KB ][ 빈 5KB ][ 사용 중 20KB ][ 빈 10KB ][ 사용 중 15KB ][ 빈 15KB ]\n\n이 상태에서 25KB 메모리 할당을 요청하면, 총 30KB의 빈 공간이 있음에도 불구하고 할당할 수 없다.\n\n2. 내부 파편화(Internal Fragmentation)\n\n할당된 메모리 블록 내부에서 실제로 사용되지 않는 공간이 발생하는 현상이다.\n\n예를 들어:\n\n// 메모리 할당자가 8바이트 단위로 할당한다고 가정 \nbyte[] data = new byte[22];  // 22바이트 요청 \n// 실제로는 24바이트(8바이트 경계에 맞춤)가 할당됨 \n// → 2바이트의 내부 파편화 발생\n\n파편화는 다음과 같은 영향을 미친다:\n\n메모리 낭비: 사용 가능한 메모리가 있음에도 실제로 사용할 수 없게 되어 낭비된다.\n\n성능 저하: 사용 가능한 메모리를 찾기 위한 검색 시간이 증가한다.\n\n메모리 할당 실패: 충분한 연속된 메모리가 없어 새로운 할당 요청이 실패할 수 있다.\n\n파편화 해결 방법\n1. 메모리 압축(Compaction)\n\n사용 중인 메모리 블록을 한쪽으로 모아 연속된 큰 빈 공간을 만든다. 이는 외부 파편화를 효과적으로 해결하지만, 메모리 복사 비용이 크고 프로세스 실행을 일시 중단해야 한다.\n\nvoid compactMemory() {     \n    Address destination = startOfHeap;         \n    for (Block block : heap) {        \n        if (block.isInUse()) {            \n            moveBlock(block, destination);            \n            destination += block.size;        \n        }    \n    }         \n    markAsFree(destination, endOfHeap - destination); \n}\n2. 가비지 컬렉션(Garbage Collection)\n\n더 이상 참조되지 않는 객체를 자동으로 탐지하여 메모리를 해제한다. 이는 많은 현대 프로그래밍 언어(Java, Python 등)에서 사용된다.\n\n3. Best-fit 알고리즘\n\n요청 크기에 가장 가까운 빈 블록을 선택하여 내부 파편화를 줄인다.\n\nBlock* allocateBestFit(size_t size) {     \n    Block* bestBlock = NULL;    \n    size_t bestSize = SIZE_MAX;         \n    for (Block* block = freeList; block != NULL; block = block->next) {        \n        if (block->size >= size && block->size < bestSize) {            \n            bestBlock = block;            \n            bestSize = block->size;        \n        }    \n    }         \n    if (bestBlock != NULL) {        \n        bestBlock->inUse = true;        \n        removeFromFreeList(bestBlock);    \n    }         \n    return bestBlock; \n}\n4. 메모리 풀(Memory Pool)\n\n동일한 크기의 객체를 위한 메모리를 미리 할당하여 관리한다.\n\npublic class MemoryPool<T> {     \n    private final Object[] pool;    \n    private final boolean[] inUse;         \n    \n    public MemoryPool(int capacity) {        \n        this.pool = new Object[capacity];        \n        this.inUse = new boolean[capacity];    \n    }         \n    \n    public T allocate() {        \n        for (int i = 0; i < pool.length; i++) {            \n            if (!inUse[i]) {                \n                inUse[i] = true;                \n                return (T) pool[i];            \n            }        \n        }        \n        throw new OutOfMemoryError(\"Memory pool is full\");    \n    }         \n    \n    public void free(T object) {        \n        for (int i = 0; i < pool.length; i++) {            \n            if (pool[i] == object) {                \n                inUse[i] = false;                \n                return;            \n            }        \n        }        \n        throw new IllegalArgumentException(\"Object not from this pool\");    \n    } \n}\n결론\n\n스택과 힙은 각기 다른 목적을 가진 중요한 메모리 관리 구조이다. 아무리 스택이 커지더라도 동적 데이터 관리와 유연성을 제공하는 힙은 일반적으론 필요하다. 이는 단순히 메모리 크기의 문제가 아닌, 구조적인 차이와 목적의 차이 때문이다.\n\n특히 멀티스레드 환경에서는 여러 스레드가 공유할 수 있는 메모리 공간이 필요한데, 스택은 본질적으로 스레드 의존적이고 지역적인 특성을 가지므로 이러한 용도로는 부적합하다. 또한 객체의 수명 관리에 있어서도 힙은 스택보다 훨씬 유연한 방식을 제공하기 때문이다.\n\n물론 힙 메모리는 파편화 문제와 같은 단점이 있지만, 이는 가비지 컬렉션, 메모리 풀, 메모리 압축 등 다양한 기법으로 해결할 수 있다. 현대 프로그래밍 언어들은 이러한 메모리 관리를 자동화하여 개발자의 부담을 줄이고 있다.\n여기까지 공부하다보니 내가 주로 쓰는 JVM이 어떻게 메모리 파편화 문제를 해결하고 효율적인 메모리 관리를 구현하는지 더 자세히 알아보고 싶어졌다.\n다음 글에서는 이어서 JVM의 메모리 관리 시스템, 특히 가비지 컬렉션의 세대별(Generational) 메모리 관리 방식에 대해 더 자세히 살펴 볼 예정이다.\n\n참고자료\n\nComputer Systems: A Programmer's Perspective (3rd Edition)\n\n스택과 힙의 근본적인 차이점 및 운영체제 수준의 메모리 관리에 대한 상세 설명.\n\n출처: Computer Systems: A Programmer's Perspective (PDF)\n\n\nThe Garbage Collection Handbook: The Art of Automatic Memory Management (2nd Edition)\n\n가비지 컬렉션의 이론과 실제 구현에 대한 포괄적인 안내서.\n\n출처: The Garbage Collection Handbook\n\n\nModern Operating Systems (4th Edition)\n\n메모리 관리 시스템과 파편화 문제에 대한 심층적인 분석.\n\n출처: Modern Operating Systems (Google Books)\n\n\nMemory Management in Java: Stack vs Heap & Garbage Collection\n\n자바 메모리 관리, 스택과 힙의 차이점 및 가비지 컬렉션의 기본 원리에 대한 설명.\n\n출처: Dev.to 블로그\n\n\nJava Garbage Collection Best Practices\n\n자바 가비지 컬렉션의 최적화 전략 및 기본 개념 설명.\n\n출처: New Relic 블로그\nHunn\n명확한 문제 정의를 가장 중요시 여기는 개발자, 채기훈입니다.\n팔로우\n이전 포스트\n운영체제에서는 어떤 알고리즘이 쓰일까?\n다음 포스트\nJVM의 메모리 구조와 가비지 컬렉션 기본 원리\n0개의 댓글\n댓글 작성\n관련 채용 정보\n타다(VCNC)\n웹 프론트엔드 개발\n타다와 함께 대한민국 모빌리티 시장을 혁신하며, 웹 프론트엔드 개발자로서 앱 내 화면을 개발할 기회를 잡으세요. React 및 TypeScript로 동작하는 유연한 개발 환경에서 동료들과 함께 문제를 해결하며 성장할 수 있는 기회가 기다립니다.\n뱅크샐러드\n웹 프론트엔드 엔지니어\n뱅크샐러드는 금융과 건강 데이터를 연계하여 혁신적인 서비스를 제공하는 플랫폼입니다. 프론트엔드 엔지니어로서 React를 활용한 개발 및 크로스 플랫폼 환경에서의 최적화 작업에 참여하게 됩니다.\n인플루디오\n[포카마켓] React 프론트엔드 개발자 (1년 이상)\nK-POP 포토카드 거래를 혁신하는 포카마켓에서 React와 Next.js를 활용한 프론트엔드 개발자로 함께 성장할 기회를 잡아보세요. 수평적이고 빠른 의사결정 구조 속에서 고객 경험을 최우선으로 하며, 적극적인 의견 공유로 더 나은 팀을 만들어갈 인재를 기다리고 있습니다.",
    "tags": [
      "heap",
      "stack",
      "자료구조"
    ],
    "commentCount": "0"
  },
  {
    "title": "다사다난 2024 회고 - 4월[적당한 스압]",
    "description": "이번 4월은 3월처럼 안밀리고 빨리 올릴 수 있게 됐다.지금은 25년 4월 3일인데 잠시 여유가 났고, 다음주부터 엄청나게 바빠질 예정이다.그래서 귀찮ㄱ..긴했지만 지금 아니면 언제 올리려나 해서 큰 맘먹고 바로 올린다!!아마...4월에도 그렇게 무엇인가를 많이 한것같...",
    "link": "https://velog.io/@seochan99/%EB%8B%A4%EC%82%AC%EB%8B%A4%EB%82%9C-2024-%ED%9A%8C%EA%B3%A0-4%EC%9B%94%EC%A0%81%EB%8B%B9%ED%95%9C-%EC%8A%A4%EC%95%95",
    "author": "서희찬",
    "date": "2025년 4월 4일",
    "comments": "1개의 댓글",
    "likes": "7",
    "thumbnailUrl": "https://velog.velcdn.com/images/seochan99/post/51232cb3-b974-4e2f-91f1-0b5e5b590b37/image.jpeg",
    "error": "Navigation timeout of 60000 ms exceeded"
  },
  {
    "title": "Swift Student Challenge Winner가 되기까지의 과정",
    "description": "2024년 11월 6일(제 15회 전국 마이스터고등학교 제전 영마스터 학술제) 부스 출품을 위해 대전으로 가는 버스 안에서 창밖을 보고 멍때리다가 어느 간판을 봤다. 그 간판을 보고 저 간판을 이용해서 어떤 아이디어를 생각해보자고 의식적으로 생각했다. 뭔 말인지 모르겠...",
    "link": "https://velog.io/@bestswlkh0310/Swift-Student-Challenge-Winner%EA%B0%80-%EB%90%98%EA%B8%B0%EA%B9%8C%EC%A7%80%EC%9D%98-%EA%B3%BC%EC%A0%95",
    "author": "이강현",
    "date": "2025년 3월 31일",
    "comments": "5개의 댓글",
    "likes": "16",
    "thumbnailUrl": "https://velog.velcdn.com/images/bestswlkh0310/post/e1678a14-8048-474d-8af9-ec9d104516b6/image.png",
    "error": "Navigation timeout of 60000 ms exceeded"
  },
  {
    "title": "API 성능 안 괜찮아 딩딩딩딩딩 🎶 - Tracing 1편",
    "description": "API 성능의 Bottleneck을 찾기 위해 Tracing을 도입해본 내용입니다.",
    "link": "https://velog.io/@hahnwoong/API-%EC%84%B1%EB%8A%A5-%EC%95%88-%EA%B4%9C%EC%B0%AE%EC%95%84-%EB%94%A9%EB%94%A9%EB%94%A9%EB%94%A9%EB%94%A9",
    "author": "anteater.log",
    "date": "2025년 4월 3일",
    "comments": "0개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/hahnwoong/post/52a7a7c7-7092-4bbd-bfa1-b89f72e47aca/image.png",
    "content": "anteater.log\n로그인\nanteater.log\n로그인\nAPI 성능 안 괜찮아 딩딩딩딩딩 🎶 - Tracing 1편\npeterTheAnteater·2025년 4월 3일\n팔로우\n12\nOpenTelemetryScyllaDBjaegernest.jsprismarabbitmqredistracingtraefik트레이싱\n데브옵스\n목록 보기\n14/15\n\nAPI 성능의 Bottleneck을 찾기 위한 삽질 과정을 적어본 블로그 글입니다.\n\n글을 쓰게 된 동기\n\n저는 회사에서 일하는거 외 에도 아는분들과 함께 프로젝트를 진행하며 실제 배포를 하고 실사용자를 받고있습니다. 대충 MAU 50명? 정도 되는 서비스라 트래픽이 엄청 많은건 아니지만 실사용자들을 통해 생기는 문제들을 통해 많은걸 배우고 삽질 있습니다.\n\n저는 팀에 DevOps개발자 로서 CI/CD, Infra, Monitoring, 등등을 맡아서 하고 있는데.... 그래서 제 블로그 글들이 다 그따구. 물론 백앤드 마이크로 서비스들 몇개 만들긴 합니다\n\n최근에 Traefik 메트릭 대시보드를 보면서 조금 이상한 수치를 보았습니다...\n\n어떤 endpoint에서 일어난 Delete인지는 모르겠지만 평균 2.45s와 최대 2.45s라는 말도 안되는 수치가 찍혀있는겁니다. 물론 Post 792ms도 정상은 아닙니다만...\n\n그래서 이게 오류인지 아니면 진짜로 특정 엔드포인트에서 저런 말도 안되는 수치가 일어나는건지 확인을 해봐야하는데 확인할 방법이 없는겁니다. (응?)\n\n\n저희 메인 Backend API Server (MSA 비스무리 하게 운영중이라 그 외 다른 api server들도 있긴 합니다) 는 Nest.js로 만들었는데 이 서비스에 엔드포인트 관련 duration time을 프로메테우스 메트릭으로 제공을 하지 않고 있었습니다. (울 백앤드 분들 일하세요!)\n\n제가 만든 서치 엔진 API는 엔드포인트별 시간 메트릭 다 설정 해놨는데\n\n뭐 하여튼 그렇다 보니 이참에 이 부분도 해결하고 DB 트랜잭션 시간이 얼마나 걸리는지 확인 하기 위해 Tracing을 도입하기로 했습니다.\n\nTracing? 트레이싱?\n\n트레이싱을 처음 들어보는 분들도 있을겁니다.\n\n트레이싱은 MSA가 유행을 하면서 같이 부상한 모니터링 방식입니다. 예전처럼 백앤드 서버가 한 개 였던 시절에는 병목 현상이 어디서 일어나는지 테스트를 하기도 편했고 모니터링 하기 쉬운 편이었습니다.\n\n하지만 점점 Microservice Architecture, 그것도 Event Driven Architecture를 같이 사용하면서 수많은 서비스들이 kafka, sqs, rabbitmq, redis 등을 거치면서 일로갔다 저리로 갔다 하면 정확히 메시지가 어디에 있는지 모니터링 하기도 어렵고 정확히 어디서 병목현상이 일어나는지 확인 하기 어려운 세상이 됐습니다.\n\n그래서 이걸 해결하려고 나온게 Tracing, 그 중 Distributed System Tracing(분산 시스템 트레이싱) 입니다.\n\n트레이싱은 APM (Application Performace Monitoring)툴들을 사용해보셨으면 본적이 있을겁니다. Elastic APM, DataDog, Sentry, NewRelic등 APM을 사용해보시면 이런 페이지를 보신적 있을겁니다.\n\n이렇게 트레이싱은 서비스 어디서 얼만큼 시간이 소요가 되고 트랜잭션을 처리 하기 위해 어디서 얼만큼 걸렸는지, 만약에 오류가 생겼으면 오류가 뭔지 를 트랙킹 해서 보여줍니다.\n\n이런 대시보드가 있으면 병목현상이 어디서 일어났는지 쉽게 알수있겠죠?\n\n사실 저희 서비스 프런트앤드에는 Sentry.io를 사용해 설정을 해뒀습니다. Sentry가 프리티어로 한개 까지는 괜찮더라구요.\n\n그래서 비슷하게 하려다가... 사실상 표준이 되어가는 OpenTelemetry를 사용해 백앤드 Tracing을 구현 해보기로 했습니다!\n\nOpenTelemetry\n\n오픈텔레메트리(OpenTelemetry)는 트레이스, 메트릭, 로그 같은 텔레메트리 데이터를 생성하고 관리하도록 설계된 옵저버빌리티 프레임워크이자 툴 키트입니다. 출처\n\n즉 오픈텔레메트리 (줄여서 Otel 오텔)는 데이터 모니터링 및 관측을 사용할때 사용하는 프레임워크가 아니고 데이터를 생성하거나 그 데이터를 관측할때 사용하는 서비스 (DataDog, Jaeger)등 한테 보내주는 역활을 합니다. 텔레메트리 데이터 파이프라인을 만들어준다고 생각하면 편할까요?\n\n그러면 생기는 질문이 꼭 있습니다. Jaeger, DataDog, New Relic등을 사용하면 자체 SDK를 설치해서 데이터를 보내도 되는데 굳이 OpenTelemetry를 사용해야되나요?\n\nOpenTelemetry를 사용하면 생기는 장점은 데이터를 가공할수도 있고 또한 DataDog, New Relic 등 SDK에 종속이 되지 않으면서 관리 할수 있게 도와줍니다.\n\n만약에 DataDog을 사용하다가 다른 서비스로 옮기고 싶다고 가정을 해봅시다. 그러면 소스코드에서 SDK제거를 하는 등 많은 리팩토링이 필요하겠죠?\n\n리팩토링을 결국 누가 하게 될까요?\n\n\n하지만 OpenTelemetry를 사용하면 언제든지 다른 백앤드 서비스에서 사용할수 있고 심지어 여러 백앤드 서비스를 한번에 사용할수 있도록 해줍니다.\n\nJaeger\n\nJaeger (예거)는 트레이싱 데이터 수집 및 처리 백앤드 툴입니다. 분산 서비스 트랜잭션을 트레이싱 하는 오픈 소스 소프트웨어죠.\n\n예거는 오픈텔레메트리 없이 자체적으로 사용을 할수도 있습니다. 자체 SDK를 대부분의 언어에서 제공을 하니까요. 하지만 오픈텔레메트리와 같이 사용을 해서 데이터 수집을 오픈텔레메트리에 맡기고 데이터 저장 및 조회를 예거한테 맡길수 있습니다.\n\n다른 트레이싱 툴들, ZipKin, Tempo들 대비 좋냐고 하면 솔직히 저는 잘 모르겠습니다. 원래 이런 툴들은 자기가 좋아하는거 하나 골라서 사용하면 됩니다.\n\nJaeger는 기본적으로 인메모리 디비를 사용해서 트레이스 데이터를 저장합니다만... 이걸 프로덕션에서 사용하면 메모리 사용량 때문에 서버가 폭팔하겠죠?\n\n\n그래서 다행이(?) 예거는 외부 데이터베이스를 사용할수 있게 해줍니다. 공식적으로 가능한 데이터베이스는 Cassandra와 ElasticSearch입니다만 (Cassandra 3.4+ and Elasticsearch 5.x/6.x/7.x) 카산드라와 일라스틱서치가 된다는 뜻은... 같은 API를 사용할수 있는 ScyllaDB, OpenSearch 등도 가능하다는거겠죠?\n\n\n실제로 저는 ScyllaDB를 사용했습니다\n\n실습\n\n일단 제가 사용한 스택들은 아래와 같습니다.\n\nTraefik v3.0+\nScyllaDB v6.0+\nNest.JS Core v10.4.1+\nPrisma Client v6.5.0+\nGo v1.23+ (Otel v1.35+)\njaeger-cassandra-schema v1.67.0+\nopentelemetry-collector-contrib v0.122.1\njaegertracing/all-in-one v1.67.0\n\n아키텍처를 보여드리자면 대충 이렇습니다.\n\n위 같이 아키텍처를 만들어서 사용을 해보니 아래와 같은 트레이싱 데이터가 잘 나오는걸 확인 했습니다.\n\n서비스/프레임워크 별 설정법은 추후 다른 블로그 글로 곧 올라갈 예정입니다.\n\npeterTheAnteater\n소프트웨어 개발과 밀당하는 개발자\n팔로우\n이전 포스트\n......Watchtower, 거기 있어?\n다음 포스트\nAPI 성능 이제 이해가 되셨을까요? - Tracing 2편\n0개의 댓글\n댓글 작성\n관련 채용 정보\n와드(캐치테이블)\nB2B Back_End Developer (3~5년차)\n캐치테이블은 외식업 전문 통합 플랫폼을 운영하며 디지털화를 선도하고 있습니다. 백엔드 개발자로 성장할 기회를 제공하며, Java, Spring을 활용한 혁신적인 서비스 개발을 지원합니다.\n매드업\n[테크사업부] 주니어 백엔드 개발자 (전문연구요원 가능)\n매드업 테크사업부에서 Python으로 디지털 마케팅 자동화 솔루션을 개발하며 함께 성장할 주니어 백엔드 개발자를 찾습니다. AWS 클라우드 환경에서 혁신적인 프로덕트를 다루며, 성장을 지원하는 다양한 혜택을 제공합니다.\n여기어때컴퍼니\nServer Engineer (전시플랫폼개발)\n여기어때에서 전시 플랫폼의 백엔드 시스템 개발을 담당할 'Server Engineer'를 찾습니다. 대용량 트래픽 처리와 데이터 동기화를 통해 서비스 신뢰성과 사용자 경험을 극대화하며, 자율적 근무환경과 다양한 복지를 제공합니다.",
    "tags": [
      "OpenTelemetry",
      "ScyllaDB",
      "jaeger",
      "nest.js",
      "prisma",
      "rabbitmq",
      "redis",
      "tracing",
      "traefik",
      "트레이싱"
    ],
    "commentCount": "0"
  },
  {
    "title": "리엑트는 왜 함수형 컴포넌트를 택했을까? (feat. 클래스형 컴포넌트)",
    "description": "클래스형 컴포넌트와 함수형 컴포넌트의 성능을 비교하는 것은 의미가 없다. 그러나 함수형 컴포넌트는 렌더링된 값을 캡처한다는 점을 미루어보아 관리 측면에서는 더 효율적이다.함수형 컴포넌트는 입력(props)에 따른 출력(UI)이 예측 가능해 순수 함수의 특성을 자연스럽게...",
    "link": "https://velog.io/@kyujenius/function-component-vs-class-component",
    "author": "kyujenius.log",
    "date": "2025년 4월 6일",
    "comments": "0개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/kyujenius/post/962d304c-f0f9-4348-8098-dd55cf9fd2b5/image.png",
    "content": "kyujenius.log\n로그인\nkyujenius.log\n로그인\n리엑트는 왜 함수형 컴포넌트를 택했을까? (feat. 클래스형 컴포넌트)\n홍규진·2025년 4월 6일\n팔로우\n11\nJavaScriptReact\n리엑트와 순수함수의 관계\n목록 보기\n3/5\n\n💡급하신 분들을 위해서 결론 먼저!\n클래스형 컴포넌트와 함수형 컴포넌트의 성능을 비교하는 것은 의미가 없다. 그러나 함수형 컴포넌트는 렌더링된 값을 캡처한다는 점을 미루어보아 관리 측면에서는 더 효율적이다.\n함수형 컴포넌트는 입력(props)에 따른 출력(UI)이 예측 가능해 순수 함수의 특성을 자연스럽게 따른다.\n클래스 컴포넌트는 this와 생명주기 메서드로 인해 상태 관리가 복잡하고 사이드 이펙트가 발생하기 쉽다.\n함수형 컴포넌트는 클로저를 활용해 렌더링 시점의 값을 캡처하여 일관성을 유지한다.\n함수형 컴포넌트는 테스트와 디버깅이 용이하며 코드 최적화에도 유리하다.\n\n순수성(Purity)이라는 개념은 함수형 프로그래밍의 핵심인데, 리액트의 함수형 컴포넌트는 이 순수성을 자연스럽게 유지하도록 설계되어 있다. 오늘은 왜 함수형 컴포넌트가 클래스 컴포넌트보다 순수성을 직관적으로 유지하기 쉬운지 왜 그렇게 표준이 되었는지 알아보자. (순수 함수에 대해서 잘 모르신다면 이전 시리즈를 참고해주세요)\n\n(👨🏻‍🏫 : 저는 처음에 리엑트를 배울 때 클래스 컴포넌트로 배웠답니다. 군대에서 리액트를 처음 배우던 날, 남들이 장병개발지원금 으로 운동화를 살 때, 큰 맘 먹고 산 리엑트 책 속에는 클래스형 컴포넌트 관련 내용으로 꽉차있었고, 열심히 공부했지만 전부 갖다 버리게 된 기억이 있어요…! 그래도 이렇게 쓰이는 날이 오네요 ㅎㅎ 그때는 함수형이 뭔지도 몰랐죠. 오랜만에 그 생각이 나네요. 🥲)\n\n1. 순수 함수와 리액트 컴포넌트\n순수 함수란 무엇인가?\n\n순수 함수(Pure Function)는 다음 두 가지 특성을 가진 함수를 말한다:\n\n동일한 입력에 대해 항상 동일한 출력을 반환한다.\n함수 외부의 상태를 변경하지 않는다(사이드 이펙트가 없다. 정확히는 부수효과가 없다).\n// 순수 함수의 예\nfunction add(a, b) {\n  return a + b;\n}\n\n// 비순수 함수의 예\nlet total = 0;\nfunction addToTotal(value) {\n  total += value; // 외부 변수 변경 (사이드 이펙트)\n  return total;\n}\n\n\n이전 시리즈 참고: https://velog.io/@kyujenius/react-pure-component\n\n리액트와 순수성의 관계\n\n리액트의 철학은 UI를 순수 함수처럼 다루는 것이다. 즉, 같은 props가 주어지면 항상 같은 UI를 렌더링해야 한다. 이것이 리액트의 선언적 프로그래밍 방식의 핵심이다.\n\n(👨🏻‍🏫 : 리액트 공식 문서에서도 컴포넌트를 '순수하게 유지하라'고 강조한답니다. 그만큼 중요하다는 거죠!)\n\n리액트 공식 문서에서는 다음과 같이 말한다:\n\n“Keeping Components Pure”\n\n출처: React 공식 문서 - 컴포넌트 순수성 유지하기\n\n2. 클래스 컴포넌트의 복잡성\nthis 키워드의 혼란\n\n클래스 컴포넌트에서는 this 키워드가 많은 혼란을 야기한다. JavaScript의 this는 호출 컨텍스트에 따라 달라지기 때문에, 이벤트 핸들러에서 this를 올바르게 바인딩하지 않으면 예상치 못한 버그가 발생한다.\n\nclass Counter extends React.Component {\n  constructor(props) {\n    super(props);\n    this.state = { count: 0 };\n    // 이벤트 핸들러에 this를 바인딩해야 함\n    this.handleClick = this.handleClick.bind(this);\n  }\n  \n  handleClick() {\n    this.setState({ count: this.state.count + 1 });\n  }\n  \n  render() {\n    return (\n      <button onClick={this.handleClick}>\n        Count: {this.state.count}\n      </button>\n    );\n  }\n}\n\n생명주기 메서드의 복잡성\n\n클래스 컴포넌트의 생명주기 메서드는 코드를 여러 메서드에 분산시키고, 관련 없는 로직이 한 메서드에 섞이는 문제를 야기한다.\n\nclass DataFetcher extends React.Component {\n  constructor(props) {\n    super(props);\n    this.state = { data: null, loading: true };\n  }\n  \n  componentDidMount() {\n    // 데이터 가져오기\n    fetchData(this.props.id).then(data => {\n      this.setState({ data, loading: false });\n    });\n    \n    // 이벤트 리스너 등록 (관련 없는 로직)\n    window.addEventListener('resize', this.handleResize);\n  }\n  \n  componentDidUpdate(prevProps) {\n    if (prevProps.id !== this.props.id) {\n      // id가 변경되면 데이터 다시 가져오기 (중복이죠)\n      this.setState({ loading: true });\n      fetchData(this.props.id).then(data => {\n        this.setState({ data, loading: false });\n      });\n    }\n  }\n  \n  componentWillUnmount() {\n    // 이벤트 리스너 제거\n    window.removeEventListener('resize', this.handleResize);\n  }\n  \n  handleResize = () => {\n    console.log('Window resized');\n  }\n  \n  render() {\n    const { data, loading } = this.state;\n    return loading ? <p>Loading...</p> : <div>{data}</div>;\n  }\n}\n\n\n이 예제에서 데이터 가져오기 로직이 componentDidMount와 componentDidUpdate에 중복되어 있고, 완전히 관련 없는 리사이즈 이벤트 처리 로직도 섞여 있다. 이런 구조는 관심사 분리(Separation of Concerns) 원칙에 위배된다.\n\n3. 함수형 컴포넌트와 훅(hook)의 등장\n함수형 컴포넌트의 단순성\n\n함수형 컴포넌트는 props를 받아 UI를 반환하는 순수 함수처럼 작동한다. 이는 순수 함수의 개념과 자연스럽게 일치한다.\n\nfunction Greeting(props) {\n  return <h1>Hello, {props.name}!</h1>;\n}\n\n\n이 간단한 컴포넌트는 props에 따라 예측 가능한 출력을 생성하며, 외부 상태를 변경하지 않는다. 완벽한 순수 함수다! 🌟\n\n훅(Hooks)을 통한 상태 관리\n\nReact 16.8에서 도입된 훅(Hooks)은 함수형 컴포넌트에서도 상태와 생명주기 기능을 사용할 수 있게 해주면서, 로직을 관심사별로 분리할 수 있게 해준다.\n\nfunction DataFetcher({ id }) {\n\n  const [data, setData] = useState(null);\n  const [loading, setLoading] = useState(true);\n  \n  useEffect(() => {\n    // 데이터 가져오기 로직\n    setLoading(true);\n    fetchData(id).then(result => {\n      setData(result);\n      setLoading(false);\n    });\n  }, [id]); // id가 변경될 때만 실행\n  \n  // 리사이즈 이벤트 처리 (사이즈 관련 로직 따로 관심사 분리)\n  useEffect(() => {\n    const handleResize = () => console.log('Window resized');\n    window.addEventListener('resize', handleResize);\n    return () => {\n      window.removeEventListener('resize', handleResize);\n    };\n  }, []); // 마운트/언마운트 시에만 실행\n  \n  return loading ? <p>Loading...</p> : <div>{data}</div>;\n}\n\n\n출처: React 공식 문서 - Effect Hook 사용하기\n\n클래스 컴포넌트와 비교하면, 함수형 컴포넌트에서는:\n\n하나의 로직 - 하나의 훅으로 그룹화된다.\n의존성 배열 [] 로 효과의 실행 시점을 명확하게 제어할 수 있다.\n클린업 함수가 효과와 함께 정의되어, 시기와 의존성이 명확하다. (즉, 예측 가능하다.)\n\n(👨🏻‍🏫 : 훅이 등장했을 때 정말 혁명적이었답니다! 코드가 훨씬 깔끔해졌죠.)\n\n4. 클로저와 값의 캡처 (어려워도 진짜 중요해요!!)\n클래스 컴포넌트의 this 문제\n\n클래스 컴포넌트에서는 this.props와 this.state가 항상 최신 값을 참조하기 때문에, 비동기 작업에서 예상치 못한 버그가 발생할 수 있다.\n\nclass ProfilePage extends React.Component {\n  showMessage = () => {\n    // 3초 후에 메시지 표시\n    setTimeout(() => {\n      alert('You followed ' + this.props.user);\n    }, 3000);\n  };\n\n  render() {\n    return <button onClick={this.showMessage}>Follow</button>;\n  }\n}\n\n\n만약 사용자가 버튼을 클릭한 후 다른 프로필로 이동하면, this.props.user는 새 사용자를 참조하게 되어 원래 의도한 사용자가 아닌 다른 사용자 이름이 표시된다.\n\n함수형 컴포넌트의 값 캡처\n\n함수형 컴포넌트는 클로저를 통해 렌더링 시점의 props 값을 캡처한다. 이는 더 예측 가능한 동작을 제공한다.\n\nfunction ProfilePage({ user }) {\n  const showMessage = () => {\n    // 렌더링 시점의 user 값이 '캡처'됨\n    setTimeout(() => {\n      alert('You followed ' + user);\n    }, 3000);\n  };\n\n  return <button onClick={showMessage}>Follow</button>;\n}\n\n\n출처: Function 컴포넌트와 Class Components의 차이점\n\n이 컴포넌트는 버튼을 표시하고, setTimeout으로 네트워크 요청을 시뮬레이션한 다음 확인 알림을 표시합니다. 예를 들어 props.user가 'Dan'이면 3초 후에 'Followed Dan'을 표시합니다. 간단하죠? 이 예제에서는 버튼을 클릭한 시점의 user 값이 클로저에 의해 캡처되어, 나중에 다른 프로필로 이동하더라도 원래 의도한 사용자 이름이 표시된다. 이는 순수 함수의 특성과 일치하는 예측 가능한 동작이다.\n\n차이점 이해하기\n\n두 버튼으로 다음 동작 시퀀스를 시도해보면 순서는 이렇다\n\nFollow 버튼 중 하나를 클릭한다.\n3초가 지나기 전에 선택된 프로필을 변경한다.\n알림 텍스트를 읽는다.\n\n이상한 차이점을 발견할 수 있습니다:\n\n함수형 ProfilePage에서는 Dan의 프로필에서 Follow를 클릭한 다음 Sophie로 이동해도 여전히 'Followed Dan'이라고 알림이 표시됩니다.\n클래스형 ProfilePage에서는 'Followed Sophie'라고 알림이 표시됩니다.\n왜 이런 차이가 발생할까?\n\n클래스의 showMessage 메서드를 자세히 살펴보자.\n\nclass ProfilePage extends React.Component {\n  showMessage = () => {\n    alert('Followed ' + this.props.user);\n  };\n\n\n이 클래스 메서드는 this.props.user에서 읽는다. React에서 props는 불변이므로 변경될 수 없다.\n\n그러나 this는 항상 변경 가능하다. 사실, 이것이 클래스에서 this의 주요한 목적이다. React는 시간이 지남에 따라 this를 변경하여 render 및 라이프 사이클내에서 최신 값을 읽을 수 있도록 한다. 따라서 요청이 진행 중인 동안 컴포넌트가 다시 렌더링되면 this 자체가 바뀌어this.props가 변경된다. showMessage 메서드는 ‘완전히 새로운’ props에서 user를 읽게 된다.\n\n(👨🏻‍🏫 : 이것은 UI의 본질에 대한 흥미로운 결과를 보여줍니다. UI는 = 현재 애플리케이션 상태의 함수라고 말한다면, 이벤트 핸들러는 렌더링 결과의 일부인데요? 이벤트 핸들러는 props와 state에 의한 특정 렌더링에 속한다고도 볼 수 있습니다! )\n\n이해를 위한 시각화\n\nUI = f(props) {\n props 와 state 사용해서 랜더링 ()\n 이벤트 핸들러에 의한 변경으로 다시 props와 state를 사용해서 랜더링()\n}\nEvent Handler => 이벤트 핸들러가 생성된 시점의 props와 state 값과 연결되어 있어야 함.\n\n즉, 특정 시점의 애플리케이션 상태(state와 props)가 주어지면, React는 그에 해당하는 UI를 렌더링한다. 상태가 변경되면 UI도 그에 맞게 업데이트된다. 그러나 this.props를 읽는 setTimeout 콜백을 예약하면 그 연결이 끊어진다. showMessage 콜백은 특정 렌더링에 연결되지 않으므로 올바른 props를 잃어버린다. this에서 읽으면 그 연결이 끊어진다.\n\n함수형 컴포넌트의 해결책\n\n함수형 컴포넌트는 이 문제를 어떻게 해결할까? 다시 함수형으로 구현한 코드를 살펴보자:\n\nfunction ProfilePage(props) {\n  const showMessage = () => {\n    alert('Followed ' + props.user);\n  };\n\n함수형 컴포넌트에는 this가 없다. 함수의 props는 React에 의해 변경되지 않고 항상 해당 렌더링과 연결된 값을 유지한다. 이것은 함수 내부의 모든 코드(이벤트 핸들러 포함)가 특정 렌더링에서의 props와 state를 ‘볼 수 있음’을 의미한다.\n\n클로저의 역할\n\nJavaScript 클로저는 이 문제를 해결하는 데 도움이 된다. 클로저는 종종 시간이 지남에 따라 변경될 수 있는 값을 생각하기 어렵기 때문에 피하는 경우가 많다. 하지만 React에서 props와 state는 불변이다! 이것은 클로저의 주요 단점을 제거한다. 특정 렌더링에서 props나 state를 클로저로 감싸면, 항상 동일하게 유지된다고 확신할 수 있다:\n\nfunction ProfilePage(props) {\n  // props는 렌더링 시점에 캡처됨!\n  const showMessage = () => {\n    alert('Followed ' + props.user);\n  };\n\n\n렌더링 시 props를 \"캡처\"했기 때문에 해당 내부의 모든 코드(showMessage 포함)는 특정 렌더링의 props를 볼 수 있습니다. React는 더 이상 우리의 예상을 벗어나지 않는다.\n\n클래스에서도 이 문제를 해결할 수 있을까?\n\n물론이다! 클래스 컴포넌트에서도 클로저를 활용할 수 있다:\n\nclass ProfilePage extends React.Component {\n  render() {\n    // props를 캡처!\n    const props = this.props;\n    \n    // 주의: 우리는 render 내부에 있습니다.\n    // 지금 클래스 메서드가 아닙니다.\n    const showMessage = () => {\n      alert('Followed ' + props.user);\n    };\n    \n    const handleClick = () => {\n      setTimeout(showMessage, 3000);\n    };\n    \n    return <button onClick={handleClick}>Follow</button>;\n  }\n}\n\n\n이렇게 하면 특정 렌더링의 props를 \"캡처\"하여 모든 코드가 해당 props를 볼 수 있도록 할 수 있다. 하지만 이 접근 방식은 render() 코드를 항상 써야하고, 그렇다면 매번 동일하게 사용해야하지만, 중복된 코드가 많아지게 된다. 따라서 클래스라는 ‘껍데기’ 를 제거하여 코드를 다음과 같이 단순화할 수 있다:\n\nfunction ProfilePage(props) {\n  const showMessage = () => {\n    alert('Followed ' + props.user);\n  };\n  \n  const handleClick = () => {\n    setTimeout(showMessage, 3000);\n  };\n  \n  return <button onClick={handleClick}>Follow</button>;\n}\n\n함수형 컴포넌트와 Hooks\n\nHooks를 사용하면 state에도 동일한 원칙이 적용된다:\n\nfunction MessageThread() {\n  const [message, setMessage] = useState('');\n  \n  const showMessage = () => {\n    alert('You said: ' + message);\n  };\n  \n  const handleSendClick = () => {\n    setTimeout(showMessage, 3000);\n  };\n  \n  const handleMessageChange = (e) => {\n    setMessage(e.target.value);\n  };\n  \n  return (\n    <>\n      <input value={message} onChange={handleMessageChange} />\n      <button onClick={handleSendClick}>Send</button>\n    </>\n  );\n}\n\n\n이 함수형 컴포넌트의 message는 \"Send\" 버튼을 클릭했을 때 input에 있던 상태를 캡처한다.\n\n항상 최신 값이 필요한 경우\n\n때로는 특정 렌더링에 속하지 않는 최신 props나 state를 읽어야 할 수도 있다. 이런 경우엔 어떻게 할까?? 정답은 바로 ref 이다.\n\nfunction MessageThread() {\n  const [message, setMessage] = useState('');\n  const latestMessage = useRef('');\n\n  const showMessage = () => {\n    alert('You said: ' + latestMessage.current);\n  };\n\n  const handleSendClick = () => {\n    setTimeout(showMessage, 3000);\n  };\n\n  const handleMessageChange = (e) => {\n    setMessage(e.target.value);\n    latestMessage.current = e.target.value;\n  };\n\n\nref는 클래스의 인스턴스 필드와 유사한 역할을 한다. 이것은 변경 가능한 명령형 프로그래밍으로의 탈출구인 셈이다.\n\n(👨🏻‍🏫 : “클래스 컴포넌트의 단점인 this 바인딩으로 인한 라이프 사이클 주기 내의 코드 중복과, Closure와 상태값 캡쳐의 불편함) 을 극복하기 위해 함수형 컴포넌트를 택하고, 클래스 컴포넌트에서의 이점을 남기기 위해서 ref 를 통해 인스턴스 필드와 같은 역할을 따로 빼두어 남겨두었다” 정도로 한 줄 요약하면 깔끔하지 않을까요? )\n\n5. 함수형 컴포넌트의 실용적 이점\n테스트 용이성\n\n함수형 컴포넌트는 입력(props)에 따른 출력(UI)이 예측 가능하므로 테스트하기 쉽다. 복잡한 생명주기 메서드나 내부 상태에 의존하지 않기 때문에 단위 테스트가 간단해진다.\n\n// 함수형 컴포넌트 테스트\ntest('Greeting displays correct name', () => {\n  const { getByText } = render(<Greeting name=\"John\" />);\n  expect(getByText('Hello, John!')).toBeInTheDocument();\n});\n\n\n출처: React Testing Library 문서\n\n결론\n\n함수형 컴포넌트는 리액트의 선언적 프로그래밍 모델과 순수 함수의 개념을 자연스럽게 결합한다. 이를 통해 코드는 더 예측 가능하고, 테스트하기 쉬우며, 유지보수가 용이해진다.\n\n리액트의 미래는 함수형 프로그래밍의 원칙을 더욱 깊이 받아들이는 방향으로 나아가고 있다. 순수성을 유지하는 것은 단순히 코드 스타일의 문제가 아니라, 버그를 줄이고 코드 품질을 높이는 핵심 요소이다. 함수형 컴포넌트는 이러한 순수성을 자연스럽게 장려하며, 더 나은 리액트 애플리케이션을 만들 수 있게 도와준다.\n\n(👨🏻‍🏫 : 클래스 컴포넌트 형식 또한 여전히 유효한 방식이지만, 함수형 컴포넌트는 순수성을 직관적으로 유지하기 쉽다는 점에서 현대 리액트 개발의 주류가 되었답니다!. 왜 함수를 쓰듯이 컴포넌트를 제작하게 되었는지, 그 근간에는 순수 함수의 개념이 필수적이예요! 그 근본적인 전후 사정에 대해서 알고보면 이렇게 조금 이해가 수월해졌길 바랍니다 ㅎㅎ)\n\n🙇🏻 글 내에 틀린 점, 오탈자, 비판, 공감 등 모두 적어주셔도 됩니다. 감사합니다..! 🙇🏻\n\n홍규진\n읽는 사람이 가장 이해하기 쉽게끔 적으려 노력합니다. 그 과정에서 스스로가 완전한 이해를 할 수 있다고 생각합니다. 그렇게 Taker 보다는 Giver이 되려 노력합니다. \n팔로우\n이전 포스트\n리액트에서의 순수성: 예측 가능한 UI의 비밀\n다음 포스트\n리액트에서 순수성을 유지하기 위한 부수 효과 관리법 (feat. 멱등성)\n0개의 댓글\n댓글 작성\n관련 채용 정보\n인플루디오\n[포카마켓] React 프론트엔드 개발자 (1년 이상)\nK-POP 포토카드 거래를 혁신하는 포카마켓에서 React와 Next.js를 활용한 프론트엔드 개발자로 함께 성장할 기회를 잡아보세요. 수평적이고 빠른 의사결정 구조 속에서 고객 경험을 최우선으로 하며, 적극적인 의견 공유로 더 나은 팀을 만들어갈 인재를 기다리고 있습니다.\n채널코퍼레이션\n[채널톡] Software Engineer\n채널톡은 아시아에서 가장 빠르게 성장하는 B2B SaaS 회사로, '올인원 AI 메신저'를 통해 고객 소통을 혁신하고 있습니다. 다양한 기술 스택을 활용해 글로벌 시장의 복잡한 문제를 해결할 수 있는 엔지니어를 기다립니다.\n코니스트\n웹 프로그래머 (신입~2년)\n웹툰 및 웹소설 데이터베이스 서비스 기업 코니스트에서 풀스택 개발자를 모집합니다. React, Node.js 등을 활용한 데이터 관리 업무와 유연 근무제 혜택이 매력적입니다.",
    "tags": [
      "JavaScript",
      "React"
    ],
    "commentCount": "0"
  },
  {
    "title": "메모리 관리 최적화 기법 알아보기",
    "description": "SI의 현실을 아는사람: ㄱ-",
    "link": "https://velog.io/@chae0738/%EB%A9%94%EB%AA%A8%EB%A6%AC-%EA%B4%80%EB%A6%AC-%EC%B5%9C%EC%A0%81%ED%99%94-%EA%B8%B0%EB%B2%95-%EC%95%8C%EC%95%84%EB%B3%B4%EA%B8%B0",
    "author": "SIOE9.log",
    "date": null,
    "comments": "0개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/chae0738/post/f0a62e04-8e37-485e-a8ec-102d0f96bc93/image.png",
    "content": "SIOE9.log\n로그인\nSIOE9.log\n로그인\n메모리 관리 최적화 기법 알아보기\nHunn·약 5시간 전\n팔로우\n5\n메모리최적화\nCS\n목록 보기\n8/8\n최근 근황\n\n회사에서 개발 코드는 만지지도 못하고 엑셀과 PPT만 한지 거의 1달이 다되어간다.\n사실상 진짜 개발과 공부는 퇴근이후에 하다보니, 내가 개발을 취미로 하고있는건가? 착각이 들기도 한다. 이런 스트레스 때문에 요즘 밥도 제대로 못먹었는데, 마침 지인이 포지션을 추천해주었고 최종 합격까지 하게되었다. 다양한 요인들 때문에 갈지 안갈지는 매우 고민하고 있지만... 이러한 스트레스 받는 상황에서도 내 최종 목표를 위한 공부는 멈출 수 없기 때문에 공부한 내용을 기록해 보고자 한다.\n\n지난 글에서는 JVM 메모리 구조와 가비지 컬렉션(GC)의 기본 원리를 살펴보았다. 이번 글에서는 한 단계 더 나아가, 고성능 애플리케이션, 특히 게임 서버, 금융 거래 시스템, 실시간 데이터 처리 엔진처럼 낮은 지연 시간(Low Latency)과 높은 처리량(High Throughput)이 생명인 시스템을 위한 메모리 관리 최적화 기법들을 코드 예제와 함께 소개하고자 한다.\n\n고성능 애플리케이션의 메모리 관리 과제\n\n이러한 고성능 시스템은 메모리 관리 측면에서 다음과 같은 특별한 요구사항들을 가진다.\n\n예측 가능한 성능: GC로 인한 예측 불가능한 지연 시간(특히 Stop-the-world) 최소화.\n높은 처리량: 초당 수십만 건 이상의 요청을 처리할 수 있는 능력.\n리소스 효율성: 제한된 메모리 자원을 최대한 효율적으로 활용.\n안정성: 메모리 누수나 심각한 파편화 없이 장기간 안정적으로 실행 가능.\n\n이를 위해서는 언어에서 기본 제공하는 기능을 넘어선 세심한 메모리 관리 전략이 필요하다.\n\n1. 커스텀 메모리 풀 (Object Pool)\n\n동일한 크기의 객체를 반복적으로 생성하고 해제하는 것은 상당한 오버헤드를 유발한다. 메모리 풀은 객체를 미리 생성해두고 필요할 때 빌려 쓰고 반납하는 방식으로, 이러한 오버헤드를 줄이고 GC 부담을 완화하며 메모리 파편화를 방지한다.\n\nimport java.util.concurrent.BlockingQueue;\nimport java.util.concurrent.LinkedBlockingQueue;\nimport java.util.function.Supplier;\nimport java.util.function.Consumer;\nimport java.util.concurrent.atomic.AtomicInteger;\n\n// 간단한 객체 풀 예시\npublic class ObjectPool<T> {\n    private final BlockingQueue<T> pool;\n    private final Supplier<T> objectFactory;\n    private final Consumer<T> objectResetter; // 객체 반납 시 초기화 로직\n    private final int maxSize;\n    // ... (생성자 등)\n\n    public ObjectPool(Supplier<T> factory, Consumer<T> resetter, int maxSize) {\n        this.objectFactory = factory;\n        this.objectResetter = resetter;\n        this.maxSize = maxSize;\n        this.pool = new LinkedBlockingQueue<>(maxSize);\n        // 필요하다면 초기 풀 채우기 로직 추가 가능\n    }\n\n    public T borrow() throws InterruptedException {\n        T object = pool.poll(); // 풀에서 즉시 가져오기 시도\n        if (object == null) {\n            // 풀이 비었으면 새로 생성 (최대 크기 제한 고려) 또는 대기\n            // 여기서는 간단히 대기하는 로직 (실제 구현은 더 복잡할 수 있음)\n            object = pool.take(); // 다른 스레드가 반납할 때까지 대기\n        }\n        return object;\n    }\n\n    public void release(T object) {\n        if (object != null) {\n            objectResetter.accept(object); // 객체 상태 초기화\n            pool.offer(object);           // 풀에 반납 (가득 찼으면 실패 가능)\n        }\n    }\n}\n\n// 사용 예시 (게임 서버의 플레이어 객체)\nObjectPool<Player> playerPool = new ObjectPool<>(\n    Player::new,  // Player 객체 생성 팩토리\n    Player::reset, // 사용 후 Player 상태 초기화 메서드\n    1000          // 최대 1000개까지 풀링\n);\n\n// ...\nPlayer p = playerPool.borrow();\ntry {\n    // 플레이어 객체 사용 로직\n} finally {\n    playerPool.release(p);\n}\n2. 직접 메모리 (Direct Memory) 활용\n\nJava NIO의 ByteBuffer.allocateDirect()는 JVM 힙(Heap)이 아닌 OS 네이티브 메모리를 직접 사용한다. 이는 대용량 파일 처리나 네트워크 소켓 I/O 시 GC의 부담을 줄이고 OS 레벨의 I/O 최적화를 활용하여 성능을 높일 수 있다.\n\nimport java.nio.ByteBuffer;\n\npublic class DirectMemoryExample {\n    public static void main(String[] args) {\n        // 100MB의 직접 메모리 할당\n        ByteBuffer directBuffer = ByteBuffer.allocateDirect(100 * 1024 * 1024);\n\n        try {\n            // 데이터 쓰기\n            for (int i = 0; i < 100; i++) {\n                directBuffer.putInt(i * i);\n            }\n            directBuffer.flip(); // 쓰기 모드 -> 읽기 모드 전환\n\n            // 데이터 읽기\n            while (directBuffer.hasRemaining()) {\n                int value = directBuffer.getInt();\n                // System.out.println(value);\n            }\n        } finally {\n            // 직접 메모리는 GC 대상이 아니지만,\n            // 참조가 사라지면 Cleaner 메커니즘 등을 통해 해제됨.\n            // 명시적 해제 API는 없으나, 시스템 자원이므로 누수되지 않도록 주의.\n            // (예: try-with-resources 와 함께 사용하는 라이브러리 활용)\n        }\n        // -XX:MaxDirectMemorySize 옵션으로 최대 크기 제한 가능\n    }\n}\n\n주의: 직접 메모리는 GC의 관리 대상이 아니므로, 너무 많이 할당하거나 해제가 제대로 관리되지 않으면 OutOfMemoryError (네이티브 메모리 부족)가 발생할 수 있다.\n\n3. 배열 재사용 및 성장 전략\n\n데이터 크기가 가변적일 때, 데이터를 담을 배열(주로 byte[])을 필요할 때마다 새로 생성하면 비효율적이다. ArrayList 내부 구현처럼, 현재 용량이 부족할 때 약 1.5배~2배 정도 더 큰 새 배열을 할당하고 기존 데이터를 복사(System.arraycopy)하는 전략이 일반적이다. 사용 후에는 배열을 버리지 않고 내부 상태(예: position)만 초기화하여 재사용한다.\n\nprivate byte[] buffer;\nprivate int position = 0;\nprivate int capacity; // 현재 버퍼의 실제 크기\n\n// ... (생성자)\n\nprivate void ensureCapacity(int requiredCapacity) {\n    if (capacity >= requiredCapacity) {\n        return; // 이미 충분한 용량\n    }\n\n    // 성장 전략: 보통 1.5배 또는 2배로 늘림\n    int newCapacity = Math.max(capacity * 3 / 2, requiredCapacity);\n    byte[] newBuffer = new byte[newCapacity];\n\n    // 기존 데이터 복사\n    if (position > 0) {\n        System.arraycopy(buffer, 0, newBuffer, 0, position);\n    }\n    buffer = newBuffer; // 새 버퍼로 교체\n    capacity = newCapacity;\n    // System.out.println(\"Buffer grown to: \" + newCapacity);\n}\n\npublic void write(byte data) {\n    ensureCapacity(position + 1);\n    buffer[position++] = data;\n}\n\npublic void reset() {\n    position = 0; // 내용만 초기화, 버퍼는 재사용\n}\n4. 메모리 정렬 및 캐시 친화적 설계\n\nCPU는 메모리에서 데이터를 읽어올 때 캐시 라인(예: 64바이트) 단위로 가져온다. 관련 데이터를 메모리 상에 가깝게 배치하면 캐시 히트율이 높아져 성능이 향상된다.\n\n구조체 배열 (AoS: Array of Structures): 일반적인 객체 지향 방식. 객체들이 메모리에 흩어질 수 있음.\nclass Particle { float x, y, z, vx, vy, vz; }\nParticle[] particles = new Particle[N];\n배열 구조체 (SoA: Structure of Arrays): 데이터 중심 방식. 동일 타입의 데이터가 연속적으로 배치되어 특정 연산에 유리.\nclass ParticleSystem {\n    float[] x, y, z;\n    float[] vx, vy, vz;\n    // 생성자에서 각 배열 초기화\n    ParticleSystem(int N) {\n        x = new float[N]; y = new float[N]; z = new float[N];\n        vx = new float[N]; vy = new float[N]; vz = new float[N];\n    }\n}\n// 사용 예: 모든 파티클의 x좌표 업데이트 시 캐시 효율적\nfor (int i = 0; i < N; i++) {\n    particleSystem.x[i] += particleSystem.vx[i] * dt;\n}\nSoA 방식은 특히 대량의 데이터를 순차적으로 처리하는 계산(SIMD 연산 등)에서 성능 이점을 가진다.\n5. 오프힙(Off-Heap) 메모리 솔루션\n\n수십 GB 이상의 매우 큰 메모리가 필요하거나, GC로 인한 지연을 극도로 피해야 할 때 고려한다. Chronicle Map, Ehcache (엔터프라이즈 버전), Apache Ignite 등은 JVM 힙 외부에 데이터를 저장하는 기능을 제공한다.\n\n// Chronicle Map 사용 예시 (라이브러리 필요)\nimport net.openhft.chronicle.map.ChronicleMap;\nimport net.openhft.chronicle.map.ChronicleMapBuilder;\nimport java.io.File;\n\n// ...\nFile mapFile = new File(\"my_offheap_cache.dat\");\nlong numberOfEntries = 1_000_000; // 백만 개 항목 예상\nint averageKeySizeBytes = 30;    // 평균 키 크기 (바이트)\nint averageValueSizeBytes = 1024; // 평균 값 크기 (1KB)\n\ntry (ChronicleMap<String, byte[]> offHeapMap = ChronicleMapBuilder\n       .of(String.class, byte[].class)\n       .averageKeySize(averageKeySizeBytes)\n       .averageValueSize(averageValueSizeBytes)\n       .entries(numberOfEntries)\n       .createPersistedTo(mapFile)) // 파일 기반 오프힙 저장소 생성\n{\n   // 데이터 저장\n   byte[] sampleData = new byte[1024];\n   // ... 데이터 채우기 ...\n   offHeapMap.put(\"user:session:12345\", sampleData);\n\n   // 데이터 조회\n   byte[] retrievedData = offHeapMap.get(\"user:session:12345\");\n\n   // ... 사용 ...\n} catch (Exception e) {\n   // 예외 처리\n}\n6.커스텀 메모리 할당자: 슬랩 할당자 (Slab Allocator)\n\n매우 낮은 수준의 제어가 필요할 때 직접 메모리 할당자를 구현하기도 한다. 슬랩 할당자는 특정 크기의 객체들을 위한 큰 메모리 청크(슬랩)를 미리 할당하고, 그 안에서 작은 단위(슬롯)를 빠르게 할당/해제하는 방식이다. 파편화를 줄이고 할당/해제 속도를 높일 수 있지만, 구현이 복잡하다.\n\n// 슬랩 할당자의 핵심 아이디어 (단순화된 슬랩 내부 로직)\nprivate static class Slab {\n    private final int slotSize;\n    private final byte[] memory; // 실제 메모리 영역\n    private final BitSet usedSlots; // 어떤 슬롯이 사용 중인지 추적\n    private final int totalSlots;\n\n    // ... 생성자 ...\n\n    public ByteBuffer allocate() { // 슬롯 할당 시도\n        int freeSlotIndex = usedSlots.nextClearBit(0); // 첫 번째 비어있는 슬롯 찾기\n        if (freeSlotIndex >= totalSlots) {\n            return null; // 이 슬랩은 가득 참\n        }\n        usedSlots.set(freeSlotIndex); // 사용 중으로 표시\n        int offset = freeSlotIndex * slotSize;\n        // memory 배열의 해당 부분을 감싸는 ByteBuffer 반환 (Heap ByteBuffer)\n        ByteBuffer buffer = ByteBuffer.wrap(memory, offset, slotSize);\n        buffer.clear(); // 사용 전 초기화\n        return buffer;\n    }\n\n    public boolean free(ByteBuffer buffer) { // 슬롯 해제 시도\n        // 버퍼가 이 슬랩의 메모리를 가리키는지 확인\n        if (buffer.array() == memory) {\n            int offset = buffer.arrayOffset() + buffer.position(); // 실제 메모리 오프셋 계산\n            if (offset % slotSize == 0) { // 슬롯 경계와 맞는지 확인\n                int slotIndex = offset / slotSize;\n                if (slotIndex >= 0 && slotIndex < totalSlots) {\n                    usedSlots.clear(slotIndex); // 사용 중 표시 해제\n                    return true;\n                }\n            }\n        }\n        return false; // 이 슬랩에서 할당된 버퍼가 아님\n    }\n}\n7. 메모리 누수 방지 전략\n약참조(Weak Reference) 활용: 캐시와 같이 객체를 오랫동안 참조할 수 있는 구조에서는, 해당 객체가 다른 곳에서 더 이상 강하게 참조되지 않을 때 GC가 메모리를 회수할 수 있도록 WeakReference 사용을 고려할 수 있다. ReferenceQueue와 함께 사용하여 GC된 참조를 정리하는 로직이 필요하다.\n// WeakReference를 사용한 캐시의 일부\nMap<Key, WeakReference<Value>> cache = new ConcurrentHashMap<>();\nReferenceQueue<Value> queue = new ReferenceQueue<>();\n\npublic void put(Key key, Value value) {\n    cleanup(); // GC된 참조 정리\n    cache.put(key, new WeakReference<>(value, queue));\n}\n\nprivate void cleanup() {\n    Reference<? extends Value> ref;\n    while ((ref = queue.poll()) != null) {\n        // ref 와 동일한 WeakReference를 가진 엔트리를 맵에서 제거\n        // (실제 구현은 더 효율적인 방식 필요)\n    }\n}\n주기적인 메모리 모니터링: MemoryMXBean을 사용하거나 VisualVM, JProfiler 같은 도구를 통해 힙 및 비힙 메모리 사용량을 주기적으로 모니터링하여 메모리 사용량 증가 추세를 관찰하고 누수 징후를 조기에 발견해야 한다.\n import java.lang.management.ManagementFactory;\n import java.lang.management.MemoryMXBean;\n import java.lang.management.MemoryUsage;\n \n // ...\n MemoryMXBean memoryBean = ManagementFactory.getMemoryMXBean();\n MemoryUsage heapUsage = memoryBean.getHeapMemoryUsage();\n long usedHeap = heapUsage.getUsed();\n long maxHeap = heapUsage.getMax();\n System.out.printf(\"Heap: %.2f MB / %.2f MB (%.1f%%)%n\",\n         usedHeap / (1024.0*1024.0), maxHeap / (1024.0*1024.0),\n         (double)usedHeap / maxHeap * 100);\n8. 벤치마킹과 성능 측정\n\n최적화 기법 도입 전후의 성능 변화를 측정하는 것은 필수다. JMH(Java Microbenchmark Harness)를 사용하면 마이크로벤치마크를 통해 특정 코드 경로의 성능을 정밀하게 측정하고 비교할 수 있다.\n\nimport org.openjdk.jmh.annotations.*;\n// ... (JMH 설정 어노테이션들)\n\npublic class MemoryAllocationBenchmark {\n\n    @Benchmark\n    public byte[] standardAllocation() {\n        // 일반적인 힙 할당\n        return new byte[1024];\n    }\n\n    // 객체 풀 상태 관리 (JMH @State 사용)\n    @State(Scope.Benchmark)\n    public static class PoolState {\n        ObjectPool<byte[]> pool = new ObjectPool<>(\n            () -> new byte[1024], arr -> {}, 1000);\n    }\n\n    @Benchmark\n    public byte[] pooledAllocation(PoolState state) throws InterruptedException {\n        // 객체 풀을 이용한 할당/반환\n        byte[] buffer = state.pool.borrow();\n        // ... (간단한 사용 시뮬레이션) ...\n        state.pool.release(buffer);\n        return buffer; // 반환 값은 보통 의미 없음\n    }\n\n    @Benchmark\n    public ByteBuffer directAllocation() {\n        // 직접 메모리 할당\n        return ByteBuffer.allocateDirect(1024);\n        // 주의: 직접 메모리는 해제 로직이 다르므로 벤치마크 설계 시 고려 필요\n    }\n}\n결론\n\n고성능 애플리케이션을 위한 메모리 관리는 단순히 GC 튜닝을 넘어, 애플리케이션의 동작 방식과 데이터 특성에 맞는 최적화 기법을 선택하고 조합하는 과정이다. 객체 풀링, 직접 메모리, 캐시 친화적 설계, 오프힙 솔루션, 커스텀 할당자 등 다양한 전략이 있으며, 각각 장단점과 복잡성을 가진다.\n\n중요한 것은 모든 최적화는 가설에 불과하며, 반드시 실제 환경과 유사한 조건에서 성능 측정을 통해 효과를 검증해야 한다는 점이다.또한 이전에 얻은 교훈처럼 코드 복잡성 증가와 유지보수 비용을 고려하여 신중하게 접근해야 한다.\n\n다음 이번 시리즈 마지막 글에서는 ZGC, Shenandoah GC와 같은 최신 저지연 GC 알고리즘의 원리와 활용 방법, 그리고 메모리 관리 기술의 최신 동향에 대해 살펴볼 예정이다.\n\n참고 자료\n\nObject Pool Pattern:\nBaeldung: https://www.baeldung.com/java-object-pool\nSourceMaking: https://sourcemaking.com/design_patterns/object_pool\nJava NIO Direct Memory:\nOracle Java Docs (ByteBuffer): https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/nio/ByteBuffer.html (allocateDirect 메소드 참고)\nBaeldung: https://www.baeldung.com/java-direct-bytebuffer\nCache Friendly Design (Data-Oriented Design):\nWikipedia (Data-Oriented Design): https://en.wikipedia.org/wiki/Data-oriented_design\nGame Programming Patterns (Data Locality): https://gameprogrammingpatterns.com/data-locality.html\nOff-Heap Memory Solutions:\nChronicle Map: https://chronicle.software/products/chronicle-map/\nApache Ignite (Off-Heap Storage): https://ignite.apache.org/docs/latest/persistence/native-persistence (개념 설명)\nSlab Allocation:\nWikipedia: https://en.wikipedia.org/wiki/Slab_allocation\nJava Weak References:\nBaeldung: https://www.baeldung.com/java-weak-reference\nJava Memory Monitoring & Profiling:\nVisualVM: https://visualvm.github.io/\nOracle Docs (MemoryMXBean): https://docs.oracle.com/en/java/javase/17/docs/api/java.management/java/lang/management/MemoryMXBean.html\nJMH (Java Microbenchmark Harness):\nOpenJDK JMH Project: https://openjdk.java.net/projects/code-tools/jmh/\nTutorial by Jakob Jenkov: http://tutorials.jenkov.com/java-performance/jmh.html\nHunn\n명확한 문제 정의를 가장 중요시 여기는 개발자, 채기훈입니다.\n팔로우\n이전 포스트\nJVM의 메모리 구조와 가비지 컬렉션 기본 원리\n0개의 댓글\n댓글 작성\n관련 채용 정보\n화해(버드뷰)\nFrontend Developer\n화해 프론트엔드팀은 웹과 B2B 서비스 등을 개발하며, 사용자 경험을 최우선으로 생각하는 팀입니다. JavaScript, React 및 문제 해결 능력을 요구하며, 하이브리드 근무제와 무한 자율휴가 등으로 개발자 친화적인 환경을 제공합니다.\n타다(VCNC)\n웹 프론트엔드 개발\n타다와 함께 대한민국 모빌리티 시장을 혁신하며, 웹 프론트엔드 개발자로서 앱 내 화면을 개발할 기회를 잡으세요. React 및 TypeScript로 동작하는 유연한 개발 환경에서 동료들과 함께 문제를 해결하며 성장할 수 있는 기회가 기다립니다.\n이지시큐\nReact FrontEnd 개발자\n정보보호 전문 컨설팅 기업인 이지시큐에서 안정적인 환경 속에서 React 프론트엔드 개발자로 성장하세요. 유연한 업무와 성장을 지원하며, SECURIST 플랫폼의 기능 개발에 참여할 기회를 제공합니다.",
    "tags": [
      "메모리",
      "최적화"
    ],
    "commentCount": "0"
  },
  {
    "title": "기초 네트워크와 함께하는 Docker",
    "description": "오늘은 개발자로 취업하기 위해 꼭 알아야 할 네트워크(CS) 지식을 Docker 실습과 함께 기초부터 차근차근 배워보도록 하겠습니다!\n\n공인 IP 와 사설 IP\nIP 주소란?\n> 인터넷에서 컴퓨터 장비들이 서로를 인식하고 통신하기 위해 사용하는 주소\n\n(여기서 인터넷은...",
    "link": "https://velog.io/@kwon5700/%EA%B8%B0%EC%B4%88-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC%EC%99%80-%ED%95%A8%EA%BB%98%ED%95%98%EB%8A%94-Docker",
    "author": "kwon5700.log",
    "date": null,
    "comments": "3개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/kwon5700/post/4348e5f9-6c6e-47df-bba0-28c72826f826/image.png",
    "content": "kwon5700.log\n로그인\nkwon5700.log\n로그인\n기초 네트워크와 함께하는 Docker\n권민재·6일 전\n팔로우\n12\ndockernetworkserver\n\n이때까지 아무 생각없이 포트포워딩하며 컨테이너를 만들지는 않으셨나요? 그 원리가 궁금하시다면 바로 들어와서 실습까지 하고 가세요!!\n\n공인 IP 와 사설 IP\nIP 주소란?\n\n인터넷에서 컴퓨터 장비들이 서로를 인식하고 통신하기 위해 사용하는 주소\n\n(여기서 인터넷은 네트워크들의 네트워크를 의미하고, 컴퓨터 장비는 Host 를 의미합니다.)\n\n여러분들의 컴퓨터, 휴대폰은 인터넷을 이용하기 위해 각자 IP 주소를 할당 받은 상태입니다. 그렇다면 여러분들이 가진 IP 가 어떻게 생겼는지 궁금하실 수도 있는데요. 현재 대부분의 IP 프로토콜은 IPv4 이기 때문에 아마 xxx.xxx.xxx.xxx 의 형태를 가지고 있을 것입니다. (이때 xxx 는 8 비트입니다.)\n\n어라? xxx 가 8 비트라면 2^32 즉, IP가 약 42억 9천개 밖에 없는거 아니야? 전세계 인구가 70억이 넘는데.. 라고 생각하실 수 있습니다! 그래서 나온 개념이 IPv6 이라는 것도 있으며 사설 IP 라는 것도 있습니다. 이 글에서는 사설 IP 에 대해 더 자세히 다뤄보겠습니다. 우선은 사설 IP 를 이해하기 위해 공인 IP가 무엇인지부터 알려드리겠습니다.\n\n공인 IP란?\n\nISP 에게 할당받게 되는 IP 주소\n\n(여기서 ISP 는 한국에서는 KT, LG U+, SK 를 의미합니다.)\n\n공인 IP 는 전세계에서 특정할 수 있는 IP 주소입니다. 예를 들면 집주소 같은 것이죠! 제가 네이버를 가기 위해선 네이버의 본사 주소를 알아야 되듯이, 인터넷에서 네이버에 접속하기 위해선 네이버 서비스가 서빙된 서버의 공인 IP를 알아야 하는 것입니다.\n\n사설 IP란?\n\n부족한 공인 IP를 대체하여 라우터에게 할당받게 되는 IP 주소\n\n(여기서 라우터는 공유기를 의미합니다.)\n\n사설 IP는 라우터로부터 할당받게 되는 IP 주소입니다. 공인 IP를 집주소로 비유했다면 사설 IP는 그 집주소에 있는 아파트의 동호수라고 생각하시면 됩니다! 그렇다면 여기서 눈치가 빠르신 분들은 사설 IP는 고유한 것이 아니란 것을 아실 수 있습니다. 왜냐하면 아파트들의 집주소는 유일하지만 동호수 EX) 1402동 402호 는 다른 집주소의 아파트에도 있을 수 있기 때문입니다!\n\n이렇게 사설 IP는 라우터에게 할당받은 고유하지 않은 IP 주소를 의미합니다. 하지만 이때 사설 IP의 주소대역은 제한되게 됩니다. 왜냐하면 사설 IP 주소가 공인 IP와 겹치게 되면 나중에 나올 NAT 에 큰 문제가 생기기 때문입니다. 이 부분에 대해선 나중에 자세하게 말씀드리겠습니다.\n\n그리하여 사설 IP 의 주소대역은\n\nClass A : 10.0.0.0 ~ 10.255.255.255\nClass B : 172.16.0.0 ~ 172.31.255.255\nClass C : 192.168.0.0 ~ 192.168.255.255\n\n로 제한됩니다. 이때 각 주소대역 앞에 고정된 비트들이 보이실겁니다. 예를 들면 Class A 에서는 10, Class C 에서는 192.168 이렇게요. 사설 IP 의 앞자리를 고정시키는 방법은 다양하게 쓰일 수 있습니다! 지금부턴 비트를 고정시키면 좋은 이유와 자세한 내용에 대해 말씀드리겠습니다.\n\nCIDR\n\nIP 주소와 서브넷 마스크를 /숫자 형식으로 표현하는 방법으로,\n고정된 클래스 체계를 벗어나서 유연하게 IP 주소를 할당하고 라우팅할 수 있게 해주는 방식\n\nCIDR 은 온전히 사설 IP Class 에만 쓰이는 개념이 아닙니다.\n\n쉽게 설명하자면 CIDR 은 xxx.xxx.xxx.xxx 형식의 IP 주소 뒤에 /숫자를 붙여서, 앞에서부터 몇 비트를 네트워크 주소로 고정할 것인지 나타내는 방식입니다.\n\n예를 들어, 172.16.0.0/12 라는 CIDR 표기를 보았을 때, 이 IP 주소를 이진수로 바꾸면 10101100.00010000.00000000.00000000 이 되겠죠. 여기서 /12는 앞의 12비트를 고정한다는 뜻이므로, 고정되는 부분은 10101100.0001이 됩니다.\n• 10101100 → 172 (완전히 고정)\n• 0001 → 16의 앞 4비트만 고정되고, 뒤 4비트는 변할 수 있음\n즉, 00010000(16)부터 00011111(31)까지 변할 수 있기 때문에,\n결과적으로 172.16.0.0부터 172.31.255.255까지의 IP 주소를 사용할 수 있게 되는 것입니다.\n\n그렇다면 왜 사설 IP 주소대역을 제한하냐? 라고 생각이 드실 수 있는데 첫번째 이유는 앞서 말씀드렸듯이 공인 IP와 사설 IP가 겹치지 않게 하기 위함이고 두번째는 라우팅 범위를 제한하여 효율을 높이기 위함입니다. 예를 들면 192.168 범위에서 IP를 5개만 할당할건데 비트를 제한하지 않으면 범위가 192.168.0.0 ~ 192.168.255.255 로 엄청 넓어지게 되기 때문입니다.\n\n네트워크 인터페이스와 포트\n네트워크 인터페이스란?\n\n컴퓨터나 라우터와 같은 장치가 인터넷에서 통신할 수 있게 해주는 통로\n\n네트워크 인터페이스는 하드웨어적 인터페이스와 소프트웨어적 인터페이스로 나눌 수 있습니다. 하드웨어의 예시로는 (유선 랜, 무선 랜), 소프트웨어의 예시로는 가상 브릿지가 있습니다.\n\n대부분 여러분들은 컴퓨터에 랜선 또는 무선 랜을 연결하여 인터넷을 하고 있을 겁니다. 이때 랜선 또는 무선 랜으로 할당받은 IP 는 라우터로 부터 할당받은 사설 IP가 되겠죠.\n\n만약 여러분들이 구글의 공인 IP인 8.8.8.8 에 먼저 요청을 보내고 싶으시다면 사설 IP 를 할당받은 이상 마음껏 요청을 보내실 수 있습니다. 왜냐하면 공인 IP는 유일하기 때문에 특정할 수 있기 때문입니다.(이것이 큰 이유는 아니지만 나중에 왜 대부분 가능한 것인지 설명해드리겠습니다.) 하지만 반대로 구글이 여러분들의 컴퓨터에 먼저 요청을 보내고 싶을 땐 바로 요청을 보낼 수 없습니다. 왜냐하면 여러분들의 사설 IP는 여러분들의 공인 IP 안에서만 존재하는 것이기 때문이죠. (특정할 수 없다는 것도 맞는 말입니다.)\n\n이때 여러분들이 구글에 먼저 요청하는 방식은 OutBound, 구글이 먼저 여러분들에게 요청하는 방식은 InBound 방식이라고 합니다.\n\n그래서 여러분들은 구글이 여러분의 컴퓨터에 먼저 요청을 보낼 수 있도록 여러분들의 공인 IP와 사설 IP를 매핑하는 작업이 필요합니다. 이와 관련된 방법은 총 2개로 NAT 와 포트포워딩이 있습니다.(배우기 앞서 역할이 서로 다르다는 것을 알아주셨으면 합니다.) 우선 이 방법을 배우기 전, 포트가 무엇인지 알아야 하기 때문에 포트부터 설명해드리겠습니다.\n\n포트란?\n\n한 IP 안에서 어떤 프로그램과 통신할지 구분할 수 있게 하는 번호\n\n예를 들어, 내 사설 IP가 192.168.0.25 일 때 React vite 와 Next 를 동시에 실행시켰다면 어떤 프로그램에 접속할지 구별할 수 있어야 합니다. 이때 각 서비스마다 포트를 다르게 하여 React vite 는 http://192.168.0.25:5173, Next 는 http://192.168.0.25:3000 처럼 해두면 클라이언트는 어떤 프로그램에 접속하기 위해 어떤 포트로 접속해야 할지 알 수 있게 됩니다.\n\n그래서 포트가 무엇인지 한 줄로 요약하자면 컴퓨터 안에서 특정 서비스나 프로그램을 식별하기 위한 번호 라고 할 수 있습니다. (0~1023 사이의 포트번호는 잘 알려진 포트 well-known port 라고 하며 임의로 포트번호를 할당할 때 유의해야 합니다.)\n\n이렇게 포트가 무엇인지에 대한 개념을 배우셨다면 드디어 NAT 와 포트포워딩이 무엇이고 어떤 것이 다른지 배울 수 있게 되었습니다. 첫번째로 NAT 부터 설명해드리겠습니다.\n\nNAT 와 포트포워딩\nNAT란?\n\n공인 IP 하나로 여러 사설 IP 를 외부와 통신하게 해주는 주소 변환 방식\n\n이 방식은 OutBound 를 먼저 하기 위해 사용하는 방식입니다. 사실 사설 IP는 바로 공인 IP로 요청을 보낼 수 없습니다. 왜냐하면 고유하지 않기 때문에 인식되지 않도록 설계되었기 때문입니다. 그래서 공인 IP로 요청을 보내기 위해선 여러분들 라우터의 공인 IP를 거쳐야 합니다. 지금부턴 어떻게 동작되는지 개념적으로 알려드리겠습니다.\n\n여러분의 라우터 공인 IP를 124.111.25.9, 사설 IP를 192.168.0.25 라고 가정하겠습니다. 만약 여러분들이 구글에 OutBound 요청을 먼저 보내고 싶으시다면 NAT 테이블에는 이렇게 설정될 겁니다.\n\n공인 IP\t공인 IP 포트번호\t사설 IP\t사설 IP 포트번호\n124.111.25.9\t10001\t192.168.0.25\t80\n\n(여기서 공인 IP의 포트번호는 NAT 테이블에 겹치지 않게 자동으로 배정되며, 사설 IP의 80 포트는 http 웹서버를 의미합니다.)\n\n이렇게 구글에 OutBound 요청을 보내면\n\n사설 IP가 NAT 테이블에 의해 공인 IP로 변환된다.\n라우터의 공인 IP 가 구글의 공인 IP로 요청을 보낸다.\n돌아온 패킷이 라우터에 온 뒤, 라우터가 NAT 테이블을 보고 패킷을 사설 IP로 전달하여 InBound 가 된다. (OutBound 를 먼저 하면 InBound 가 잠시 가능함)\n\n이런 순서를 거쳐 OutBound 가 되게 됩니다. 이렇게 여러분들은 NAT 테이블을 통해 먼저 다른 공인 IP에게 요청을 날리는 방법에 대해서 알게 되셨습니다!\n\n그러면 다음은 공인 IP가 먼저 여러분의 컴퓨터에 InBound 할 수 있도록 하는 포트포워딩 방식에 대해서 설명해드리겠습니다.\n\n포트포워딩이란?\n\n공인 IP:포트번호와 사설 IP:포트번호를 매핑시켜 외부에서 접속할 수 있게 하는 주소 변환 방식\n\n포트포워딩은 구글이 먼저 여러분들의 사설 IP에 요청을 보내는 InBound 를 하는 상황에 필요한 방식입니다. 공인 IP 에서는 사설 IP로 바로 요청을 보낼 수 없습니다. 그 이유는 NAT 에서 설명한 이유와 비슷합니다.\n\n공인 IP\t공인 IP 포트번호\t사설 IP\t사설 IP 포트번호\n124.111.25.9\t80\t192.168.0.25\t80\n\n(NAT 방식은 대부분 라우터가 자동으로 해주지만 포트포워딩 방식은 직접 사용자가 공인 IP와 사설 IP를 지정하고 매핑해줘야 합니다.)\n\n이렇게 구글이 먼저 InBound 요청을 보내면\n\n구글이 124.111.25.9:80 주소로 요청을 보낸다.\n라우터에서 포트포워딩 테이블을 확인한 뒤 매핑된 사설 IP 와 포트번호로 요청을 전달한다.\n그 후 이 흐름에 대한 정보가 NAT 테이블에 등록된다.\n요청을 반환하는 패킷이 NAT 테이블을 참조하여 구글에게 다시 간다.\n\n이런 순서를 거쳐 InBound 가 되게 됩니다. 포트포워딩을 할 때 공인 IP의 포트번호는 사용자가 임의로 정해도 되지만 대부분 사설 IP 의 포트번호와 같게 하는게 좋습니다. 이렇게 하여 OutBound 와 InBound 가 어떻게 동작하는지 알아보았습니다.\n\n드디어 여러분들은 지금까지 배운 내용들로 직접 실습을 해볼 수 있게 되셨습니다!! 지금부턴 Docker 를 통해 지금까지 배운 내용을 복습해보겠습니다. (Docker 기본 문법을 모르시는 분들이 계시다면 제가 올린 Docker 기초부터 알려줄게 글을 읽고 오시는 것을 추천드립니다.)\n\nDocker 실습\n가상 네트워크 생성\n\n이번 실습의 큰 목표는 외부에서 먼저 InBound 요청을 보내는 것이기 때문에 여기선 실습을 위한 Docker 가상 네트워크 환경을 만들어보겠습니다.\n\n현재 여러분들의 컴퓨터는 라우터에게 하드웨어 인터페이스로 할당받은 사설 IP를 가지고 있을 것입니다. 하지만 쉬운 이해를 위해서 현재 여러분들의 컴퓨터 사설 IP 를 공인 IP 라고 가정하겠습니다. 우선 실습을 위해 Docker 를 실행시켜주세요.\n\n\n\ndocker network ls\n\n이 명령어는 현재 Docker 에 있는 네트워크 리스트를 조회하는 명령어입니다. 여러분들이 처음 Docker 에 들어가서 저 명령어를 사용한다면\n\nNETWORK ID\tNAME\tDRIVER\tSCOPE\n6566b7b897bd\tbridge\tbridge\tlocal\ned0b01df9cbf\thost\thost\tlocal\n8849b8025101\tnone\tnull\tlocal\n\n이런 형태의 데이터가 나오게 될 것입니다. 여러분들이 중점적으로 보셔야 할 것은 bridge 와 host 입니다. 여기서 bridge 는 컨테이너끼리 통신할 수 있게 중간에서 연결해주는 가상의 네트워크 방식입니다. 컨테이너는 생성될 때 bridge 네트워크의 CIDR 에 맞게 사설 IP 가 할당됩니다. 그러면 bridge 안에 있는 컨테이너끼리는 서로의 사설 IP 를 알기만 한다면 bridge 를 통해 통신할 수 있게 됩니다. 그리고 여기서 host 는 여러분들의 컴퓨터 IP 를 가집니다. 앞에서 여러분들의 컴퓨터 IP 를 공인 IP 라고 생각하자 했으니 host 는 공인 IP 를 의미하게 됩니다. 이를 통해 컨테이너가 외부로 OutBound 요청을 보내고 싶다면 host 를 통해 NAT 로 요청을 보낼 수 있는 것이죠.\n\n이렇게 기본적인 Docker 네트워크를 아셨다면 마저 실습을 진행해보겠습니다. 앞서 말씀드렸듯 bridge 는 bridge 안에서의 컨테이너끼리의 통신을 가능하게 하는 녀석이므로 bridge 를 1개 더 만든다면 서로 다른 네트워크를 가지게 될 것입니다.\n\n\n\ndocker network inspect 네트워크명\n\n이 명령어는 네트워크명의 상세 정보를 확인하는 명령어입니다. 이때 여러분들이 유심히 보셔야 할 정보는 IPAM 안에 Config 의 Subnet IP 입니다. 만약 여러분들의 bridge Subnet 이 172.17.0.0/16 으로 되어 있다면 여러분들 bridge 안에 있는 컨테이너들의 IP 는 172.17.0.2 ~ 172.17.0.255 로 설정될 것입니다.\n\n\n\ndocker network create --driver bridge --subnet 10.0.0.0/24 네트워크명\n\n이 명령어는 driver 가 bridge 이고 네트워크명 아래의 컨테이너 IP 를 10.0.0.2 ~ 10.0.0.255 까지만 가능하게 하는 새로운 네트워크를 만드는 명령어입니다. (저는 네트워크명에 second-bridge 를 입력했습니다.) 이러고 다시 네트워크를 조회하는 명령어를 사용해보면\n\nNETWORK ID\tNAME\tDRIVER\tSCOPE\n6566b7b897bd\tbridge\tbridge\tlocal\ned0b01df9cbf\thost\thost\tlocal\n8849b8025101\tnone\tnull\tlocal\n95324a17683e\tsecond-bridge\tbridge\tlocal\n\n이렇게 second-bridge 라는 이름을 가진 새로운 네트워크가 생긴 것을 확인해보실 수 있습니다. 그 뒤에 second-bridge 의 상세 정보를 확인하는 명령어를 사용해보면 IPAM 안에 Config 의 Subnet 이 10.0.0.0/24 로 된 것을 보실 수 있습니다. 지금부턴 2개의 분리된 네트워크가 생겼으니 각각 네트워크에 컨테이너를 만들어 보겠습니다. 원활한 실습을 위해 터미널창 2개를 켜주세요.\n\n\n\ndocker run -d --name nginx nginx\n\n우선 이 명령어를 첫번째 터미널창에 입력해주세요. 그러면 기본 bridge 에 nginx 라는 이름의 컨테이너가 백그라운드로 실행될 것입니다. 그 다음\n\n\n\ndocker container inspect nginx\n\n이 명령어로 다른 네트워크에서 nginx 컨테이너로 요청을 보내기 위해 nginx 컨테이너의 IP 를 알아낼 겁니다. IP 주소는 NetworkSettings 안에 Networks 안에 bridge 안에 있는 IPAddress 에서 확인하실 수 있습니다. 기본 bridge 의 Subnet 이 172.17.0.0/16 이였기 때문에 아마 nginx 컨테이너의 IP 는 172.0.0.2 일 것입니다. 그 다음은 두번째 터미널창으로 가주세요.\n\n\n\ndocker run -it --network second-bridge --name ubuntu devwikirepo/pingbuntu bin/bash\n\n이 명령어는 네트워크명이 second-bridge 인 곳에 ubuntu 라는 컨테이너를 만들고 인터랙티브 모드로 실행하는 명령어입니다. 여기까지 잘 따라오셨으면 드디어 다른 네트워크에 있는 nginx 컨테이너에 요청을 보낼 수 있습니다. 한 번 확인했던 nginx 컨테이너에 요청을 보내볼까요?\n\n\n\nping 172.17.0.2\n\n당연히 이 요청은 패킷을 다시 받지 못할 것입니다. 왜냐하면 172.17.0.2 는 사설 IP 이기 때문에 InBound 요청을 먼저 하려면 nginx 에서 포트포워딩을 해줘야 하기 때문이죠!! 그럼 잠시 공인 IP 로 OutBound 를 먼저 하는 것은 가능하다고 했으니 구글의 공인 IP 인 8.8.8.8 로 요청을 보내보겠습니다.\n\n\n\nping 8.8.8.8\n\n이 명령어는 아마 정상적으로 요청을 보낼 수 있을 것입니다. 왜냐하면 공인 IP 로 OutBound 요청을 먼저 보내기 위해선 NAT 테이블이 필요한데 여기선 라우터라고 가정한 우리의 컴퓨터가 자동으로 NAT 테이블에 공인 IP 와 사설 IP 를 매핑해줬기 때문이죠. 제가 방금 했던 말이 자연스럽게 이해되셨다면 정말 잘 따라오고 계신겁니다!!\n\n그러면 마지막으로 이 글의 목표인 외부에서 먼저 InBound 요청을 보내기 위해 포트포워딩을 하는 실습을 해보도록 하겠습니다!\n\n포트포워딩\n\nDocker 에서 포트포워딩을 하는 방법은 굉장히 단순합니다. 그렇기에 여러분들은 포트포워딩을 하는 이유와 포트포워딩을 한 뒤 일어나는 InBound 요청 과정에 대해 집중해주시길 바랍니다. 우선 포트포워딩을 하지 않았을 땐 외부에서 먼저 InBound 요청을 하지 못 한다는 것을 확인해야 하기 때문에 전에 만들었던 nginx 에 접속을 해보도록 하겠습니다. chrome 에 들어가서 http://localhost:80 이라고 입력해주세요. 아마 접속에 실패했다고 나올 것입니다. (nginx 의 기본 포트는 80 입니다.)\n\n이 이유는 외부에서 사설 IP 로 InBound 를 하기 위해선 라우터의 IP 와 사설 IP 를 매핑하는 작업인 포트포워딩을 해줘야 하는데 하지 않았기 때문입니다. 그러면 포트포워딩을 한 nginx2 라는 컨테이너를 만들어보겠습니다.\n\n\n\ndocker run -d -p 80:80 --name nginx2 nginx\n\n이 명령어는 원래 InBound 요청을 먼저 받지 못하는 사설 IP 를 가진 nginx2 컨테이너를 라우터의 80 포트에 포트포워딩 시켜 InBound 요청을 먼저 받을 수 있도록 하는 명령어입니다. (앞의 80은 라우터의 포트, 뒤에 80은 컨테이너의 포트입니다. nginx 의 포트는 무조건 80 포트이기 때문에 임의로 바꾸시면 안 됩니다!)\n\n이렇게 한 뒤 chrome 에 들어가서 http://localhost:80 을 해보시면 정상적으로 nginx 에 접속하신 것을 보실 수 있습니다! 이 이유는 외부에서 라우터의 IP:80 으로 요청을 보냈을 때 라우터에서 포트포워딩 테이블을 본 뒤 그 패킷을 매핑되어 있는 사설 IP 에 전달했기 때문입니다. 그 후에는 NAT 테이블에 자동으로 정보가 생성되어 Return 즉, OutBound 요청을 다시 외부로 하게 됩니다. 제가 방금 말한 모든 것을 이해하셨다면 정말 대단하신겁니당!!\n\n마무리\n네트워크 삭제\n\n지금까지 실습을 해서 새로운 네트워크도 생겼으니 이를 삭제하는 방법도 알려드리겠습니다.\n\n\n\ndocker stop ubuntu # 현재 실행 중인 ubuntu 컨테이너를 중지시킵니다.\ndocker rm -f ubuntu # ubuntu 컨테이너를 강제로 삭제합니다.\ndocker network rm second-bridge # second-brdige 라는 이름의 network 를 삭제합니다.\n\n이 명령어를 모두 하셨을 때 이상이 없으셨다면 오늘 했던 실습의 뒷정리를 완벽하게 하신겁니다.\n\n감사인사\n\n조금은 어려웠을 수도 있는 내용인 네트워크와 Docker 를 두서없이 알려드려 죄송합니다. 그래도 이 글이 여러분들께 기초부터 탄탄하게 시작하실 수 있는 발판이 되었으면 좋겠습니다. 긴 글 읽어주셔서 감사합니다!\n\n권민재\n팔로우\n이전 포스트\nDocker 기초부터 알려줄게\n다음 포스트\n개발자의 시선으로 보는 Implicit vs Explicit\n3개의 댓글\n댓글 작성\n정현\n5일 전\n\n도커를 이해하는데 정말 도움이 되는 글 같네요!\n감사합니다\n\n1개의 답글\n조재민\n4일 전\n\n유익해요!!\n\n답글 달기\n관련 채용 정보\n화해(버드뷰)\nFrontend Developer\n화해 프론트엔드팀은 웹과 B2B 서비스 등을 개발하며, 사용자 경험을 최우선으로 생각하는 팀입니다. JavaScript, React 및 문제 해결 능력을 요구하며, 하이브리드 근무제와 무한 자율휴가 등으로 개발자 친화적인 환경을 제공합니다.\n현대오토에버\n[FE Engineering] 개발/운영 및 Governance 체계 수립 - Frontend Engineer\n현대오토에버에서 완성차 운영 서비스를 개발하며 프론트엔드 기술 거버넌스를 수립할 기회를 잡아보세요. JavaScript와 React 등의 전문성을 발휘할 수 있는 창의적인 환경이 여러분을 기다리고 있습니다.\n미리디\n[미리캔버스] 프론트엔드 개발자\n미리캔버스는 디자인 생태계를 혁신하는 올인원 플랫폼으로, 1,400만 고객을 위해 프론트엔드 개발을 통해 사용자 경험을 최적화하고 있습니다. React와 Next.js를 활용해 확장 가능한 구조를 설계하며, 빠르게 변화하는 환경에서도 뛰어난 성능을 제공하는 팀의 일원이 되어보세요!",
    "tags": [
      "docker",
      "network",
      "server"
    ],
    "commentCount": "3"
  },
  {
    "title": "레이어드 아키텍처에서 단위 테스트가 어려운 이유",
    "description": ">  Spring 기반의 레이어드 아키텍처를 사용하다 보면, 단위 테스트(Unit Test)를 작성할 때 테스트 하기 힘든 메서드들을 만날때가 있습니다.\n>  특히 Repository와 Service 계층을 테스트할 때, \"이게 진짜 단위 테스트 맞나?\"라는 의문이",
    "link": "https://velog.io/@aeeengsungwoo/%EB%A0%88%EC%9D%B4%EC%96%B4%EB%93%9C-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%EC%97%90%EC%84%9C-%EB%8B%A8%EC%9C%84-%ED%85%8C%EC%8A%A4%ED%8A%B8%EA%B0%80-%EC%96%B4%EB%A0%A4%EC%9A%B4-%EC%9D%B4%EC%9C%A0",
    "author": "aeeengsungwoo.log",
    "date": null,
    "comments": "2개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/aeeengsungwoo/post/200be1fb-67c5-43b0-a480-a0fb83f3d0c5/image.png",
    "content": "aeeengsungwoo.log\n로그인\naeeengsungwoo.log\n로그인\n레이어드 아키텍처에서 단위 테스트가 어려운 이유\n성우·5일 전\n팔로우\n11\nTestCode\n목록 보기\n2/2\n\nSpring 기반의 레이어드 아키텍처를 사용하다 보면, 단위 테스트(Unit Test)를 작성할 때 테스트 하기 힘든 메서드들을 만날때가 있습니다.\n특히 Repository와 Service 계층을 테스트할 때, \"이게 진짜 단위 테스트 맞나?\"라는 의문이 들 때가 많죠.\n이번 글에서는 레이어드 아키텍처의 한계 중 하나인 '단위 테스트의 어려움'을 파헤치고, 그 원인을 하나씩 뜯어보며 해결책까지 고민해보겠습니다.\n\n레이어드 아키텍처 구조도\n\n레이어드 아키텍처의 한계\n레이어 사이 결합이 강해지면서 내부 캡슐화가 깨질 위험이 있다.\n기존 구조에서는 단위 테스트가 어렵고 JPA 환경에 의존적인 테스트를 하게된다.\nRepository 테스트 Mock을 만들 때 Jpa의 모든 메서드를 오버라이드 해야한다.\n\n레이어드 아키텍처에서 흔히 사용하는 패턴은 Repository가 JpaRepository를 직접 상속받는 구조입니다. 이 방식은 간편하고 강력하지만, 테스트에서는 문제가 됩니다. Repository가 JpaRepository를 상속받으면 테스트 코드 실행 시 JPA가 개입하게 되는데, 여기서부터 이야기가 꼬이기 시작합니다.\n\n1. JPA와 Hibernate의 강한 결합\n\nRepository가 JpaRepository를 직접 상속하면 테스트할 때 JPA가 끼어듭니다. 이게 기본적인 문제의 시작이에요.\n\n2. Hibernate 때문에 테스트가 어려운 이유\n\nJPA는 Hibernate를 사용해 데이터베이스와 소통합니다. 예를 들어, findByName 같은 메서드를 정의하면 Hibernate가 이름만 보고 쿼리를 만들어줍니다. 개발할 때는 편리하지만, 테스트에서는 문제가 됩니다.\n\n왜 어려울까?\nHibernate는 메서드 이름으로 쿼리를 추측해서 만들기 때문에 내부 로직을 우리가 제어하거나 확인하기 어렵습니다.\nRepository를 테스트하려면 Hibernate가 쿼리를 잘 만드는지 확인해야 하는데, 이건 Repository 로직이 아니라 Hibernate 동작을 검증하는 셈이죠.\nHibernate가 동작하려면 데이터베이스 연결과 JPA 설정이 필요해서 단순한 단위 테스트가 불가능해집니다.\n\"메서드 하나 테스트하려는데 왜 Hibernate까지 신경 써야 하지?\"라는 생각이 들기 때문입니다.\n3. Service 테스트까지 번지는 문제\n\nService는 Repository를 의존합니다. 단위 테스트는 의존성을 분리해야 하는데, Repository가 JPA에 얽혀 있으니, Service 로직을 테스트하려면 Repository와 JPA, Hibernate가 필요합니다. 단순한 로직도 데이터베이스 환경을 띄워야 하니 오버헤드가 커집니다.\n\n결국 단위 테스트가 아니라 통합 테스트가 되고, 실행 속도도 느려집니다.\n\n4. 해결책\n\nService의 진짜 단위 테스트를 하고 싶다면 Repository를 추상화하면 됩니다!!\n\n실제 구현체는 JpaRepository를 사용하고, 테스트에서는 가짜 객체(FakeRepository)를 주입합니다.\n\npublic class FakePostRepository implements PostRepository {\n    private static Long idCounter = 0L;\n    private final Map<Long, Post> postStore = new HashMap<>();\n\n    @Override\n    public Post save(Post post) {\n        Long id = post.getId() != null && post.getId() > 0 ? post.getId() : ++idCounter;\n        Post savedPost = Post.builder()\n                .id(id)\n                .postTitle(post.getPostTitle())\n                .postDescription(post.getPostDescription())\n                .postCategory(post.getPostCategory())\n                .prompt(post.getPrompt())\n                .build();\n        postStore.put(id, savedPost);\n        return savedPost;\n    }\n\n위의 코드처럼, 인메모리에서 처리할 수 있도록 구현하는거에요.\n원래라면 DB 혹은 영속성 객체에 저장되어야 할 객체를 인메모리 배열에 저장합니다.\n\npublic class PostDeletePostServiceTest {\n\n    private PostDeletePostService postDeletePostService;\n    private FakePostRepository fakePostRepository;\n    private FakeUserRepository fakeUserRepository;\n\n    @BeforeEach\n    void init() {\n        this.fakePostRepository = new FakePostRepository();\n        this.fakeUserRepository = new FakeUserRepository();\n\n        postDeletePostService = PostDeletePostService.builder()\n                .postRepository(fakePostRepository)\n                .userRepository(fakeUserRepository)\n                .build();\n                }\n}\n\nService 단위테스트 부분에선, FakeRepository를 상속받습니다.\n\n이렇게 구현하게 되면, Repository를 의존할 때 발생했던 JPA, DB 연동 문제는 전혀 발생하지 않게 됩니다. FakeRepository에선 JPA, DB와 관련된 코드는 하나도 없기 때문이죠!!\n\npublic class PostDeletePostServiceTest {\n\n    private PostDeletePostService postDeletePostService;\n    private FakePostRepository fakePostRepository;\n    private FakeUserRepository fakeUserRepository;\n\n    @BeforeEach\n    void init() {\n        this.fakePostRepository = new FakePostRepository();\n        this.fakeUserRepository = new FakeUserRepository();\n\n        postDeletePostService = PostDeletePostService.builder()\n                .postRepository(fakePostRepository)\n                .userRepository(fakeUserRepository)\n                .build();\n                }\n    @Test\n    void deletePost로_게시글을_삭제할_수_있다() {\n        // given\n        Long userId = 1L; // 게시글 작성자\n        Long postId = 1L; // 삭제할 게시글\n\n        // when\n        boolean result = postDeletePostService.deletePost(userId, postId);\n        // then\n        assertThat(result).isTrue(); // 행위 검증: 삭제가 성공했는지 결과 확인\n        assertThat(fakePostRepository.findById(postId)).isEmpty(); // 상태 검증: 게시글이 삭제된 상태 확인\n    }\n}\n\n그리고 Service의 단위테스트 부분에선, 배열(FakeRepository)에 값이 있는 상태에서, 삭제가 되는지 확인해주면 되는겁니다.\n\n한마디로, 행위 검증과 상태 검증을 둘다 해주는 과정입니다!\n\n테스트코드의 의존성 구조도를 그림으로 보면 이렇게 됩니다.\n\n\n실제 서비스의 구조도는 이렇게 되겠죠?!\n\n5. 결론\n\nService 단위 테스트에서 FakeRepository를 사용하면 JPA나 DB 없이도 로직을 검증할 수 있습니다.\n\n상태 검증으로 삭제 후 데이터가 없는지 확인하고,\n행위 검증으로 메서드가 의도대로 동작했는지 확인합니다.\n\n이렇게 하면 진정한 단위 테스트가 가능해지고, 테스트 속도도 빨라지며 불필요한 오버헤드가 사라집니다.\n작은 프로젝트에서라도 적용해보세요. 단위 테스트의 진짜 매력을 느끼실 겁니다!\n\n🙇🏻 글 내에 틀린 점, 오탈자, 비판, 공감 등 모두 적어주셔도 됩니다. 감사합니다..! 🙇🏻\n\n성우\n백엔드 개발자가 되고싶은 감자의 주절주저리\n팔로우\n이전 포스트\n레거시 코드에 TestCode 입히기 -Domain\n2개의 댓글\n댓글 작성\n조승현\n4일 전\n\n이런 방식이면 fakerepository가 상태를 가지니 테스트 메소드가 여러 개 존재할 때 각각의 테스트에서 insert한 자료가 다른 테스트 메소드에 영향을 끼치게 됩니다.\n통합테스트라면 의도한 동작이지만 단위테스트는 보통 각각의 환경이 격리된다고 가정하고 짜다보니 예기치 못한 동작이 나올 수 있어요.\n\n자칫 실수로 테스트 마지막에 delete해주지 않으면 insert 는 하나를 했는데 findAll의 size가 1이 아니거나 그럴 수 있겠죠.\n또한 junit은 병렬 테스트를 지원하다보니 여러 메소드가 동시에 실행되면 문제가 됩니다.\n예를 들어 testUserInsert() 와 testAdminDelete()가 각각 1L을 대상으로 테스트한다고 가정할 때 insert 테스트와 delete 테스트가 병렬로 시행되니 insert 검증 도중 값이 없어지는 오류가 나올 수도 있습니다.\n\n이를 피하기 위해서는 Mock 객체를 생성해주는 라이브러리를 사용하는 방법이 있습니다.\n\n답글 달기\n김성준\n2일 전\n\n저도 Mockito를 사용해서 모킹하거나 차라리 DataJpaTest 사용해서 db단까지 격리하지 않고 테스트하는게 나아보여요.\n\nFakeRepository가 실제 Repository가 다르게 동작하면 테스트 하는 의미가 없어질 수 있고요.\nRepository를 목킹하는건 레이어를 격리해서 테스트한다는 관점에서는 좋지만, Repository 단이 수정되면 목킹 사용한 테스트 코드들도 같이 수정되야 한다는 단점이 있습니다.\n\n답글 달기\n관련 채용 정보\n라포랩스(퀸잇)\n서버 엔지니어 (비즈니스 트라이브)\n퀸잇을 운영하는 라포랩스에서 서버 엔지니어를 찾습니다. Kotlin, Spring 등으로 비즈니스 성장을 이끄는 인프라를 개발하고, 임팩트 있는 도전의 주인공이 되어보세요!\n머스트핀테크\n[MUST-A] 풀스택 개발자 (신입)\n핀테크와 AI 기반 서비스를 제공하는 MUST FINTECH에서 혁신적인 웹서비스 개발 업무를 맡을 신입 풀스택 개발자를 찾습니다. Node.js 및 MySQL 경험을 활용하여 글로벌 프로젝트에 참여하며, 재택근무와 해외 워케이션 기회를 누릴 수 있습니다.\n머스트잇\nBack-end Engineer (3년 이상)\n대한민국의 온라인 명품 커머스 플랫폼 MUST IT에서 스마트 럭셔리의 새로운 경험을 만들고, 백엔드 개발로 혁신적인 서비스를 구축할 동료를 찾습니다. Kotlin, Spring Boot 등 다양한 기술 스택을 활용해 함께 성장할 기회를 놓치지 마세요!",
    "tags": [],
    "commentCount": "2"
  },
  {
    "title": "Korest Docs: Kotlin DSL로 Spring REST Docs를 더 쉽게 사용하기",
    "description": "Spring REST Docs 관련 오픈소스 개발기",
    "link": "https://velog.io/@komment/Korest-Docs-2",
    "author": "komment.dev",
    "date": "2025년 4월 3일",
    "comments": "0개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/komment/post/775a8fe7-4f41-4214-b79a-e1d410187934/image.png",
    "content": "komment.dev\n로그인\nkomment.dev\n로그인\nKorest Docs: Kotlin DSL로 Spring REST Docs를 더 쉽게 사용하기\nkomment·2025년 4월 3일\n팔로우\n13\nKorest-DocsSpringSpring bootkotlinkotlin-dslmaven centralspring-rest-docs오픈소스오픈소스 배포\n2025 개발 일지\n목록 보기\n2/2\n본 포스팅은 Kotlin+Spring 환경에서 Spring REST Docs를 편리하게 활용하기 위해 직접 개발한 오픈소스와 관련된 내용을 담고 있습니다. 오픈소스의 소스코드는 다음 링크에서 확인하실 수 있습니다.\n서론\n\n지난 글의 서론으로 대체합니다.\n\n  Spring Framework를 활용할 때 API 명세에 대하여 Swagger를 활용하는 것이 좋을지, Spring REST Docs를 활용하는 것이 좋을지 고민하던 때가 있었다. 필자는 현재 회사에서는 팀의 의견에 따라 Swagger를 활용하고 있는데, 개인적으로는 Spring REST Docs 쪽에 손을 들고 있다.\n\n  Swagger 편에 서서 이야기 하면 비교적 이쁜(?) 디자인과 curl call 테스트 지원을 장점으로 뽑을 수 있을 것 같다. 하지만 Swagger 어노테이션이 비즈니스 코드에 침투한다는 치명적인 단점을 갖고 있다.\n\n  반면 Spring REST Docs는 비즈니스 코드에 아무런 영향을 주지 않고, 테스트를 강제하면서 테스트 실패를 통해 API 인터페이스 변경을 감지해준다. 필자가 Restdocs를 선호하는 이유도 위와 같은데, 만약 Swagger가 제공하는 디자인과 기능이 마음에 든다면 Spring REST Docs로 명세를 하고, Swagger UI로 변환시켜줄 수 있다면 두 마리 토끼를 모두 잡을 수 있다.\n\nSpring REST Docs가 가진 문제점\n\n  하지만 Spring REST Docs를 싫어하는 사람도 적지 않은데, 가장 큰 이유가 바로 중복된 코드와 그에 따른 가독성 저하다. 아래는 Spring REST Docs를 활용하여 작성한 API 명세 예시 코드다.\n\n  더 많은 정보를 가지고 있는 Field가 제일 복잡해보이는데, header와 parameter도 optional 등의 정보를 추가한다고 가정하면 코드는 더 중복되고, 더 읽기 힘들어질 것이다.\n\n이런 기능이 있었으면 좋겠다.\n\n  이러한 문제들을 해결하고 싶었다. 다음은 필자가 생각했던 방향성이다.\n\n  andDocument() 확장함수를 통해 API 명세 후 다른 andDo() 작업을 할 수도 있고, 명세 목적이라면 documentation() 선언형 함수를 통해 가독성 좋게 명세가 가능하다.\n\n이미 오픈소스로 있을까?\n\n  어떤 기능을 개발할지 정한 후 가장 먼저 한 작업은 이미 오픈소스가 존재하는지 점검하는 것이었다. 더 있을지는 모르겠지만(찾기 꽤나 힘들다..) 다음의 두 사례를 찾을 수 있었다.\n\nspring-rest-docs-kotlin\ntosspayments-restdocs\n\n  앞선 포스팅에서 Spring REST Docs에 Issue-192, Issue-547, Issue-677가 올라와있는데, spring-rest-docs-kotlin는 관련 이슈들에서 많은 언급을 받았다. 하지만 아쉽게도 오픈소스는 아니었다.\n\n  토스 페이먼츠에서는 필자가 구현하려는 내용을 이미 구현하여 사용하고 있었다. (역시 내가 생각한건 다 있구나..) 하지만 찾아보니 내부에서 사용하는 오픈소스인듯 싶다. 따라서 해당 포스팅 또한 참고하여 직접 개발하고 배포해기로 결정했다.\n\n  그렇게 개발 및 배포돼 붙여진 이름이 Korest Docs 다.\n\nKorest Docs: Spring Restdocs Kotlin DSL library\n\n  Korest Docs는 Spring REST Docs를 보다 쉽고 편리하게 사용할 수 있도록 돕는 Kotlin DSL 기반의 API 문서화 라이브러리다. Spring REST Docs는 강력한 기능을 제공하지만, 설정이 복잡하고 많은 반복적인 코드가 필요하다. Korest Docs는 이러한 문제를 해결하기 위해 Kotlin의 DSL 스타일을 적극 활용하여 더욱 직관적이고 선언적인 방식으로 API 문서를 작성할 수 있도록 개선되었다.\n\n  이제 개발자는 불필요한 보일러플레이트 코드를 줄이고, 문서화에 집중할 수 있다. Korest Docs는 타입 추론, 기본 Snippet 자동 구성, Swagger UI 변환 등 다양한 편의 기능을 제공하여, Spring REST Docs의 기능을 그대로 유지하면서도 훨씬 간결하고 생산적인 문서화 환경을 제공한다. (몇몇 기능들은 아직 개발 진행중이다)\n\n1. Kotlin DSL을 활용한 선언형 API 명세\n\n  Korest Docs는 Kotlin DSL을 활용하여 선언형 방식으로 API 문서를 작성할 수 있도록 합니다. 이를 통해 가독성이 뛰어나며, 간결하고 구조화된 API 명세를 손쉽게 작성할 수 있습니다.\n\nfun MockMvc.requestWithDocs(\n    method: HttpMethod,\n    urlTemplate: String,\n    vararg vars: Any?,\n    dsl: MockHttpServletRequestDsl.() -> Unit = {},\n): ResultActionsDsl {\n    return request(method, urlTemplate, *vars) {\n        requestAttr(RestDocumentationGenerator.ATTRIBUTE_NAME_URL_TEMPLATE, urlTemplate)\n        dsl()\n    }\n}\n\n  기본적으로는 확장 함수를 통해 request에 Spring REST Docs를 설정해준다. 이를 통해 다음과 같이 명세가 가능하다.\n\nmockMvc.requestWithDocs(HttpMethod.GET, \"/example/{id}\", 1) {\n    header(HttpHeaders.AUTHORIZATION, \"Bearer access-token\")\n    param(\"param1\", \"value1\")\n}\n.andExpect {\n    status { isOk() }\n}\n.andDocument(\"identifier\") {\n    requestHeader {\n        header(\"Authorization\", \"Access Token\", \"Bearer access-token\")\n    }\n\n    pathParameter {\n        pathVariable(\"id\", \"id\", 1)\n    }\n\n    requestParameter {\n        queryParameter(\"param1\", \"parameter 1\", \"value1\")\n    }\n\n    responseField {\n        field(\"code\", \"Response Code\", ReturnCode.SUCCESS.code)\n        field(\"message\", \"Response Message\", ReturnCode.SUCCESS.message)\n        field(\"data\", \"Response Data\", data)\n        optionalField(\"data.message\", \"message\", data.message)\n        field(\"data.userId\", \"User Id\", data.userId)\n    }\n}\n.andDo {\n    // 생략\n}\n\n  만약 andDo()를 통한 추가 작업이 필요없다면 다음과 같이 명세할 수 있습니다.\n\ndocumentation(\"identifier\") {\n    request(HttpMethod.GET, \"/example/{id}\") {\n        pathVariable(\"id\", \"id\", 1)\n    }\n            \n    requestHeader {\n        header(\"Authorization\", \"Access Token\", \"Bearer access-token\")\n    }\n\n    requestParameter {\n        queryParameter(\"param1\", \"parameter 1\", \"value1\")\n    }\n\n    responseField {\n        field(\"code\", \"Response Code\", ReturnCode.SUCCESS.code)\n        field(\"message\", \"Response Message\", ReturnCode.SUCCESS.message)\n        field(\"data\", \"Response Data\", data)\n        optionalField(\"data.message\", \"message\", data.message)\n        field(\"data.userId\", \"User Id\", data.userId)\n    }\n}\n\n  이를 통해 명세에만 집중할 수 있게 되고, 가독성 또한 크게 향상된다.\n\n2. 타입 추론\n\n  Korest Docs는 요청 및 응답 모델에서 자동으로 타입을 추론하여 불필요한 반복 작업을 줄여줍니다. 다음은 FieldsSpec의 field() inline 함수다.\n\ninline fun <reified T : Any> field(\n    path: String,\n    description: String?,\n    example: T,\n    attributes: Map<String, Any> = mapOf(\"optional\" to false, \"ignored\" to false),\n) {\n    this.field(path, description, example, T::class, attributes)\n}\n\n  Kotlin에서 inline 함수를 대상으로 제공하는 Reified Type Parameter를 통해 Type 정보를 가져올 수 있다. 다음은 inline 함수에서 호출하는 field 메서드이다.\n\noverride fun <T : Any> field(\n    path: String,\n    description: String?,\n    example: T,\n    type: KClass<T>,\n    attributes: Map<String, Any>,\n) {\n    fields.putIfAbsent(path, example)\n    val descriptor = PayloadDocumentation.fieldWithPath(path)\n        .type(type.toFieldType().toString())\n        .description(description)\n        .attributes(*attributes.putFormat(type).toAttributes())\n\n    add(descriptor)\n}\n3. 기본 스니펫 재구성\n\n  Korest Docs는 기본 스니펫을 재구성하여 Type, Optional 등 필드가 확장된 API 문서 작성이 가능합니다. 다음은 각 요소별 필드 정보다.\n\n구분\t이름\t타입\t필수\t포맷\t설명\npath parameter\tO\tO\tX\tX\tO\nquery parameter\tO\tO\tO\tO\tO\nrequest header\tO\tO\tO\tX\tO\nrequest field\tO\tO\tO\tO\tO\nrequest part\tO\tX\tO\tX\tO\nrequest part field\tO\tO\tO\tO\tO\nresponse field\tO\tO\tO\tO\tO\n3. 추가될 기능\n\n  Korest Docs는 API 문서를 Swagger UI로 자동 변환하여 가시성을 높이는 기능을 제공할 계획이다. 또한, 다양한 확장 기능을 통해 API 문서 작성의 효율성을 극대화할 수 있다. 이 밖에도 여러 편의 기능들을 제공하기 위해 개발 중이다.\n\nMaven Central에 배포하기\n1. 회원가입 및 Namespace 설정\n\n  먼저 위의 링크를 통해 Maven Central 사이트에 들어가서 회원가입을 진행한 후 Namespace를 추가해주면 된다.\n\n  Namespace의 경우, 따로 도메인을 가지고 있지 않다면 io.github.{깃허브 계정}으로 등록해주면 된다.\n\n2. Maven Central 유저 토큰 발급\n\n  우측 상단에 View Account 메뉴에 들어가 유저 토큰을 발급해야한다. 발급 후에 username과 password는 꼭 따로 기록해두어야 한다.\n\n3. GPG키 생성 및 공개키 전송하기\n\n  오픈소스가 신뢰할 수 있는 프로젝트임을 보장하기 위해서는 서명을 해야 하는데, 이 때 OpenPGP 표준을 구현한 GnuPG를 통해 무료로 암호화 할 수 있다.\n\n# gnupg 설치\n$ brew install gnupg\n\n# 키 생성\n$ gpg --full-gen-key\n\n# 공개키를 keyserver에 등록\n$ gpg --keyserver keys.openpgp.org --send-keys GPG공개키\n\n# 비밀키 내보내기\n$ gpg --keyring secring.gpg --export-secret-keys > ~/.gnupg/secring.gpg\n4. gradle script 작성\n\n  gradle 스크립트를 작성하기 전에 지금까지 설정한 키들을 gradle.properties에 작성해줘야 한다.\n\nmavenCentralUsername=CENTRAL_USERNAME\nmavenCentralPassword=CENTRAL_PASSWORD\nsigning.keyId=GPG_PUBLIC_KEY\nsigning.password=GPG_PRIVATE_KEY_PASSWORD\nsigning.secretKeyRingFile=SECRET_KEY_PATH\n\n  이제 gradle 스크립트를 작성해주자. 여기서 오픈소스인 gradle-maven-publish-plugin을 활용해주었다. 아래 스크립트는 korest-docs-core의 build.gradle.kts다.\n\nimport com.vanniktech.maven.publish.SonatypeHost\n\n. . .\n\nmavenPublishing {\n    coordinates(\n        groupId = \"${property(\"group\")}\",\n        artifactId = \"${property(\"artifact\")}-core\",\n        version = \"${property(\"version\")}\"\n    )\n\n    pom {\n        name.set(\"korest-docs\")\n        description.set(\"Spring Restdocs extension library using Kotlin Dsl\")\n        inceptionYear.set(\"2025\")\n        url.set(\"https://github.com/lcomment/korest-docs\")\n\n        licenses {\n            license {\n                name.set(\"The Apache License, Version 2.0\")\n                url.set(\"https://www.apache.org/licenses/LICENSE-2.0.txt\")\n            }\n        }\n\n        developers {\n            developer {\n                id.set(\"lcomment\")\n                name.set(\"Hyunseok Ko\")\n                email.set(\"komment.dev@gmail.com\")\n            }\n        }\n\n        scm {\n            connection.set(\"scm:git:git://github.com/lcomment/korest-docs.git\")\n            developerConnection.set(\"scm:git:ssh://github.com/lcomment/korest-docs.git\")\n            url.set(\"https://github.com/lcomment/korest-docs.git\")\n        }\n    }\n\n    publishToMavenCentral(SonatypeHost.CENTRAL_PORTAL)\n    signAllPublications()\n}\n5. 배포\n\n  이제 배포를 진행해보자. 다음의 명령어를 통해 배포할 수 있고, 설정에 문제가 없다면 배포가 성공한다.\n\n$ ./gradlew publishAllPublicationsToMavenCentralRepository\n\n  배포 후에는 Maven Central에서 확인 가능한데, publish를 하면 취소가 불가능하니 잘 확인하고 publish를 진행하자.\n\n  이후에는 이렇게 mvnrepository에서도 확인할 수 있다. (mvnrepository에서 보기까지는 시간이 조금 걸린다.)\n\nKorest Docs 사용해보기\n\n  그럼 배포한 Korest Docs를 간단하게 사용해보자. (Document를 작성하고 있지만 아직 완성하지 못했다..)\n\n  먼저 의존성을 추가해줘야 한다.\n\n// build.gradle.kts\ndependencies {\n    implementation(\"io.github.lcomment:korest-docs-starter:1.0.0\")\n}\n\n  이제 활용한 테스트 코드를 확인해보자. (전체코드: 링크)\n\n@SpringBootTest\n@ExtendWith(KorestDocumentationExtension::class)\ninternal class ApiSpec {\n\n    @MockBean\n    lateinit var exampleService: ExampleService\n    \n    @Test\n    fun `korest docs test`() {\n        val data = ExampleResponse()\n        doReturn(data).`when`(exampleService).get()\n        \n        documentation(\"identifier\") {\n            request(HttpMethod.GET, \"/example/{id}\") {\n                pathVariable(\"id\", \"id\", 1)\n            }\n            \n            requestHeader {\n                header(\"Authorization\", \"Access Token\", \"Bearer access-token\")\n            }\n\n            requestParameter {\n                queryParameter(\"param1\", \"parameter 1\", \"value1\")\n            }\n\n            responseField {\n                field(\"code\", \"Response Code\", ReturnCode.SUCCESS.code)\n                field(\"message\", \"Response Message\", ReturnCode.SUCCESS.message)\n                field(\"data\", \"Response Data\", data)\n                optionalField(\"data.message\", \"message\", data.message)\n                field(\"data.userId\", \"User Id\", data.userId)\n            }\n        }\n    }\n}\n\n  더 자세한 설명은 Korest Docs 공식문서에서 확인할 수 있다.\n\n여담\n\n  Korest Docs와 관련하여 어떤 편의 기능이 더 있으면 좋을지 항상 생각하고, 이를 ISSUE에 올려두고 있다. 관심이 있는 개발자분들이라면 한번 살펴보고 같이 작업해나가는 날이 빨리 왔으면 좋겠다.\n\nkomment\n안녕하세요. 서버 개발자 komment 입니다.\n팔로우\n이전 포스트\nSpring REST Docs 파헤치기\n0개의 댓글\n댓글 작성\n관련 채용 정보\n채널코퍼레이션\n[채널톡] Software Engineer\n채널톡은 아시아에서 가장 빠르게 성장하는 B2B SaaS 회사로, '올인원 AI 메신저'를 통해 고객 소통을 혁신하고 있습니다. 다양한 기술 스택을 활용해 글로벌 시장의 복잡한 문제를 해결할 수 있는 엔지니어를 기다립니다.\n젭(zep)\n프론트엔드 개발자\nZEP은 교육과 퀴즈 플랫폼을 통해 공교육 혁신에 나선 에듀테크 스타트업으로, React 기반의 신규 기능 개발과 팀워크 강화에 중점을 둡니다. 기술 도전과 비즈니스 임팩트를 함께 이루는 환경에서 성장할 개발자를 기다립니다.\n스터닝\n프론트엔드 개발자(신입)\n프론트엔드 개발자로서 국내 최대 크리에이티브 플랫폼 스터닝에서 UX/UI 협업 및 웹 서비스 개발을 통해 창작자의 가치를 실현하는 데 기여해보세요. React, Typescript, Next.js와 같은 기술을 활용하며 유연한 근무 환경에서 업무에 몰입할 수 있습니다.",
    "tags": [
      "Korest-Docs",
      "Spring",
      "Spring boot",
      "kotlin",
      "kotlin-dsl",
      "maven central",
      "spring-rest-docs",
      "오픈소스",
      "오픈소스 배포"
    ],
    "commentCount": "0"
  },
  {
    "title": "[AWS] EC2+Lambda+EventBridge 사용해서 원하는 시간대만 서버 켜두기",
    "description": "아... 저번달에 8달러 더 나갔다..",
    "link": "https://velog.io/@hyeonji8436/AWS-EC2LambdaEventBridge-%EC%82%AC%EC%9A%A9%ED%95%B4%EC%84%9C-%EC%9B%90%ED%95%98%EB%8A%94-%EC%8B%9C%EA%B0%84%EB%8C%80%EB%A7%8C-%EC%84%9C%EB%B2%84-%EC%BC%9C%EB%91%90%EA%B8%B0",
    "author": "hong.log",
    "date": null,
    "comments": "1개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/hyeonji8436/post/d301999e-8377-46f4-991e-861306caf424/image.png",
    "content": "hong.log\n로그인\nhong.log\n로그인\n[AWS] EC2+Lambda+EventBridge 사용해서 원하는 시간대만 서버 켜두기\n홍현지·약 3시간 전\n팔로우\n4\nawsec2eventbridgelambda\n\nBooLock 서비스 만들면서 지원받은 크레딧을 다 써서 aws 프리티어 사용하려고 서버를 옮긴 적이 있다.\n\n그리고 내가 간과한 게 있다. public, private 서버 두개를 돌리는데, 24 * 31 * 2 하면 프리티어에서 무료로 지원해주는 시간인 750시간은 족히 넘긴다는 사실을 말이다.\n\n그래서 오후 시간대만 서버를 구동시키기로 했다. 그리고 이걸 당연히 자동으로 서버가 꺼졌다, 켜졌다가 할 수 있도록 관리해야했다..\n\nAWS Lambda와, EventBridge를 이용해서 08:00~20:00 동안만 서버를 구동하도록 설정해주었다.\n\n1. IAM 설정\n\n만약 별도의 IAM 계정을 사용하지 않고 root 계정을 사용할 것이라면 1-2만 확인하고 나머지는 건너 뛰어도 된다.\n\n나는 BooLock 서비스를 AWS로 배포하면서, boolock 이라는 IAM 계정을 하나 만들어서 이를 통해서 EC2, VPC 등등의.. 설정을 해주었다.\n\nBooLock 관련 AWS 설정들은 전부 이 boolock 계정을 통해 관리할 생각이었기에, Lambda 함수를 생성할 때와 EventBridge 규칙 생성에 필요한 권한들을 추가적으로 부여해 주어야했다.\n\n사용자 그룹을 Lambda용, EventBridge 용으로 따로 나눠서 생성해주고, boolock 사용자를 그룹에 추가하는 방식으로 해주었다. (나중에 다른 서비스도 내 계정으로 쓸지도 모르자낭..~~)\n\n1-1. role, policy 관련 정책 생성\n\nLambda와 EventBridge 서비스 모두 함수를 생성하든, 규칙을 생성하든 해당 함수나 규칙이 개별적인 IAM Role와 Policy를 갖게 되며, 함수와 규칙을 생성할 때 자동으로 할당된다.\n\nAWS에서 자동으로 할당해주지만, 아무튼 role, policy를 생성하고 붙여주는 것이다보니 lambda함수와 EventBridge 규칙을 생성해주는 IAM 계정에 이 role과 policy를 생성해주고 붙여주는 권한이 필요하다.\n\n그리고 그 액션은 iam:CreatePolicy, iam:CreateRole, iam:AttachRolePolicy, iam:ListPolicies 이다. 이 네개 권한만 갖고 있는 정책은 없기 때문에 정책을 추가적으로 생성해주었다.\n\n(굳이 이 4개의 액션만을 가지는 정책을 별도로 만드는 이유는, iam에 대한 권한은 서브 계정에 엄격하게 지정해주고 싶었기 때문일 뿐 이 과정을 건너뛰고 IAMFullAccess를 해줘도 상관 없다)\n\nIAM -> 정책 -> 정책 생성 순으로 들어간다.\n\n권한 지정의 정책 편집기를 보면 시각적/JSON으로 나뉘어져 있는데, JSON을 선택해준다.\n\n{\n\t\"Version\": \"2012-10-17\",\n\t\"Statement\": [\n\t\t{\n\t\t\t\"Sid\": \"Statement1\",\n\t\t\t\"Effect\": \"Allow\",\n\t\t\t\"Action\": [\n\t\t\t\t\"iam:CreatePolicy\",\n\t\t\t\t\"iam:AttachRolePolicy\",\n\t\t\t\t\"iam:CreateRole\",\n              \t\"iam:ListPolicies\"\n\t\t\t],\n\t\t\t\"Resource\": [\n\t\t\t\t\"*\"\n\t\t\t]\n\t\t}\n\t]\n}\n\n위 JSON을 정책편집기에 작성해준다.\n\n정책 이름을 추가해주고 정책 생성을 해준다. 나는 iam_rolePolicyCreate 으로 설정해주었다.\n\n1-2. EC2 관련 정책 설정\n\nEC2 관련 정책은 lambda 함수에서 EC2 인스턴스 시작, 중지, 조회를 하기위해서 필요하다.\n나중에 lambda 함수를 만들고 난 후 추가로 이 정책을 할당해주어야한다.\n\nIAM -> 정책 -> 정책 생성 순으로 들어간다.\n\n권한 지정의 정책 편집기를 보면 시각적/JSON으로 나뉘어져 있는데, JSON을 선택해준다.\n\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"VisualEditor0\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"ec2:StartInstances\",\n                \"ec2:StopInstances\",\n                \"ec2:DescribeInstances\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\n\n위 JSON을 정책편집기에 작성해준다.\n\n정책 이름을 추가해주고 정책 생성을 해준다. 나는 lambda_ec2_control 으로 설정해주었다.\n\n1-3. 사용자 그룹 설정\n\nIAM -> 사용자 그룹 -> 그룹 생성 순으로 들어가서 그룹 생성을 해주면 된다.\n\nLambda용은 lambda, EventBridge의 용은 eventbridge 으로 이름을 지어주었다.\n\n\n그리고 사용자 그룹에 내가 사용할 boolock 사용자를 추가해주었다.\n\n4-1. Lambda 함수 생성 및 관리 용 정책을 추가해주어야하니 AWSLambda_FullAccess 권한을 추가해주었다.\n\n4-2. EventBridge 용은 AmazonEventBridgeFullAccess 권한을 추가해주었다.\n\n4-3. 두 사용자 그룹 모두 위에서 만든 iam_rolePolicyCreate 이 정책도 추가해주었다.\n\n사용자 그룹 생성해주면 끝 ~\n2. lambda 함수 생성\n\nlambda함수는 EC2 서버를 시작해주는 start함수와 중지해주는 stop함수 두개를 나눠 만들었다.\n\n함수 생성은 lambda 서비스 -> 함수 -> 함수 생성 순으로 들어가서 해주면 된다.\n\n이름은 그냥 boolock-server-stop/start 로 해주었다.\n\n그리고 둘 다 런타임은 node.js로 해주고, 함수 생성 해준다.\n\n2-1. 서버 시작 함수 코드 및 트리거 설정\n함수 코드 수정\n\n서버 시작 함수를 생성했으면, 먼저 코드 소스에서 아래와 같이 코드를 수정한다.\n\nimport { EC2 } from '@aws-sdk/client-ec2';\n\nconst ec2 = new EC2();\n\nexport const handler = async (event) => {\n  try{\n    const instanceIdList = [EC2_ID_List];\n\n    const params = {\n      InstanceIds: instanceIdList \n    };\n\n    const data = await ec2.startInstances(params);\n\n    console.log('인스턴스 시작 성공:', JSON.stringify(data));\n\n    return {\n      statusCode: 200,\n      body: JSON.stringify({\n          message: 'EC2 인스턴스 시작 완료',\n          data: data\n      })\n  };\n  }catch(error){\n    console.error('인스턴스 시작 중 오류 발생:', error);\n        \n    return {\n        statusCode: 500,\n        body: JSON.stringify({\n            message: '인스턴스 시작 실패',\n            error: error.message\n        })\n    };\n  }\n};\n\n\nconst instanceIdList = [EC2_ID_List]; 여기에 반드시 자동으로 시작할 ec2 서버 인스턴스 id들을 넣어줘야한다. (문자열 배열로)\n\n그리고 좌측에 있는 DEPLOY 버튼을 눌러줘야지 함수 코드가 적용된다.\n\nec2 정책 추가\n\n구성 -> 권한 -> 실행 역할의 역할 이름 아래에 있는 링크를 클릭해서 들어간다.\n\n해당 역할의 권한 정책의 우측에서 권한 추가 -> 정책 연결로 들어간다.\n\n검색에서 아까 만들었던 lambda_ec2_control를 검색하고, 정책을 추가해준 후 권한 추가 버튼을 눌러준다.\n\n트리거 추가\n\nec2 정책까지 추가해주었으면 이제 오전 8시에 서버를 켜주기 위한 트리거를 추가해준다.\n\n함수 개요의 다이어그램에 있는 트리거 추가 버튼을 클릭한다.\n\n트리거 소스를 선택해주어야하는데 EventBridge를 선택해준다.\n\n새 규칙 생성 으로 선택해주고, 이름과 추가로 설명이 필요하면 설명도 추가해준다. 나는 그냥 startAt8AM으로 해주었다.\n\n그리고 규칙 유형은 예약 표현식으로 해주고, 표현식은 cron(0 8 * * ? *) 이렇게 써준다. 그리고 트리거 추가를 해주면 트리거가 추가된다.\n\n2-2. 서버 중지 함수 코드 및 트리거 설정\n\n서버 중지 함수도 서버 시작 함수와 해야하는 과정은 똑같다.\n\n함수 코드 수정\nimport { EC2 } from '@aws-sdk/client-ec2';\n\nconst ec2 = new EC2();\n\nexport const handler = async (event) => {\n  try{\n    const instanceIdList = [EC2_ID_List];\n\n    const params = {\n      InstanceIds: instanceIdList \n    };\n\n    const data = await ec2.stopInstances(params);\n\n    console.log('인스턴스 중지 성공:', JSON.stringify(data));\n        \n    return {\n        statusCode: 200,\n        body: JSON.stringify({\n            message: 'EC2 인스턴스 중지 완료',\n            data: data\n        })\n    };\n  }catch(error){\n    console.error('인스턴스 중지 중 오류 발생:', error);\n        \n    return {\n        statusCode: 500,\n        body: JSON.stringify({\n            message: '인스턴스 중지 실패',\n            error: error.message\n        })\n    };\n  }\n};\n\n해당 함수로 deploy 해주면 된다.\n\nec2 정책 추가\n\nec2 정책 추가는 위 과정과 동일하게 해주면 된다.\n\n트리거 추가\n\n트리거 또한 위 과정과 동일하게 해주고, 예약 표현식만 cron(0 20 * * ? *) 으로 해주면 된다.\n\n마치며\n\nlambda 함수가 잘 작동되는 것은 lambda 함수에서 테스트를 생성해서 테스트해봐도 되고, 아니면 CloudWatch의 로그그룹에 함수 실행 결과가 로그로 남아있기에 로그를 확인해주어도 된다.\n\nboolock 서버는 docker 와 mongodb를 사용하기 때문에 서버를 껐다 킬때마다 몽고 서버도 열고, docker도 재시작해주어야하는데, 이 설정은 다음 포스팅에서 ssl인증서 자동 발급 스크립트와 함께 설명하도록 하겠다.\n\n\n\n\n끝!\n\n홍현지\n이상하다 난 분명 프엔인데\n팔로우\n이전 포스트\n[AWS] EC2로 서버 구축하기\n1개의 댓글\n댓글 작성\n최씨\n약 2시간 전\n\n인프라 개발 응원합니다 :)\n\n답글 달기\n관련 채용 정보\n클래스101(Class101)\n소프트웨어 엔지니어\n크리에이터의 성공을 지원하는 클래스101에서 소프트웨어 엔지니어로 혁신적인 결제 시스템과 플랫폼 기반 기술을 개발하세요. AWS와 다양한 최신 기술 스택을 활용해 견고한 성장의 일원이 되어 보세요!\n화해(버드뷰)\nBackend Developer\n화해는 글로벌 서비스를 위한 백엔드 개발을 통해 RESTful API와 MySQL 데이터베이스 설계를 맡아 전문성을 키울 수 있는 환경을 제공합니다. 하이브리드 근무제와 자기계발비 지원 등으로 개발자에게 최적화된 업무 환경을 마련하고 있습니다.\n텐핑거스(10fingers)\n[데이트팝]Python 백엔드 개발자(0~5년)\n데이트팝은 350만 소상공인을 위한 마케팅 플랫폼으로, 유저 피드백을 즉각적으로 반영하는 B2C 서비스입니다. Python, AWS, Django 등을 활용해 REST API 개발 및 클라우드 인프라 관리 업무를 맡으며, 협력 중시의 개발 문화를 경험할 수 있습니다.",
    "tags": [
      "aws",
      "ec2",
      "eventbridge",
      "lambda"
    ],
    "commentCount": "1"
  },
  {
    "title": "대학교 챗봇\n- (1)RAG 기술 선택 배경과 프로세스",
    "description": "우리 대학교 홈페이지는 원하는 정보를 얻기 굉장히 힘들다. 예를 들어 \"부전공 필수과목\" 검색 시 검색과 상관 없는 자료들이 나와서 확인하는데 오랜 시간이 걸린다. 새내기때도 정보를 찾기 어려웠고, 헌내기인 지금에도 정보를 찾기 위해 홈페이지를 뒤적이는게 귀찮다는 생각...",
    "link": "https://velog.io/@kky1373/%EB%8C%80%ED%95%99%EA%B5%90-%EC%B1%97%EB%B4%87-%EC%84%9C%EB%B9%84%EC%8A%A4-%EB%A7%8C%EB%93%A4%EA%B8%B0",
    "author": "kky1373.log",
    "date": "2025년 3월 31일",
    "comments": "6개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/kky1373/post/cecf67ac-75a2-41e8-8241-85c612647711/image.png",
    "content": "kky1373.log\n로그인\nkky1373.log\n로그인\n대학교 챗봇 - (1)RAG 기술 선택 배경과 프로세스\n가연·2025년 3월 31일\n팔로우\n12\nLLMrag챗봇\n2025 캡스톤\n목록 보기\n1/1\n\n우리 대학교 홈페이지는 원하는 정보를 얻기 굉장히 힘들다. 예를 들어 \"부전공 필수과목\" 검색 시 검색과 상관 없는 자료들이 나와서 확인하는데 오랜 시간이 걸린다. 새내기때도 정보를 찾기 어려웠고, 헌내기인 지금에도 정보를 찾기 위해 홈페이지를 뒤적이는게 귀찮다는 생각이 들었다.\n그래서 이번 산업공학과 캡스톤으로 대학교 홈페이지 정보 접근성을 개선하기 위한 챗봇 구현을 진행하게 되었다.\n\n1. LLM 환각 현상\n\n생성형 AI를 사용해 본 사람이라면 AI가 앞뒤가 맞지 않는 말을 하거나 아예 현실에 없던 새로운 내용을 만들어내는 것을 경험해 본 적 있을 것이다.\n생성형 AI에서는 데이터의 공백을 채우려고 시도하거나, 입력에 문제가 있을 때 환각 현상을 일으킨다.\n학습 데이터와 모순되는 출력을 생성하거나(외재적 환각) 학습 데이터에서 확인할 수 없는 출력을 생성하는(내재적 환각) 환각 현상이 발생한다.\n이러한 환각 현상은 챗봇의 신뢰성을 저하시키고, 사실처럼 보이는 허구로 사용자를 교묘하게 속일 수 있어 반드시 해결해야 할 중요한 문제이다.\n\n2. RAG(Retrieval-Augmented Generation)\n\nllm 의 환각 현상을 해결하기 위해 RAG 를 사용하게 되었다.\nRAG는 검색 기능을 활용해 LLM 텍스트 생성에 도움을 주는 기술이다.\n이 방식은 외부 지식을 참조함으로써 모델이 사실에 기반한 정확한 정보를 제공할 수 있게 하여 환각 현상을 줄여준다.\n\n프로세스\n\nRAG 는 질문이 들어왔을 때 미리 저장해 둔 데이터들을 기반하여 LLM 이 정확도 높은 답변을 생성하도록 도와준다.\n\nRAG 의 기본 프로세스는 다음과 같다.\n\n\n사용자가 질문을 한다.\n사용자의 질문을 임베딩(벡터화)한다.\n벡터 데이터베이스에서 이 임베딩과 유사도가 높은 문서나 청크를 검색한다.\n검색된 관련 정보와 원래 질문을 LLM의 프롬프트에 포함시켜 응답을 생성한다.\n생성된 응답을 사용자에게 제공한다.\n\n우리는 이러한 프로세스를 위해 외부 데이터를 가져와 전처리&임베딩 후 디비에 저장하고, 검색 알고리즘과 후보정을 구현하면 된다.\n\n데이터\n\n대학교 챗봇을 위해 필요한 데이터를 생각해보았다.\n데이터의 종류는 총 두가지이다.\n1️⃣ 첫번째는 전남대학교 홈페이지의 믿을만한 정보이다.\n전남대학교 홈페이지의 학사일정, 각 학과의 설명, 필수 이수과목, 공지사항 등의 데이터를 스크래핑 하여 데이터를 생성할 예정이다.\n\n2️⃣ 두번째는 에브리타임의 정보들이다.\n에브리타임의 답변들은 신뢰할만한 정보가 아니기 때문에 자주 올라오는 질문들만 가져와서 직접 답변을 찾아 데이터를 추가해 줄 예정이다.\n\n임베딩 기법\n\n임베딩은 희소 표현 임베딩과 밀집 표현 임베딩이 있다.\n\n🤖 희소 표현 임베딩(원-핫 인코딩)은 표현하고자 하는 단어만 1로, 나머지는 0으로 표현된다. 공간 낭비가 크고, 단어 간 의미적 관계를 파악하지 못한다. 하지만 고유명사나 특정 키워드의 경우 정확도가 높아진다.\n🖋️ 밀집 표현 임베딩은 단어의 의미를 저차원의 실수 벡터로 표현한다.\n단어 간 관계와 유사성을 측정할 수 있어 단어의 의미 기반 검색이 가능하다.\n\n희소 표현 기반 검색 알고리즘에는 TF-IDF(혹은 개선된 버전인 BM25)를,\n밀집 표현 기반 검색 알고리즘에는 코사인 유사도가 많이 사용된다.\n\n최근에는 BERT,RoBERTa 와 같은 트랜스포머 기반 모델의 임베딩과 CLIP 과 같은 다중 모달 임베딩 기술이 발전하고 있다.\n\n우리 팀은 최소 기능을 구현할 때는 밀집 표현 임베딩 방식(신경망 기반 임베딩, GPT 임베딩 모델)을 사용하고, 추후 키워드 기반 검색 기능을 추가할 때 BM25와 같은 희소 표현 검색 방식을 추가하여 하이브리드 검색 시스템을 구축할 예정이다.\n\nRAG vs Fine-tuning\n\n파인튜닝\n\n도메인의 전문성을 더 잘 표현할 수 있다.\n응답 생성 시 일관된 스타일과 형식을 유지한다.\n🚫 하지만, 데이터의 정적 스냅샷에 의존해서 최신 정보를 반영하려면 지속적인 재학습이 필요하다.\n또한 비용이 높으며 모델 내부에 정보가 통합되어 투명성이 낮다.\n\nRAG ✅\n\n동적 데이터 환경에서 효과적이다.\n비용이 상대적으로 저렴한 편이다.\n프로세스의 투명성이 높아 정확성 검증에 유리하다.\n🚫 하지만 검색된 정보의 품질에 의존적이며, 도메인 특화 표현 방식 학습에 한계가 있다.\n\n대학교 정보는 지속적으로 바뀌며 전문성 있는 정보들은 아니기 때문에 RAG가 적합하다고 생각하여 RAG를 선택했다.\n\n3. 기술 스택\n\n\n개발 구조는 이렇다.\nSelenium 으로 홈페이지를 스크래핑 하고, langchain 을 활용해 전반적인 RAG를 구현할 것이다. 임베딩 라이브러리로는 gpt 임베딩 모델을, 언어 모델로는 Gemini, UI 로는 gradio 를 활용할 계획이다.\n\n레퍼런스\n\n환각 현상의 원인과 해결책\n\nRAG or 파인튜닝? 선택 전 던져야할 몇가지 질문들\n\nLLM의 한계를 보완하는 기술 :RAG\n\n고상희 et.al, RAG 기반 LLM을 적용한 공지사항 챗봇 시스템 개발\n\n가연\n팔로우\n6개의 댓글\n댓글 작성\n앵우\n2025년 3월 31일\n\n우왕우앙 RAG에 대해서 넘 잘 공부하셨네요!! 👍🏻👍🏻\n\n벡터db로 chromadb를 선택하셨는데 인메모리 데이터베이스라 개발 환경과 맞추기 어려울 수도 있는 점이 있어요. 그래서 한번 pinecone도 추천해드리고 싶어요! pinecone 단점으로는 무료 계정은 하나의 데이터베이스밖에 사용 못 하지만 클라우드상의 데이터베이스이고 gpt 기반 임베딩 모델이 제공된다는게 장점입니다!\n\n그리고 챗봇 UI로 streamlit도 추천드리고 싶습니다! 파이썬 기반으로 작성되는데 아마 어려움은 없을거에요! 옵션이 다양해서 gradio보다 챗봇 페이지를 능력껏 커스텀할 수 있습니다!! 그리고 streamlit cloud에서 깃허브 레포지토리 기반으로 쉽게 페이지 배포까지 해줘요!!! 짱이죠~~\n\n캡스톤 화이팅하시길 바랄게요~!! 항상 넘넘 응원해욤🥰\n\n1개의 답글\n레디\n2025년 3월 31일\n\n아니 엄청 쓰껄한걸 하고 있네\n\n희소 표현 기반 검색 알고리즘과 밀집 표현 기반 검색 알고리즘의 차이에 대해 알려주세요 교수님\n\n1개의 답글\n시현한하루\n2025년 4월 6일\n\n제 플젝에서도 RAG를 쓰는데 이해가 안갔었는데 이거 보니까 완전 이해되네요!! 진짜 1타 명강의~~~\n\n1개의 답글\n관련 채용 정보\n뷰노\nAI Research Scientist - DCARS (전문연가능)\n뷰노는 AI 기반 의료기기를 개발하여 의료진의 진단을 돕고, DeepCARS 같은 혁신 제품으로 환자의 예후 개선에 기여하고 있습니다. 딥러닝 기술을 활용한 연구개발을 통해 의료AI 분야의 경력을 쌓을 수 있는 기회를 제공합니다.\n아키스케치\nAI / Backend Engineer (AI / 백엔드 엔지니어)\nArchisketch는 AI 기술과 3D 모델링으로 인테리어 시장을 혁신하는 B2B SaaS 스타트업입니다. 기존 시스템을 넘어서는 고성능 AI 기반 API 개발에 참여하며, 자율적인 근무 환경 속에서 뛰어난 동료들과 함께 성장할 기회를 제공합니다.\n보이스루\n[카카오계열사]Prompt Engineer\n글로벌 번역 인프라를 혁신하는 보이스루에서 AI 기반 번역 서비스 기획 및 개발을 담당할 인재를 찾고 있습니다. LLM 프롬프트 최적화와 NLP 경험을 통해 번역 생태계를 확장하는 기회를 잡아보세요!",
    "tags": [
      "LLM",
      "rag",
      "챗봇"
    ],
    "commentCount": "6"
  },
  {
    "title": "Frontend 첫시작",
    "description": "'프론트앤드'는 말 그대로 풀어보면 '프론트'는 앞이고 '엔드'는 끝이라는 의미로 한마디로 웹페이지의 눈에 보이는 부분을 개발한당이렇게 말하니까 되게 간단해보이긴한다..'백앤드'도 말 그래도 풀어보면 '백'은 뒤이고 '엔드'는 끝이라는 의미로 한마디로 웹페이의 뒷면에 ...",
    "link": "https://velog.io/@seoxeon0728/Frontend-%EC%B2%AB%EC%8B%9C%EC%9E%91",
    "author": "seoxeon0728.log",
    "date": null,
    "comments": "2개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/seoxeon0728/post/9eb32ad7-1c89-4466-8f67-e353983e1ee4/image.jpeg",
    "content": "seoxeon0728.log\n로그인\nseoxeon0728.log\n로그인\nFrontend 첫시작\n서연·6일 전\n팔로우\n5\n프론트엔드(Frontend)란?\n\n'프론트앤드'는 말 그대로 풀어보면 '프론트'는 앞이고 '엔드'는 끝이라는 의미로 한마디로 웹페이지의 눈에 보이는 부분을 개발한당\n이렇게 말하니까 되게 간단해보이긴한다..\n\n그러면 백엔드(Backend)란?\n\n'백앤드'도 말 그래도 풀어보면 '백'은 뒤이고 '엔드'는 끝이라는 의미로 한마디로 웹페이의 뒷면에 보이지 않는 부분을 개발한다!\n사실 필자는 백엔드에 대해선 별다른 큰 지식이 없다..^-^\n\nHTML? 그게 뭔데?\n\nHTML.. 물론 나도 첨엔 이게뭐지? 싶었다ㅎㅎ\nHTML(약자는 나도 뭔지 모른다)은 프론트엔드 즉 웹사이트를 개발하는데 사용되는 언어중 하나라고 생각하면 된다. 텍스트, 이미지, 링크 등과 같은 요소를 만들수 있다.\n\nCSS 이건 또 뭐야..\n\n나도 정확한 개념은 잘 모르겠는데 나는 그냥 웹사이트의 디자인을 할수있는거라 생각하고 있다. HTML에서 추가했던 폰트든, 이미지든, 배경화면이든 여기서 내가 원하는 스타일대로 바꿀수 있다.\n\nJAVA SCRIPT? 이게 젤 중요해!!\n\n나도 처음엔 JS의 정확한 의미를 헷갈려했다.. 근데 그만큼 웹개발에서 중요한 요소중 하나이다. 앞에서 설명했듯이 웹페이지는 3가지 요소로 나누어져있다. HTML은 웹페이지의 가장 큰 뼈대를 제공하고, CSS는 색깔이나 글씨체와 같은 디자인을 할수있다고 했다. 자바스크립트는 '객체지향 스크립트 언어' 로 웹페이지의 동작을 담당한다. 즉 내가 웹페이지 화면을 다른 화면으로 넘기고 싶다! 하면 이때 JS가 필요하다는것이다.\n\n+초반에는 나처럼 HTML과 CSS로만 웹페이지(자기소개 같은거)를 만들수는 있지만 웹페이지 질이 올라갈수록 어쩔수없이 JS를 쓰게 될거다..\n\n+그러므로 C언어 공부를 많이 해놓자! 난 아마도 지금 JS가 제일 어려운것 같다.\n\n그럼 이만 마무리 해보도록 하겠당.. 지금 졸리다.... 사실 이 글을 적은 이유는 그냥 대충이라도 내용정리를 한번 해야될것 같았다. 물론 선배들이 다들 쓰시길래 부러워서? 그런것도 있다^-^\n\n안뇽\n\n서연\nGSM 9기\n팔로우\n2개의 댓글\n댓글 작성\n전준연\n6일 전\n\n짧게라도 공부한 내용 정리해보는 모습 보기 좋네요 👍\n\n1개의 답글\n관련 채용 정보\n현대오토에버\n[FE Engineering] 개발/운영 및 Governance 체계 수립 - Frontend Engineer\n현대오토에버에서 완성차 운영 서비스를 개발하며 프론트엔드 기술 거버넌스를 수립할 기회를 잡아보세요. JavaScript와 React 등의 전문성을 발휘할 수 있는 창의적인 환경이 여러분을 기다리고 있습니다.\n미리디\n[미리캔버스] 프론트엔드 개발자\n미리캔버스는 디자인 생태계를 혁신하는 올인원 플랫폼으로, 1,400만 고객을 위해 프론트엔드 개발을 통해 사용자 경험을 최적화하고 있습니다. React와 Next.js를 활용해 확장 가능한 구조를 설계하며, 빠르게 변화하는 환경에서도 뛰어난 성능을 제공하는 팀의 일원이 되어보세요!\n퀸라이브\n[재택근무] 프론트엔드 개발자 (2년 이상)\n퀸라이브는 데이터 기반의 폐쇄형 라이브커머스를 운영하며, React 및 Next.js로 사용자 경험을 높이는 프론트엔드 개발자를 찾고 있습니다. 자유롭게 아이디어를 공유할 수 있는 문화 속에서 함께 성장하며 새로운 기회를 얻어보세요.",
    "tags": [],
    "commentCount": "2"
  },
  {
    "title": "브라우저 캐싱 속 웹 개발자의 역할에 관하여 (feat. Cache-Control)",
    "description": "오늘은 웹 개발자라면 반드시 알아야 할 브라우저 캐싱에 대해 이야기해보려 한다. 웹사이트를 방문할 때 페이지가 순식간에 로드되거나 혹은 반대로 느릿느릿 로딩되는 사이트에 짜증을 느껴본 적이 있을 것이다. 이 차이의 핵심에는 종종 '캐싱'이라는 기술이 숨겨져있다.브라우저...",
    "link": "https://velog.io/@kyujenius/browser-cache",
    "author": "kyujenius.log",
    "date": "2025년 4월 3일",
    "comments": "2개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/kyujenius/post/5b6ea502-7760-4780-aaa8-829e37f73c4e/image.webp",
    "content": "kyujenius.log\n로그인\nkyujenius.log\n로그인\n브라우저 캐싱 속 웹 개발자의 역할에 관하여 (feat. Cache-Control)\n홍규진·2025년 4월 3일\n팔로우\n11\nCSnetwork\n\n오늘은 웹 개발자라면 반드시 알아야 할 브라우저 캐싱에 대해 이야기해보려 한다. 웹사이트를 방문할 때 페이지가 순식간에 로드되거나 혹은 반대로 느릿느릿 로딩되는 사이트에 짜증을 느껴본 적이 있을 것이다. 이 차이의 핵심에는 종종 '캐싱'이라는 기술이 숨겨져있다.\n\n💡급하신 분들을 위해서 결론 먼저!\n브라우저 캐싱은 브라우저(Chrome, Firefox, Safari, Edge) 마다 이미 자동으로 내재되어있으나, 상황에 맞게 개발자가 설정한 캐싱 규칙이 우선시된다.\n브라우저 캐싱은 웹 리소스를 로컬에 저장해 재사용함으로써 웹 성능을 크게 향상시킨다.\n브라우저 캐싱은 요청-응답-저장-검증의 기본 프로세스를 따른다.\n효과적인 캐싱은 페이지 로딩 시간을 매우 단축시킬 수 있다.\n메모리 캐시, 디스크 캐시, HTTP 캐시 등 다양한 브라우저 캐시 유형이 존재한다.\n결국엔 브라우저 또한 하나의 소프트웨어다보니까, 하드웨어의 자원을 쓰는데 이를 더 효율적으로 쓰는 것의 차이점이다.\n\n\"(👨🏻‍🏫 : 보통은 캐싱에 의해서 성능이 개선이 되는지에 대해서만 알고 있으나, 백엔드가 하는 건지, 프론트가 하는 건지, 브라우저 개발자가 해주는 건지, 어떻게 설정하는지 등에 대해서는 매번 헷갈립니다. 또한 React Query 같은 툴을 쓸 때도 캐싱을 통해 최적화를 쓴다는데, 이 캐싱은 브라우저에서 하는 건지가 매번 걸리게 됩니다. 따라서 이 글을 적게 되었어요! )\"\n\n캐시 기능은 브라우저 내에 이미 내재되어있다.\n\n브라우저는 특별한 캐싱 헤더가 없더라도 자체적인 \"휴리스틱 신선도(heuristic freshness)\" 알고리즘을 사용하여 리소스를 자동으로 캐시합니다. 이 방식은 다음과 같이 작동합니다:\n\n대부분의 브라우저는 Last-Modified 헤더를 기반으로 캐시 기간을 추측합니다\n일반적으로 리소스가 마지막으로 수정된 이후 시간의 약 10%를 캐시 유효 기간으로 설정합니다.\n예를 들어, 리소스가 20시간 전에 마지막으로 수정되었다면, 브라우저는 약 2시간 동안 해당 리소스를 캐시할 수 있습니다.\n\n그러나 이 자동 캐싱에는 몇 가지 중요한 제한 사항이 있습니다:\n\n각 브라우저마다 구현 방식이 일부 다르기 때문에 예측하기 어렵습니다.\n캐싱 동작이 브라우저와 기기에 따라 일관되지 않을 수 있습니다.\n웹사이트의 성능과 사용자 경험을 최적화하기에는 충분하지 않을 수 있습니다\n\n\"(👨🏻‍🏫 : 결론적으로, 브라우저는 기본적인 자동 캐싱을 제공하지만, 최적의 성능과 일관된 사용자 경험을 위해서는 개발자가 명시적인 캐싱 규칙을 설정하는 것이 중요합니다. 오늘은 이를 전반적으로 알아보고 어떻게 설정할 수 있는지를 알아보겠습니다. )\"\n\n1. 브라우저 캐싱이란? 웹 성능 향상을 위한 첫걸음\n\n브라우저 캐싱은 웹 브라우저가 웹사이트의 리소스(HTML, CSS, JavaScript, 이미지 등)를 사용자의 로컬 장치에 임시로 저장하는 프로세스다. 이렇게 저장된 리소스는 사용자가 같은 웹사이트를 다시 방문하거나 같은 페이지 내에서 이동할 때 서버에서 다시 다운로드하지 않고 로컬에서 불러올 수 있다.\n\n캐싱의 기본 개념\n\n캐싱은 컴퓨터 공학에서 자주 사용되는 개념으로, 자주 접근하는 데이터를 빠르게 접근할 수 있는 위치에 임시 저장하는 기술이다. 웹 브라우징에서는 이 개념이 네트워크 요청을 줄이고 페이지 로딩 속도를 향상시키는 데 적용된다.\n\n캐싱이 필요한 이유\n속도 향상: 캐시된 리소스는 네트워크를 통해 다시 다운로드할 필요가 없어 페이지 로딩 시간이 크게 단축된다.\n대역폭 절약: 서버와 클라이언트 간의 데이터 전송량이 감소하여 대역폭 사용이 줄어든다.\n서버 부하 감소: 모든 사용자가 매번 모든 리소스를 요청하지 않으므로 서버의 부하가 줄어든다.\n오프라인 경험: 일부 캐싱 전략을 사용하면 인터넷 연결 없이도 웹사이트를 볼 수 있다. (HTML, CSS, JS) 를 브라우저가 갖고 있다면 뼈대(HTML), 뼈대를 꾸며주는 것(CSS) 작동되게 도와주는 코드(JS) 모두가 있으니 백엔드 단과 소통하여 랜더링하는 페이지가 아니면 이 또한 가능하게 된다.\n캐싱의 간단한 예시 ( 백엔드 개발 영역 )\n\n다음은 HTTP 헤더를 사용한 기본적인 캐싱 설정의 예시다:\n\nCache-Control: max-age=3600\nETag: \"33a64df551425fcc55e4d42a148795d9f25f89d4\"\nLast-Modified: Wed, 03 Apr 2025 04:30:00 GMT\n\n이 헤더는 브라우저에게 해당 리소스를 1시간(3600초) 동안 캐시하도록 지시한다.\n\n출처: MDN Web Docs - HTTP 캐싱\n\n2. 브라우저 캐싱의 작동 원리와 기본 프로세스 이해하기\n\n브라우저 캐싱은 복잡해 보이지만, 기본적으로 몇 가지 핵심 단계를 따른다. 이 프로세스를 이해하면 캐싱을 효과적으로 구현하고 문제를 해결하는 데 큰 도움이 된다.\n\n기본 캐싱 프로세스\n요청 단계: 사용자가 웹페이지를 방문하면 브라우저는 필요한 리소스(HTML, CSS, 이미지 등)를 요청한다.\n응답 수신: 서버는 요청된 리소스와 함께 캐싱 지시사항(HTTP 헤더)을 응답으로 보낸다.\n캐시 저장: 브라우저는 이 리소스를 로컬 캐시에 저장하고, 캐싱 지시사항에 따라 유효 기간을 설정한다.\n캐시 검증: 사용자가 같은 리소스를 다시 요청할 때, 브라우저는 캐시된 버전이 있는지, 그리고 그것이 여전히 유효한지 확인한다.\n캐시 사용 또는 재검증: 캐시가 유효하면 브라우저는 로컬 캐시에서 리소스를 제공한다. 유효하지 않으면 서버에 재검증 요청을 보내거나 새 버전을 다운로드한다.\nHTTP 헤더와 캐싱 제어\n\n브라우저 캐싱은 주로 HTTP 헤더를 통해 제어된다. 가장 중요한 헤더들은 다음과 같다:\n\nCache-Control: 가장 강력하고 유연한 캐싱 제어 메커니즘이다.\n\nCache-Control: max-age=86400, public\n\n이 예시는 리소스를 24시간(86400초) 동안 공개적으로 캐시할 수 있음을 나타낸다.\n\nETag: 리소스의 특정 버전을 식별하는 고유한 문자열이다.\n\nETag: \"33a64df551425fcc55e4d42a148795d9f25f89d4\"\n\nLast-Modified: 리소스가 마지막으로 수정된 날짜와 시간을 나타낸다.\n\nLast-Modified: Wed, 03 Apr 2025 04:30:00 GMT\n\nExpires: 리소스가 만료되는 정확한 시간을 지정한다(Cache-Control이 우선함).\n\nExpires: Thu, 04 Apr 2025 04:30:00 GMT\n\n\"(👨🏻‍🏫 : Cache-Control 헤더는 정말 강력해요! 'no-store'로 설정하면 아예 캐싱을 방지할 수도 있고, 'must-revalidate'로 설정하면 만료된 캐시를 반드시 재검증하도록 할 수도 있답니다. 브라우저가 이를 최우선적으로 확인하는 것이라고 볼 수 있죠. )\"\n\n브라우저의 캐싱 결정 과정\n\n브라우저가 리소스를 요청할 때 따르는 일반적인 결정 과정은 다음과 같다:\n\n캐시에 리소스가 있는가?\n없다면 → 서버에 요청\n있다면 → 다음 단계로\n캐시된 리소스가 여전히 신선한가(max-age 내인가)?\n신선하다면 → 캐시에서 직접 사용\n신선하지 않다면 → 다음 단계로\n재검증이 필요한가?\nETag나 Last-Modified가 있다면 → 조건부 요청으로 서버에 재검증\n없다면 → 서버에 새 요청\n\n이 과정을 코드로 표현하면 다음과 같다:\n\n// 브라우저의 캐싱 결정 과정을 의사 코드로 표현\nfunction fetchResource(url) {\n  const cachedResource = cache.get(url);\n\n  if (!cachedResource) {\n    // 캐시에 없음 - 서버에서 가져오기\n    return fetchFromServer(url);\n  }\n\n  if (isFresh(cachedResource)) {\n    // 캐시가 신선함 - 캐시에서 직접 사용\n    return cachedResource;\n  }\n\n  if (hasValidator(cachedResource)) {\n    // 검증자가 있음 - 조건부 요청으로 재검증\n    return revalidateWithServer(url, cachedResource);\n  }\n\n  // 그 외의 경우 - 새로 요청\n  return fetchFromServer(url);\n}\n\n출처: Google Developers - HTTP 캐싱\n\n1. 초기 방문 (캐시 없음)\n\n2. 캐시 있는 재방문 (유효한 캐시)\n\n3. 캐시 만료 후 재방문 (데이터 변경은 없음)\n\n4. 캐시 만료 후 재방문 (데이터 변경 있음)\n\n3. 캐시가 웹 페이지 로딩 속도에 미치는 영향과 중요성\n\n캐싱은 웹 성능 최적화의 핵심 요소 중 하나다. 적절한 캐싱 전략은 웹사이트의 로딩 속도를 극적으로 향상시킬 수 있으며, 이는 사용자 경험과 비즈니스 성과에 직접적인 영향을 미친다.\n\n로딩 속도 향상의 수치적 증거\n\n캐싱이 웹 페이지 로딩 속도에 미치는 영향은 실제 수치로 확인할 수 있다:\n\n초기 로딩 vs 재방문: 캐싱이 제대로 구현된 웹사이트는 재방문 시 초기 로딩 대비 50-80% 더 빠르게 로드될 수 있다.\n네트워크 요청 감소: 효과적인 캐싱은 HTTP 요청 수를 최대 90%까지 줄일 수 있다.\n대역폭 사용량: 캐싱은 사용자와 서버 간의 데이터 전송량을 크게 줄여, 모바일 사용자의 데이터 사용량을 절약한다.\n\n다음 차트는 캐싱 전후의 페이지 로딩 시간의 상대적인 비교를 나타냈다:\n\n로딩 시간(초)\n  │\n  │    ████\n  │    ████\n  │    ████        ████\n  │    ████        ████\n  │    ████        ████        ████\n  │    ████        ████        ████\n  │____████________████________████____\n      초기 방문     캐시 없는     캐시 있는\n                   재방문       재방문\n\n초기 방문 vs 캐시 없는 재방문\n\n초기 방문은 사용자가 웹사이트를 처음 방문할 때 발생하는 상황으로, 브라우저에 해당 웹사이트의 리소스가 전혀 저장되어 있지 않은 상태입니다. 이때 브라우저는 모든 리소스(HTML, CSS, JavaScript, 이미지 등)를 서버에서 새롭게 다운로드해야 한다. 그러나, 캐시 없는 재방문과, 초기 방문은 같은 상황이 아닌가? → 아니다.\n\n캐시 없는 재방문은 사용자가 이전에 방문했던 웹사이트를 다시 방문하지만, 다음과 같은 이유로 캐시를 사용할 수 없는 상황을 의미합니다:\n\n캐시 만료: 캐시된 리소스의 유효 기간(TTL)이 만료되었을 때\n캐시 무효화: 서버에서 리소스가 변경되어 캐시가 유효하지 않을 때\n캐시 정책: 'no-store'와 같은 캐시 제어 지시자가 설정되어 있어 캐싱이 금지된 경우\n\n이 경우, 브라우저는 서버에 조건부 요청(Conditional request)을 보내 캐시 유효성을 검증하는 과정을 거칩니다. 만약 서버에서 리소스가 변경되었다고 판단하면, 브라우저는 새로운 리소스를 다운로드해야 합니다.\n\n비즈니스 영향과 사용자 경험\n\n캐싱이 단순히 기술적인 최적화를 넘어 비즈니스에 미치는 영향은 상당하다:\n\n이탈률 감소: 구글에 따르면, 페이지 로딩 시간이 1초에서 3초로 늘어나면 이탈률이 32% 증가한다.\n전환율 향상: 아마존은 페이지 로딩 시간이 100ms 감소할 때마다 매출이 1% 증가한다는 사실을 발견했다.\nSEO 개선: 구글은 페이지 속도를 검색 순위 결정 요소로 사용하므로, 캐싱을 통한 속도 향상은 검색 엔진 순위에 긍정적인 영향을 미친다.\n사용자 만족도: 빠른 웹사이트는 사용자 만족도와 신뢰도를 높인다.\n실제 사례 연구\n\n실제 기업들의 캐싱 최적화 사례를 살펴보자:\n\nPinterest: 서비스 워커와 캐싱 전략을 도입한 후 페이지 로드 시간을 40% 단축하고, 사용자 참여도를 60% 증가시켰다.\nFinancial Times: 적절한 캐싱 정책을 구현하여 반복 방문자의 페이지 로드 시간을 75% 단축했다.\nWalmart: 페이지 로드 시간이 1초 개선될 때마다 전환율이 2% 증가하는 것을 확인했다.\n\n\"(👨🏻‍🏫 : 제 경험상, 이미지가 많은 웹사이트에서 캐싱을 적용했을 때 가장 극적인 성능 향상을 볼 수 있었어요. 특히 로고나 아이콘 같은 반복적으로 사용되는 이미지는 꼭 캐싱하세요! 핀터레스트도 월마트도 사실 대다수가 이미지로 구성되어있는 페이지다보니까, 이를 개선하는 것이 중요했을 겁니다. )\"\n\nDevTool을 통해 캐시 정도 측정하기\n\n자신의 웹사이트에서 캐싱 효과를 측정하는 방법은 다음과 같다:\n\nChrome DevTools: Network 탭에서 'Size' 열을 확인하면 '(from disk cache)' 또는 '(from memory cache)'라는 표시를 볼 수 있다.\nLighthouse: 구글의 Lighthouse 도구를 사용하여 'Serve static assets with efficient cache policy' 항목을 확인한다.\nWebPageTest: 첫 번째 방문과 반복 방문의 성능 차이를 비교할 수 있다.\n// 페이지 로딩 성능 측정 예시 코드\nwindow.addEventListener(\"load\", function () {\n  // 성능 측정 데이터 수집\n  const perfData = window.performance.timing;\n  const pageLoadTime = perfData.loadEventEnd - perfData.navigationStart;\n\n  console.log(`페이지 로딩 시간: ${pageLoadTime}ms`);\n\n  // 캐시 상태 확인\n  const entries = performance.getEntriesByType(\"resource\");\n  const cachedResources = entries.filter((entry) => entry.transferSize === 0);\n\n  console.log(\n    `총 리소스: ${entries.length}, 캐시된 리소스: ${cachedResources.length}`\n  );\n});\n\n출처: Web.dev - Measure performance with the RAIL model\n\n4. 브라우저 캐시의 종류와 각각의 특징 비교\n\n브라우저 캐싱은 단일 메커니즘이 아니라 여러 유형의 캐시가 함께 작동하는 복합적인 시스템이다. 각 캐시 유형은 고유한 특성과 용도를 가지고 있으며, 이들을 이해하면 더 효과적인 캐싱 전략을 수립할 수 있다.\n\n메모리 캐시 (Memory Cache)\n\n메모리 캐시는 RAM에 저장되는 임시 캐시다. 가장 빠른 접근 속도를 제공하지만, 브라우저가 닫히면 내용이 사라진다.\n\n특징:\n\n속도: 매우 빠름 (RAM 접근 속도)\n지속성: 브라우저 세션 동안만 유지\n용량: 제한적 (시스템 메모리에 의존)\n주요 용도: 현재 탭에서 자주 사용되는 리소스 (스크립트, 스타일시트, 작은 이미지)\n디스크 캐시 (Disk Cache)\n\n디스크 캐시는 하드 드라이브나 SSD에 저장되는 보다 영구적인 캐시이다. 메모리 캐시보다 느리지만 브라우저를 다시 시작해도 데이터가 유지된다.\n\n특징:\n\n속도: 중간 (디스크 접근 속도)\n지속성: 브라우저를 닫은 후에도 유지\n용량: 상대적으로 큼 (일반적으로 수백 MB)\n주요 용도: 큰 이미지, 비디오, 오디오 파일, 자주 방문하는 웹사이트의 리소스\n\n\"(👨🏻‍🏫 : 위 두가지 캐시는 사실 주로 브라우저 개발자가 결정하는 메커니즘입니다. 각 브라우저마다의 성능이 다른 것이 위의 두가지의 설정 차이 때문입니다. 브라우저는 자체적인 알고리즘을 통해 어떤 리소스를 메모리에 캐시할지, 어떤 리소스를 디스크에 캐시할지 결정합니다. 일반 개발자 ( Frontend, Backend 개발자 )는 오직 public, private, max-age 등의 지시어를 사용하여 캐싱 방식을 제안할 수 있지, 메모리 vs 디스크 캐시의 선택은 직접 제어할 수 없습니다.)\"\n\nHTTP 캐시 (HTTP Cache)\n\nHTTP 캐시는 HTTP 헤더를 기반으로 작동하는 캐시 메커니즘으로, 서버가 명시적으로 캐싱 규칙을 지정할 수 있다.\n\n특징:\n\n제어: 서버 측에서 HTTP 헤더를 통해 제어\n유연성: 다양한 캐싱 정책 설정 가능\n검증: ETag, Last-Modified 등을 통한 리소스 검증 지원\n주요 용도: 모든 종류의 웹 리소스에 적용 가능\n\n\"(👨🏻‍🏫 : HTTP 캐시는 개발자가 가장 많이 제어할 수 있는 캐시 유형이에요. Cache-Control 헤더만 잘 설정해도 성능이 확 좋아진답니다!)\"\n\n서비스 워커 캐시 (Service Worker Cache)\n\n서비스 워커 캐시는 프로그래밍 방식으로 완전히 제어할 수 있는 캐시로, 오프라인 경험을 제공하는 데 중요하다.\n\n특징:\n\n제어: JavaScript를 통한 프로그래밍 방식 제어\n오프라인 지원: 네트워크 연결 없이도 웹 앱 사용 가능\n유연성: 사용자 정의 캐싱 전략 구현 가능\n주요 용도: PWA(Progressive Web Apps), 오프라인 기능이 필요한 웹 앱\n// 서비스 워커를 사용한 캐싱 예시\nself.addEventListener(\"install\", function (event) {\n  event.waitUntil(\n    caches.open(\"my-cache-v1\").then(function (cache) {\n      return cache.addAll([\n        \"/\",\n        \"/styles/main.css\",\n        \"/scripts/main.js\",\n        \"/images/logo.png\",\n      ]);\n    })\n  );\n});\n\nself.addEventListener(\"fetch\", function (event) {\n  event.respondWith(\n    caches.match(event.request).then(function (response) {\n      return response || fetch(event.request);\n    })\n  );\n});\n\n출처: MDN Web Docs - 서비스 워커 API\n\n브라우저별 캐시 구현 차이\n\n각 브라우저는 캐시를 약간 다르게 구현하므로, 이러한 차이점을 이해하는 것이 중요하다:\n\n브라우저\t메모리 캐시 크기\t디스크 캐시 기본 크기\t특이사항\nChrome\t동적 할당\t~80% 사용 가능 디스크 공간\t각 프로필별 독립 캐시\nFirefox\t동적 할당\t기본 1GB, 조정 가능\t강력한 개인정보 보호 모드\nSafari\t제한적\t시스템에 의해 관리\tITP(Intelligent Tracking Prevention) 적용\nEdge\t동적 할당\t기본 최대 10GB\tChromium 기반으로 Chrome과 유사\n최적의 캐시 전략 선택하기\n\n웹사이트의 특성에 따라 다양한 리소스에 적합한 캐시 전략이 다르다:\n\n자주 변경되지 않는 정적 자산 (로고, 아이콘, 폰트):\n장기 캐싱 (Cache-Control: max-age=31536000)\n버전 관리 또는 지문(fingerprinting) 적용\n자주 업데이트되는 CSS/JS:\n중간 기간 캐싱 + 버전 관리\n파일명에 해시 포함 (예: main.a2b3c4.js)\nAPI 응답 데이터:\n짧은 기간 캐싱 또는 조건부 요청\nETag 활용\n사용자별 콘텐츠:\nprivate 캐시 지시문 사용\n필요한 경우 no-store 적용\n\n\"(👨🏻‍🏫 : 글을 읽다보면 저는 이 부분에서 갑자기 궁금한 점이 생겼는데 여러분도 한 번 생각해보세요! 브라우저에는 디스크도, 메모리도 없는데 왜 브라우저 캐시라는 이름이 붙었을까요? 결론부터 말씀을 드리자면 브라우저 또한 하나의 소프트웨어이고, 즉 하드웨어에 의해서 돌아갑니다. 그 결과 하드웨어의 자원을 할당받아 사용하는데, 브라우저는 운영체제로부터 할당받은 메모리와 디스크 공간을 사용하여 다양한 캐시를 구현합니다. 브라우저 캐시라는 이름이 붙는 이유는 이러한 캐싱 메커니즘이 웹 브라우저 소프트웨어에 의해 관리되고 구현되기 때문입니다.)\"\n\n브라우저와 캐시의 관계 명확히 하기\n브라우저는 소프트웨어이다: 웹 브라우저(Chrome, Firefox, Safari 등)는 컴퓨터에서 실행되는 소프트웨어 애플리케이션이다. 이 소프트웨어는 컴퓨터의 하드웨어 자원(메모리, 디스크 등)을 활용한다.\n브라우저가 자원을 관리한다: 브라우저는 운영체제로부터 할당받은 메모리와 디스크 공간을 사용하여 다양한 캐시를 구현한다.\n메모리 캐시: 브라우저는 운영체제로부터 할당받은 RAM의 일부를 사용하여 메모리 캐시를 구현한다.\n디스크 캐시: 브라우저는 하드 드라이브나 SSD의 특정 폴더/디렉토리를 사용하여 디스크 캐시를 구현한다.\n브라우저 자체 기능: HTTP 캐시와 서비스 워커 캐시는 브라우저가 제공하는 기능으로, 브라우저 소프트웨어의 일부이다.\n브라우저 캐시의 실제 저장 위치\n\n브라우저 캐시의 실제 저장 위치는 다음과 같습니다:\n\n메모리 캐시: 컴퓨터의 RAM에 저장되지만, 브라우저 프로세스에 할당된 메모리 공간 내에서 관리됩니다.\n디스크 캐시: 운영체제의 파일 시스템에 저장됩니다. 예를 들어:\nChrome (Windows):\nC:\\\\Users$$사용자명]\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\\\\Default\\\\Cache\nFirefox (Windows): C:\\\\Users$$사용자명]\\\\AppData\\\\Local\\\\Mozilla\\\\Firefox\\\\Profiles$$프로필]\\\\cache2\nChrome (Mac): ~/Library/Caches/Google/Chrome\nSafari (Mac): ~/Library/Caches/com.apple.Safari\n\n\"(👨🏻‍🏫 : 저는 맥 유저라 한 번 확인해봤더니\n\n\n다음과 같이 나오네요 조금 볼품없지만 캐시가 있따는 것을 실제로 확인하니 신기합니다)\"\n\nHTTP 캐시: 이는 개념적인 메커니즘으로, 실제 저장은 메모리 캐시나 디스크 캐시를 통해 이루어집니다.\n서비스 워커 캐시: Cache API를 통해 구현되며, 일반적으로 브라우저의 디스크 캐시와는 별도의 저장소를 사용합니다.\n\n따라서 \"브라우저 캐시\"라는 이름은 이러한 캐싱 메커니즘이 웹 브라우저 소프트웨어에 의해 구현되고 관리된다는 사실에서 비롯된 것입니다. 브라우저는 운영체제가 제공하는 하드웨어 자원(메모리, 디스크)을 활용하여 이러한 캐시를 구현합니다.\n\n\"(👨🏻‍🏫 : 어떻게 좀 이해가 됐나요? 글을 세부적으로 여러개로 나눌까 하다가 이해를 위해서 한 번의 글에 담으려고 노력했습니다 ㅎㅎ 좀 길어도 재밌게 읽었기를 바랍니다!)\"\n\n🙇🏻 글 내에 틀린 점, 오탈자, 비판, 공감 등 모두 적어주셔도 됩니다. 감사합니다..! 🙇🏻\n\n홍규진\n읽는 사람이 가장 이해하기 쉽게끔 적으려 노력합니다. 그 과정에서 스스로가 완전한 이해를 할 수 있다고 생각합니다. 그렇게 Taker 보다는 Giver이 되려 노력합니다. \n팔로우\n이전 포스트\nJS로 알아보는 동기처리와 비동기 처리의 차이점\n다음 포스트\n순수함수의 기본 개념\n2개의 댓글\n댓글 작성\nmunjji\n2025년 4월 3일\n\n글이 술술 읽혀요\n\n1개의 답글\n관련 채용 정보\n젭(zep)\n프론트엔드 개발자\nZEP은 교육과 퀴즈 플랫폼을 통해 공교육 혁신에 나선 에듀테크 스타트업으로, React 기반의 신규 기능 개발과 팀워크 강화에 중점을 둡니다. 기술 도전과 비즈니스 임팩트를 함께 이루는 환경에서 성장할 개발자를 기다립니다.\n씨제이올리브영(CJ올리브영)\n프론트엔드 개발자 (커머스서비스)\n올리브영은 헬스&뷰티 스토어로 옴니채널 혁신을 이끄는 글로벌 라이프스타일 플랫폼입니다. JavaScript와 React를 활용한 프론트엔드 개발 프로젝트로 고객 경험을 개선하며, 독보적인 오프라인 비즈니스와 온라인 결합한 플랫폼을 함께 만들어갈 인재를 기다립니다.\n아토머스(마인드카페)\nReact 프론트엔드 개발자\n아토머스는 정신건강 서비스 대중화를 목표로 최초의 멘탈 헬스케어 플랫폼 '마인드카페'를 운영하며, React를 활용한 웹 개발 업무를 맡게 됩니다. 팀원들과의 협업 및 혁신적인 문화 속에서 소중한 가치를 만드는 경험을 함께하세요.",
    "tags": [
      "CS",
      "network"
    ],
    "commentCount": "2"
  },
  {
    "title": "JS로 알아보는 동기처리와 비동기 처리의 차이점",
    "description": "프로그래밍을 처음 배울 때 가장 헷갈리는 개념 중 하나가 바로 동기와 비동기다. 이 요청이 커피숍에서 주문을 하고 기다리는 방식을 생각해보자. 주문 후 카운터에서 커피가 나올 때까지 꼼짝 않고 기다리는가, 아니면 진동벨을 받고 자리에 앉아 다른 일을 하는가? 이것이 바...",
    "link": "https://velog.io/@kyujenius/sync-async",
    "author": "kyujenius.log",
    "date": "2025년 4월 2일",
    "comments": "0개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/kyujenius/post/d5f81138-cef2-4b5f-b4ac-8e8f6f1894f7/image.png",
    "content": "kyujenius.log\n로그인\nkyujenius.log\n로그인\nJS로 알아보는 동기처리와 비동기 처리의 차이점\n홍규진·2025년 4월 2일\n팔로우\n11\nCSJavaScript\n비동기처리\n목록 보기\n1/1\n\n프로그래밍을 처음 배울 때 가장 헷갈리는 개념 중 하나가 바로 동기와 비동기다. 이 요청이 커피숍에서 주문을 하고 기다리는 방식을 생각해보자. 주문 후 카운터에서 커피가 나올 때까지 꼼짝 않고 기다리는가, 아니면 진동벨을 받고 자리에 앉아 다른 일을 하는가? 이것이 바로 동기와 비동기의 차이를 가장 쉽게 설명하는 예시다.\n\n(👨🏻‍🏫 : 하나의 주문이 들어오면 하나를 만드는 동안, 아무것도 안 하는 식당이 있나요? 있긴 하죠. 오마카세… 하지만 비용이 정말 많이 들죠? 이게 바로 동기식 식당 운영이랍니다!)\n\n💡급하신 분들을 위해서 결론 먼저!\n동기 처리는 작업을 순차적으로 실행하며, 하나의 작업이 완료될 때까지 다음 작업은 대기한다.\n비동기 처리는 작업의 완료를 기다리지 않고 다음 작업을 실행할 수 있어 효율적이다.\n동기는 설계가 간단하고 직관적이지만 블로킹으로 인한 성능 저하가 발생할 수 있다.\n비동기는 자원을 효율적으로 사용할 수 있지만 코드가 복잡해질 수 있다.\n상황에 맞게 적절한 방식을 선택하는 것이 중요하다.\n1. 동기(Synchronous)와 비동기(Asynchronous)의 기본 개념\n동기(Synchronous) 처리란?\n\n동기 처리는 말 그대로 '동시에 일어난다'는 의미를 가진다. 요청과 그 결과가 동시에 일어난다는 약속이다. 작업을 요청하면 그 작업이 완료될 때까지 기다린 후에 다음 작업을 수행한다. 이는 마치 은행 창구에서 한 명의 고객이 업무를 마쳐야 다음 고객이 업무를 볼 수 있는 것과 같다. 은행은 효율보다, 하나의 고객의 경험을 위해서 동기식 처리를 택한 것이다.\n\n비동기(Asynchronous) 처리란?\n\n비동기 처리는 '동시에 일어나지 않는다'는 의미를 가진다. 요청과 결과가 동시에 일어나지 않을 거라는 약속이다. 하나의 요청에 대한 응답을 즉시 처리하지 않아도, 그 대기 시간 동안 다른 요청을 처리할 수 있는 방식이다. 카페에서 커피를 주문하고 진동벨을 받아 자리에 앉아 기다리는 것과 유사하다.\n\n(👨🏻‍🏫 : 비동기는 마치 멀티태스킹 같은 거랍니다. 안성재 셰프는 요리할 때 물을 끓이면서 야채를 썰고, 그러면서 또 소스를 만드는 식으로 일을 처리하는데, 이게 바로 비동기식 작업의 좋은 예시죠!)\n\n2. 동기와 비동기의 작동 방식 차이\n동기 방식의 작동 원리\n\n동기 방식에서는 작업이 순차적으로 실행된다. 현재 실행 중인 태스크가 있다면 다음 태스크는 현재 태스크가 완료될 때까지 기다려야 한다. 이는 블로킹(Blocking) 방식으로도 불리며, 한 작업이 다른 작업을 차단하는 특성을 가진다.\n\n예를 들어, 계좌 이체와 같은 작업은 동기 방식으로 처리되어야 한다. A의 계좌에서 B의 계좌로 송금할 때, 두 계좌의 잔액 변경이 동시에 이루어져야 하기 때문이다.\n\n// 동기 방식의 파일 읽기 예제\n// 파일 읽기 -> content 콘솔에 찍기 -> 파일 읽기 완료 콘솔에 찍기\nfunction readFileSynchronously(filename) {\n  const content = fs.readFileSync(filename, 'utf-8');\n  console.log(content);\n  console.log('파일 읽기 완료');\n}\n\n\n출처: Node.js 공식 문서 https://nodejs.org/api/fs.html\n\n비동기 방식의 작동 원리\n\n비동기 방식에서는 현재 실행 중인 태스크가 완료되지 않아도 다음 태스크를 실행할 수 있다. 이는 논블로킹(Non-blocking) 방식으로, 작업이 완료될 때까지 기다리지 않고 다른 작업을 수행할 수 있다.\n\n시험 시간을 예로 들면, 학생이 시험지를 풀고 선생님에게 제출한 후, 선생님이 채점하는 동안 학생은 다른 과목을 공부하거나 휴식을 취할 수 있다. 이것이 바로 비동기 방식의 예시다.\n\n// 비동기 방식의 파일 읽기 예제\n// 파일 읽기 요청 완료 -> 파일 읽기 -> 성공시 콘솔 찍기 -> 실패시 err throw 하기\nfunction readFileAsynchronously(filename) {\n  fs.readFile(filename, 'utf-8', (err, data) => {\n    if (err) throw err;\n    console.log(data);\n  });\n  console.log('파일 읽기 요청 완료');\n}\n\n(👨🏻‍🏫 : 비동기 코드를 처음 접하면 실행 순서가 헷갈릴 수 있어요. 위 예제에서는 '파일 읽기 요청 완료'가 먼저 출력되고, 그 다음에 파일 내용이 출력된답니다. 신기하죠?)\n\n3. 동기와 비동기의 장단점 비교\n동기 방식의 장단점\n\n장점:\n\n설계가 매우 간단하고 직관적이다.\n작업의 순서가 보장되어 예측 가능하다.\n디버깅이 상대적으로 쉽다.\n\n단점:\n\n결과가 주어질 때까지 아무것도 못하고 대기해야 한다.\nI/O 작업과 같이 시간이 오래 걸리는 작업에서 성능 저하가 발생할 수 있다.\n비동기 방식의 장단점\n\n장점:\n\n결과가 주어지는데 시간이 걸리더라도 그 시간 동안 다른 작업을 할 수 있어 자원을 효율적으로 사용할 수 있다.\nI/O 작업이나 네트워크 요청과 같은 시간이 오래 걸리는 작업에 적합하다.\n사용자 인터페이스의 반응성을 유지할 수 있다.\n\n단점:\n\n동기 방식보다 설계가 복잡하다.\n작업의 실행 순서가 보장되지 않아 예측하기 어려울 수 있다.\n디버깅이 어렵고 오류 처리가 복잡할 수 있다.\n\n(👨🏻‍🏫 : 저는 처음에 비동기 프로그래밍을 배울 때 콜백 지옥에 빠졌었답니다. 프로미스와 async/await를 알기 전까지는 정말 고생했죠. 비동기의 장점이 많지만, 그만큼 잘 다루기 위한 학습 곡선이 있다는 점을 기억하세요!)\n\n4. 동기와 비동기의 적절한 사용 상황\n동기 처리가 적합한 경우\nCPU 집약적인 작업: 복잡한 계산이나 데이터 처리와 같이 CPU를 많이 사용하는 작업.\n순서가 중요한 작업: 계좌 이체와 같이 작업의 순서가 중요한 경우.\n간단한 애플리케이션: 복잡성이 낮은 소규모 애플리케이션이나 스크립트.\n데이터 일관성이 중요한 경우: 데이터베이스 트랜잭션과 같이 일관성이 중요한 작업.\n비동기 처리가 적합한 경우\nI/O 작업: 파일 읽기/쓰기, 네트워크 요청, 데이터베이스 쿼리와 같은 I/O 작업.\n사용자 인터페이스: 사용자 경험을 향상시키기 위해 UI의 반응성을 유지해야 하는 경우.\n독립적인 여러 작업: 서로 의존성이 없는 여러 작업을 동시에 처리해야 하는 경우.\n대규모 서버 애플리케이션: 많은 요청을 동시에 처리해야 하는 웹 서버와 같은 애플리케이션.\n// 비동기 처리의 좋은 예: 웹 API 요청\nfunction fetchUserData() {\n  console.log('데이터 요청 시작');\n  fetch('<https://api.example.com/users>')\n    .then(response => response.json())\n    .then(data => {\n      console.log('사용자 데이터:', data);\n    })\n    .catch(error => {\n      console.error('에러 발생:', error);\n    });\n  console.log('다른 작업 계속 진행');\n}\n\n\n출처: MDN Web Docs https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API\n\n(👨🏻‍🏫 : 실제 프로젝트에서는 동기와 비동기를 적절히 섞어서 사용하는 경우가 많답니다. 예를 들어, 서버에서는 비동기로 여러 요청을 처리하지만, 각 요청 내에서는 동기적으로 작업을 처리하는 식이죠!)\n\n5. 실제 예제로 이해하는 동기와 비동기\n일상생활에서의 예시 (동기식)\n\n동기 방식: 은행 창구에서 업무를 보는 상황. 한 고객의 업무가 끝날 때까지 다른 고객은 기다려야 한다.\n\n프로그래밍에서의 예시\n\n동기 방식 코드 예제:\n\n// 동기 방식의 계산 예제\nfunction calculateSum(n) {\n  let sum = 0;\n  for (let i = 1; i  {\n  console.log(`은행 손님 대접 ${i} 번째 손님`);\n\t}, 3000);\nconsole.log('다음 작업 계속 진행'); // 타이머가 끝나기 전에 실행됨\n\n\n출처: MDN Web Docs https://developer.mozilla.org/en-US/docs/Web/API/setTimeout\n\n일상생황에서의 예시(비동기식)\n\n비동기 방식: 카페에서 주문 후 진동벨을 받고 자리에 앉아 기다리는 상황. 주문 후 커피가 나오기를 기다리는 동안 다른 일을 할 수 있다.\n\n프로그래밍에서의 예시\n\n비동기 방식 코드 예제:\n\n// 커피숍 비동기 작업 시뮬레이션\nconsole.log(\"손님: 커피 한 잔 주세요.\");\n\n// 커피 준비 비동기 작업\nconst prepareCoffee = new Promise((resolve) => {\n  console.log(\"바리스타1: 커피 준비 시작합니다.\");\n  setTimeout(() => {\n    resolve(\"커피\");\n  }, 3000);\n});\n\n// 케이크 준비 비동기 작업\nconst prepareCake = new Promise((resolve) => {\n  console.log(\"바리스타1: 케이크도 준비할게요.\");\n  setTimeout(() => {\n    resolve(\"케이크\");\n  }, 2000);\n});\n\nconsole.log(\"손님: (자리에 앉아 Velog 확인 중)\");\n\n// 완료되는 즉시 비동기 작업 처리\nprepareCoffee.then((coffee) => {\n  console.log(`바리스타1: ${coffee} 나왔습니다.`);\n});\n\n// 완료되는 즉시 비동기 작업 처리\nprepareCake.then((cake) => {\n  console.log(`바리스타2: ${cake} 나왔습니다.`);\n});\n\n// 비동기들이 다 처리된 후처리\nPromise.all([prepareCoffee, prepareCake]).then(() => {\n  console.log(\"손님: 감사합니다!\");\n});\n\n\n(👨🏻‍🏫 : JavaScript는 싱글 스레드 언어이지만, 비동기 처리를 통해 마치 멀티 스레드처럼 동작할 수 있답니다. 스레드가 작업의 개수를 나타내는데, 어떻게 이게 가능할까요? 이벤트 루프라는 개념이 이를 가능하게 하는데, 다음엔 이 주제로 글을 써보겠습니다!)\n\n🙇🏻 글 내에 틀린 점, 오탈자, 비판, 공감 등 모두 적어주셔도 됩니다. 감사합니다..! 🙇🏻\n\n홍규진\n읽는 사람이 가장 이해하기 쉽게끔 적으려 노력합니다. 그 과정에서 스스로가 완전한 이해를 할 수 있다고 생각합니다. 그렇게 Taker 보다는 Giver이 되려 노력합니다. \n팔로우\n0개의 댓글\n댓글 작성\n관련 채용 정보\n백패커\n[아이디어스/텀블벅/텐바이텐] 클라우드 엔지니어 (1년 이상)\n아이디어스와 텀블벅이 함께하는 백패커에서 클라우드 엔지니어로의 기회를 잡아보세요. AWS와 Kubernetes를 활용한 효율적인 개발 환경에서 함께 성장하며 창작 생태계를 혁신할 수 있습니다.\n어스얼라이언스\n백엔드 개발자 (신입~2년)\n금융을 콘텐츠로 혁신하는 어스얼라이언스에서 백엔드 개발자를 모집합니다. NestJS 기반의 개발 경험이 있다면, 성장과 함께 금융 콘텐츠 혁신의 주역이 될 수 있는 기회를 놓치지 마세요!\n힐링페이퍼(강남언니)\n서버 (백엔드) 개발자 (B2B SaaS)\n미용 의료 병원의 혁신적인 운영 솔루션을 만드는 강남언니에서 서버 개발자를 찾습니다. CI/CD 및 도메인 주도 설계를 활용하여 고객 가치를 극대화하는 재미있는 팀 환경에서 성장할 기회를 제공합니다.",
    "tags": [
      "CS",
      "JavaScript"
    ],
    "commentCount": "0"
  },
  {
    "title": "TypeScript: 개발 속도를 높이는 타입의 힘",
    "description": "TypeScript를 실무에서 많이 사용하는 것은 익히 알고 있고 중요한 것도 아는데, 정작 왜 중요하지? 라는 생각은 언제나 가지고 있었다. 우연히 TypeScript에 대해서 깊이 공부할 수 있는 기회가 생겨서 TypeScript의 정의, 장점, 타입 시스템, 유틸...",
    "link": "https://velog.io/@munjji/TypeScript-%EA%B0%9C%EB%B0%9C-%EC%86%8D%EB%8F%84%EB%A5%BC-%EB%86%92%EC%9D%B4%EB%8A%94-%ED%83%80%EC%9E%85%EC%9D%98-%ED%9E%98",
    "author": "munjji.log",
    "date": "2025년 4월 4일",
    "comments": "0개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/munjji/post/04206d1a-52af-40be-a0de-650d1847ab3e/image.png",
    "content": "munjji.log\n로그인\nmunjji.log\n로그인\nTypeScript: 개발 속도를 높이는 타입의 힘\nmunjji·2025년 4월 4일\n팔로우\n10\n프론트엔드\n목록 보기\n1/1\n\nTypeScript를 실무에서 많이 사용하는 것은 익히 알고 있고 중요한 것도 아는데, 정작 왜 중요하지? 라는 생각은 언제나 가지고 있었다. 우연히 TypeScript에 대해서 깊이 공부할 수 있는 기회가 생겨서 TypeScript의 정의, 장점, 타입 시스템, 유틸리티 타입까지 정의해보고자 한다!\n\nTypeScript란?\n\nJavaScript에 타입 시스템을 추가한 정적 타입 언어이다.\n\nMicrosoft가 만들었고, 지금은 거의 표준처럼 쓰이고 있다. JavaScript의 Superset이기 때문에 JS 코드 그대로 동작하면서, 아래와 같이 변수에 타입을 지정할 수 있다.\n\nlet user:String = \"munjji\";\n\nJavaScript가 가지고 있는 문제점을 통해서 TypeScript가 만들어진 배경을 이야기 해보자면,\n\nJavaScript의 문제점 👿\n\nJavaScript의 가장 큰 특징은 동적 타이핑이라는 점이다.\n코드를 실행하기 전까지는 타입을 알 수도 없고, 에러가 런타임에야 터진다는 문제가 있다.\n아래와 같이 예를 들어 greet이라는 함수를 정의 했는데 실제로는 nickname이라는 프로퍼티에 값을 주게 되면 user는 name이 없으니까 런타임 에러가 발생한다.\n\n1. JavaScript는 실행되기 전까지는 타입을 알 수 없다.\n2. 오류가 코드를 작성하는 중에는 보이지 않고 실행 후에야 드러난다.\n3. 특히, API 응답이나 props가 잘못된 경우에는 console을 통해 버그를 뒤늦게 발견한다.\n\n이런 문제점만 해도 프론트엔드 개발자들이 언제나 느끼고 있던 고충일 것이다..\n\n하 지 만!\n\nTypeScript에서는 위의 greet 함수를 아래와 같이 정의하고 작성한다.\n\n\n이렇게 작성한 TypeScript는 코드가 실행되기 전에 코드를 저장하거나 컴파일 할 때\n에러 표시를 발생시켜준다. 저장만 해도 name이 없다는 것을 에디터가 알려주게 된다!\n\n\nTypeScript의 장점 😇\n1. TypeScript는 컴파일 타임에 타입을 체크하는 `정적 타입 검사`이다.\n2. 코드 작성 단계에서 이미 오류를 알려주니까 빠르게 수정이 가능하다.\n3. IDE 자동 완성 + 타입 추론 덕분에 실수할 확률이 낮아진다.\n\n\nTypeScript가 정적 타입 검사를 수행하면서 위와 같은 이점을 얻을 수 있으며 이런 장점이 JavaScript가 가지는 문제점을 대부분 해결해준다.\n\n실행 전에 에러를 미리 막아주니까, 디버깅 시간도 줄고 안정성은 올라가겠죠오!\n\nTS 개발 속도 향상의 근거\n자동 완성 기능\n-> 문서를 찾아볼 일이 줄어서 개발 시간이 단축된다.\n빠른 오류 감지\n-> 디버깅 시간이 준다.\n리팩토링 보장\n-> 타입 기반 리팩토링 가능하여 안전하고 빠른 변경이 가능하다.\n문서화된 코드\n-> 타입이 곧 문서가 될테니 협업도 쉬워진다.\n타입 시스템\n\n이 예시를 보게 되면 Person이라는 인터페이스를 만들고 프로퍼티로 name을 String 타입으로 선언했습니다.\n\n그리고 user 상수에 name과 age 값을 넣어준 것을 Person을 타입으로 하고 있는 person 상수에 저장을 해주는 상황인데, 이렇게 하면 에러가 날까여?\n\n....\n\n정답은 \"에러가 나지 않는다!\" 입니다..!\n\n\"이건 분명 에러인데 왜 TS가 통과 시켜주지..?\" 라는 경우가 종종 발생할 것입니다. 왜냐, 저도 그랬기 때문이죠.\n\n에러가 발생하지 않고 TS가 그냥 통과 시켜주는 이유는 TS가 구조적 타이핑을 따르기 때문입니다.\n\n구조적 타이핑이란?\n\nTypeScript는 변수의 이름보다 객체의 구조를 보고 타입을 판단한다.\n\n즉, 객체의 이름이 아니라 구조만 맞으면 타입이 맞다고 판단합니다.\n아래 예시처럼 name이라는 프로퍼티만 있어도 age가 추가된다고 한들 TypeScript는 통과를 시켜줍니다.\n\n\n단, 객체 리터럴을 직접 넘길 때는 다르다.\n\n이 예시처럼 객체 리터럴을 직접 전달하게 되면, 엄격한 검사로 에러가 발생한다. 이게 바로 초과 프로퍼티 검사라고 합니다.\n\n초과 프로퍼티 검사\n\n객체 리터럴을 직접 넘길 때만 초과 필드를 엄격히 검사한다.\n\n다시 말해, 리터럴은 타입이 명확하니까 엄격하게 검사를 하고 변수는 타입을 추론하니까 구조만 맞으면 통과됩니다.\n\n구조적 타이핑과 초과 프로퍼티 검사를 알고 있어야 TypsScript가 왜 에러를 주지 않는지 이해하고 잘 사용할 수 있겠죠?!\n\n유틸리티 타입\n\n우리가 잘 알고 있는 원시타입 6가지인 number  string  boolean  undefined  null  symbol 를 통해 함수와 객체를 선언하고 사용할 수 있습니다.\n\n그리고 타입스크립트가 자체적으로 제공하는 특수한 타입은 유틸리티 타입이라고 합니다.\n\n이 중에서 가장 많이 사용되는 TOP 5 유틸리티 타입에 대해서 설명해보고자 한다.\n\nPartial\n\nPartial<T>는 주어진 타입의 모든 프로퍼티 를 optional하게 만들어주는 기능을 제공합니다.\n\n다시 말해서, 주어진 타입의 각 프로퍼티에 ?를 붙여서 각 프로퍼티를 optional 하게 만든 새로운 타입을 만들어줍니다. 이러한 특징 때문에 patch API, 수정 폼에서 주로 사용합니다.\n\ninterface User {\n  name: string,\n  email: string,\n  age: number\n}\n\ntype UserUpdate = Partial<User>;\n\nconst Munjji:UserUpdate = {\n  name: \"Munjji Lee\",\n}\n\n이 처럼 User 프로퍼티에 있는 email과 age를 작성하지 않았음에도 optional 처리가 되었기에 UserUpdate를 타입으로 하고 있는 Munjji에서는 에러가 발생하지 않음을 확인할 수 있습니다. 👍\n\nPick\n\nPick<T, K>은 T 타입의 특정 프로퍼티 중 K로 지정한 프로퍼티만을 포함한 새로운 타입을 만듭니다. 즉, 우리가 전체 유저 타입에서 특정 필드만 뽑아서 사용하고 싶을 때 유용합니다.\n\ninterface User {\n  name: string,\n  email: string,\n  age: number\n}\n\ntype UserPreview = Pick<User, \"name\" | \"email\">;\n\ninterface UserCardProps {\n  user: UserPreview,\n}\n\nexport const UserCard = {{ user }: UserCardProps} => {\n  return (\n    <div className = \"user-card\">\n    \t<p>이름: {user.name}</p>\n\t\t<p>이메일: {user.email}</p>\n\t</div>\n  );\n};\n\n예를 들어 마이페이지에서 유저의 name과 email만 보여주는 카드 컴포넌트를 만든다고 할 때, 전체 User 타입을 그대로 넘기기에는 너무 무겁고 불필요한 정보가 많습니다.\n\n이럴 때 Pick<User, \"name\" | \"email\">을 쓰면, 정확히 필요한 필드만 갖는 타입을 만들 수 있습니다. 👍\n\nOmit\n\nOmit<T, K>은 T 타입의 특정 프로퍼티 중 K로 지정한 프로퍼티만를 제외한 새로운 타입을 만듭니다. 특정 필드를 명시적으로 제거하고 싶은 상황에 유용합니다.\n\ninterface User {\n  id: string,\n  name: string,\n  email: string,\n  password: string // 비공개\n}\n\ntype PublicUser = Omit<User, \"password\">;\n\ninterface UserCardProps {\n  user: PublicUser\n}\n\n예를 들어 사용자 정보를 화면에 표시하되, password는 절대 노출하면 안 되겠죠?\n\n그럴 때 Omit<User, \"password\">를 쓰면, 타입 레벨에서부터 해당 필드에 접근할 수 없도록 막아버릴 수 있습니다.\n\n이런 식으로 보안에 강한 코드, 그리고 더 명확한 의도를 가진 타입 정의가 가능해집니다.\n\nReadonly\n\nReadonly<T>는 객체를 읽기 전용(read-only) 으로 만들어주는 유틸리티 타입입니다.\n\n예를 들어 설정값, 환경변수처럼 절대 바뀌면 안 되는 데이터를 정의할 때 유용합니다!\n\ninterface AppConfig {\n  appName: string,\n  apiBaseUrl: string,\n  version: string,\n}\n\nconst config: Readonly<AppConfig> = {\n  appName: '이먼지 페이지',\n  apiBaseUrl: \"https://api.munjji.co.kr\",\n  version: \"1.0.0\",\n};\n\nconfig.version = \"2.0.0\"; // ❌ 에러: 읽기 전용 속성이므로 'version'에 할당할 수 없습니다. ts\n\n코드를 작성하는 순산부터 타입이 \"이건 바꾸면 안 돼!\"라고 알려주니까, 실수로 상태를 수정하거나 의도치 않게 변경하는 걸 막을 수 있습니다. 💪\n\nRecord\n\nRecord<K, T>는 K로 지정한 프로퍼티 키들이 V로 지정한 값을 가지는 객체 타입을 만듭니다. 즉, 우리가 객체를 만들 때 키와 값의 타입을 정확하게 지정하고 싶을 때 사용하는 타입니다.\n\n실무에서는 상태 관리, 옵션 맵, 카운트 맵 등에서 정말 자주 쓰입니다.\n\ntype Category = \"snack\" | \"toy\" | \"food\",\ntype StockMap = Record<Category, number>;\n\nconst stock: StockMap = {\n  snack: 100,\n  toy: 75,\n  food: 50,\n};\n\nstock[\"snack\"] = 200; // ✅ OK\n\n예를 들어 카테고리별 재고 수량 같은 구조를 만들 때,\nRecord<Category, number>라고 쓰면, 해당 키에만 수량을 매핑할 수 있습니다. 👍\n\n결론\n\n\"타입스크립트는 속도를 낮추는게 아니라 속도를 담보한다.\" 라고 정의할 수 있을 것 같습니다.\n\n실행되기 전에 오류를 막고 디버깅 시간을 줄이고 협업도 편해지고 리팩토링도 자유로워집니다.\n\n이런 장점을 가진 타입스크립트를 쓰지 않을 이유는 없다고 생각합니다. TS 관련해서 찾아보면서 새로 알게 되는 것들도 정말 많았고 똑똑하게 TS를 사용하고 있지 않다는 것도 많이 알게 되어 반성했기에, 앞으로는 더 똑부러지게 TS를 적극 활용해야겠다는 다짐과 함께 글 마무리 합니다. 👋\n\n출처:\nhttps://velog.io/@jeris/TypeScript-%EC%9C%A0%ED%8B%B8%EB%A6%AC%ED%8B%B0-%ED%83%80%EC%9E%85\nhttps://www.typescriptlang.org/docs/handbook/utility-types.html\n\nmunjji\n부대찌개 레쯔고\n팔로우\n0개의 댓글\n댓글 작성\n관련 채용 정보\n무무즈\n프론트엔드 엔지니어\n아이와 함께 하는 삶을 행복하게 만드는 무무즈에서 프론트엔드 엔지니어로 웹서비스를 혁신할 기회를 제공합니다. React와 Typescript를 활용한 프로젝트 설계 및 진행 경력이 있다면, 자율적인 업무 환경에서 성장할 수 있는 기회를 놓치지 마세요!\n화해(버드뷰)\nFrontend Developer\n화해 프론트엔드팀은 웹과 B2B 서비스 등을 개발하며, 사용자 경험을 최우선으로 생각하는 팀입니다. JavaScript, React 및 문제 해결 능력을 요구하며, 하이브리드 근무제와 무한 자율휴가 등으로 개발자 친화적인 환경을 제공합니다.\n토스플레이스\nFrontend Developer\n토스플레이스에서 프론트엔드 개발자로 팀에 합류하여 오프라인 결제 시장의 디지털 혁신에 기여하세요. React와 TypeScript를 활용하여 매장 운영의 새로운 경험을 창출하고, 자율적인 근무 문화를 누리며 도전적인 프로젝트에 참여할 기회를 가져보세요.",
    "tags": [],
    "commentCount": "0"
  },
  {
    "title": "UI/UX에 진심인 프론트엔드 개발자의 여행 노션 설계기",
    "description": "여행 노션, 그냥 만들지 않았습니다. UI/UX에 진심인 프론트엔드 개발자의 실제 사용기와 설계 노하우를 담았습니다 ✈️",
    "link": "https://velog.io/@gracekim527/UIUX%EC%97%90-%EC%A7%84%EC%8B%AC%EC%9D%B8-%ED%94%84%EB%A1%A0%ED%8A%B8%EC%97%94%EB%93%9C-%EA%B0%9C%EB%B0%9C%EC%9E%90%EC%9D%98-%EC%97%AC%ED%96%89-%EB%85%B8%EC%85%98-%EC%84%A4%EA%B3%84%EA%B8%B0",
    "author": "gracekim527.log",
    "date": "2025년 3월 31일",
    "comments": "3개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/gracekim527/post/f27454a9-67dd-4785-a62d-6865b5db6257/image.png",
    "content": "gracekim527.log\n로그인\ngracekim527.log\n로그인\nUI/UX에 진심인 프론트엔드 개발자의 여행 노션 설계기\nGraceKim·2025년 3월 31일\n팔로우\n6\n노션\n\n안녕하세요, Grace입니다.\n이번 블로그는 비록 코딩과 직접적인 연관은 없지만, 여행 노션을 만들며 UI/UX를 고민한 경험을 가볍게 공유하고자 합니다.\n\n이번 달 초, 남자친구와 일본 여행을 다녀왔는데요.\n그때 직접 설계하고 사용한 노션이 예상보다 훨씬 유용했고, 주변에서도 좋게 봐주셔서 이 노션의 설계 방식과 사용기를 간단히 풀어보려 합니다.\n\n그럼 바로 시작해볼게요!\n\n✍️ 노션에 어떤 내용을 담을 것인가?\n\n먼저, 노션을 만들기 전에 “어떤 정보가 필요할까?“를 고민했습니다.\n\n다양한 여행 노션 템플릿을 참고한 결과, 다음과 같은 항목들을 포함하기로 했어요:\n• 여행 체크리스트\n• 예약(해야 할) 리스트\n• 각종 바우처 아카이빙\n• 여행 관련 레퍼런스 저장소\n• 전반적인 여행 일정\n• 가계부\n\n이 모든 내용을 정리하기 위해, 아래와 같이 노션을 구성해봤습니다.\n\n감성적인 일본 사진을 커버로 설정하고, 여행 날짜는 Callout(콜아웃) 기능으로 강조했습니다.\n위에서 정리한 항목들은 전부 Dashboard 안에 모아, 카테고리별로 분류하고 필요한 정보만 안에 들어가 확인할 수 있게 만들었어요.\n\n그런데 노션은 기본적으로 페이지를 생성하면, 홈 화면에는 아래처럼 단순한 링크 블록만 남는 구조예요.\n\n아무런 꾸밈 없이 이렇게 두면… 사실 꾸미기에 익숙하지 않은 사람은 그냥 여기서 멈추기 쉬워요.\n하지만 저는 UI도, UX도 모두 포기할 수 없었습니다.\n\n그래서 홈 화면에 도쿄 날씨 위젯도 함께 임베드했어요.\n공백을 줄이고 시각적으로도 훨씬 풍부하게 보이도록 구성했습니다.\n\n🗓 여행 일정은 어떻게 설계했을까?\n\n여행 노션에서 가장 중요한 건 단연 여행 일정이에요.\n일정이 보기 불편하거나 정리가 잘 안 되어 있다면, 저는 아예 노션을 쓰지 않았을 거예요.\n\n💡 사용자는 누구이고, 어떤 환경에서 볼까?\n\n이번 노션의 실제 사용자는 저와 남자친구.\n여행 중엔 대부분 모바일 환경에서 확인하겠죠.\n\n그런데 모바일 노션에서 데이터베이스 뷰는 정말 불편했어요.\n특히 내용이 많아지면 가로 스크롤이 생기는데, 한눈에 들어오지 않아서 UX가 너무 떨어졌죠.\n왼쪽이 일반 페이지들의 리스트고, 오른쪽이 데이터베이스입니다.\n\n오히려 간단한 회의록 같은 정보라면 페이지 여러 개로 나누는 게 낫겠다는 생각도 들었어요.\n물론 표 기능도 있지만, property가 많아질수록 가로로 늘어나는 구조는 여전히 불편했답니다.\n\n🤔 \"시간표처럼 한눈에 보이게\"라는 UX적 발상\n\n그래서 생각했어요.\n“내가 원하는 건 어디에 가는지가 가장 중요하고, 몇 시쯤인지는 부가적인 정보야.”\n\n그렇다면 날짜별로 시간표처럼 보이게 하면 되겠네!\n이 결론에 도달했고, 그때 딱 맞는 뷰가 바로 데이터베이스의 Board 뷰였어요.\n\n이렇게 구성하니,\n• 무엇을 하는지\n• 어떤 순서로 이동하는지\n• 대략적인 시간은 어떤지\n\n이 모든 걸 모바일에서도 한눈에 확인할 수 있었어요.\n\n또한, 이 일정 뷰는 Dashboard 내부가 아닌 외부에 바로 노출시켰어요.\ndepth를 줄이는 것만으로도 접근성과 UX가 확 달라지거든요.\n\n🎒 마무리하며\n\n이렇게 필요한 정보만 정리한 노션 덕분에, 여행 중에는 노션과 구글맵만으로도 충분했어요.\n무거운 템플릿 대신, 심플하게 필요한 것만 담은 구성이 오히려 더 편했고요.\n\n많이 공유되는 여행 노션 템플릿들은 대부분 ‘정보 아카이빙’에 초점을 맞추다 보니 실제 사용 시엔 오히려 무겁게 느껴졌어요.\n그래서 저는 “여행 중 가장 자주 보게 될 화면이 어떤 UX여야 할까?”라는 관점으로 접근했고, 그 결과물이 꽤 만족스러웠답니다.\n\n이상, UI와 UX를 모두 포기할 수 없었던 프론트엔드 개발자의 여행 노션 설계기였습니다.\n읽어주셔서 감사합니다!\n\nGraceKim\nT자형 개발자가 되고 싶은 GraceKim입니다\n팔로우\n이전 포스트\n[Git] 갑자기 한글화가 된 Git..?\n3개의 댓글\n댓글 작성\n초록바다\n2025년 4월 1일\n\n글 잘 읽었습니다!\n여행할 때뿐만 아니라 일상생활에서도 유용하게 활용할 수 있는 노션 템플릿인 것 같아요.\n\n저도 여자친구와 일본 여행을 계획 중인데, 여자친구를 위해 완벽한 여행을 준비하고 싶습니다.\n혹시 실례가 되지 않는다면, 해당 노션 템플릿을 공유받을 수 있을까요?\n\n만약 공유가 어렵다면 정말 괜찮습니다!\n여행 노션을 설계하는 데 정말 많은 인사이트를 얻어 갑니다. 😊\n\n1개의 답글\n관련 채용 정보\n정리습관\n프론트엔드개발자(0~5년)\nAI 기반 정리습관 서비스의 프론트엔드 개발자를 모집합니다. React.js 및 Next.js 경험을 활용해, 고객 맞춤형 공간 정리 솔루션을 함께 설계해보세요!\n마카롱팩토리\n프론트엔드 개발 (5년 이상)\n차량관리 1위 앱 '마이클'을 운영하는 마카롱팩토리에서 혁신적인 웹 서비스를 함께 만들 프론트엔드 개발자를 찾고 있습니다. React와 TypeScript를 활용하여 사용자 경험을 개선하고, 자율적인 근무 환경에서 성장할 기회를 제공합니다.\n현대오토에버\n[FE Engineering] 개발/운영 및 Governance 체계 수립 - Frontend Engineer\n현대오토에버에서 완성차 운영 서비스를 개발하며 프론트엔드 기술 거버넌스를 수립할 기회를 잡아보세요. JavaScript와 React 등의 전문성을 발휘할 수 있는 창의적인 환경이 여러분을 기다리고 있습니다.",
    "tags": [
      "노션"
    ],
    "commentCount": "3"
  },
  {
    "title": "리액트에서의 순수성: 예측 가능한 UI의 비밀",
    "description": "리액트 세계에서 순수함수는 뗄래야 뗄 수가 없다. 항상 같은 상황에서 같은 반응을 보여준다는 확신은 곧 디버깅과 유지 보수성을 이끈다. 이런 순수함수의 특성이 리액트의 핵심 철학이 된 이유는 무엇일까? 복잡한 UI 개발 환경에서 순수함수는 어떻게 빛을 발할까?\n\n> \"...",
    "link": "https://velog.io/@kyujenius/react-pure-component",
    "author": "kyujenius.log",
    "date": "2025년 4월 5일",
    "comments": "0개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/kyujenius/post/724613bb-985e-47b0-a99d-2d64688dd8fa/image.png",
    "content": "kyujenius.log\n로그인\nkyujenius.log\n로그인\n리액트에서의 순수성: 예측 가능한 UI의 비밀\n홍규진·2025년 4월 5일\n팔로우\n10\nJavaScriptReact\n리엑트와 순수함수의 관계\n목록 보기\n2/5\n\n리액트 세계에서 순수함수는 뗄래야 뗄 수가 없다. 항상 같은 상황에서 같은 반응을 보여준다는 확신은 곧 디버깅과 유지 보수성을 이끈다. 이런 순수함수의 특성이 리액트의 핵심 철학이 된 이유는 무엇일까? 복잡한 UI 개발 환경에서 순수함수는 어떻게 빛을 발할까?\n\n\"(👨🏻‍🏫 : 리액트 공식문서 내에서도 항상 순수성에 대한 중요성을 강조한답니다. 그 이유에 대해서 같이 알아볼까요?)\"\n\n리액트 공식 문서에서는 다음과 같이 말한다:\n\n“Keeping Components Pure”\n\n출처: React 공식 문서 - 컴포넌트 순수성 유지하기\n\n리액트에서 정의하는 순수성은 전통적인 함수형 프로그래밍에서의 순수 함수 본질은 같으나 세부적인 개념은 약간 다릅니다. 리액트에서는 컴포넌트가 다음 조건을 만족하면 순수하다고 본다:\n\n렌더링 과정에서 사이드 이펙트가 없어야 함 - 외부 변수를 수정하거나 DOM을 직접 조작하지 않음\n동일한 입력(props, state, context)에 대해 항상 동일한 JSX 결과를 반환해야 함\n\n주로 참고한 공식 문서: https://react.dev/learn/keeping-components-pure\n\n💡급하신 분들을 위해서 결론 먼저!\n리액트 컴포넌트는 순수함수처럼 동작할 때 예측 가능하고 디버깅이 용이하다.\n리액트의 렌더링 프로세스는 순수성을 기반으로 최적화되어 있다.\n순수 컴포넌트는 애플리케이션의 안정성과 성능을 크게 향상시킨다.\n1. 리액트 컴포넌트가 순수해야 하는 이유\n순수한 컴포넌트\n\n리액트 컴포넌트가 순수함수처럼 동작한다면, 같은 props와 state에 대해 항상 같은 UI를 렌더링한다. 이는 UI의 예측 가능성을 크게 높인다.\n\nfunction Recipe({ drinkers }) {\n  return (\n    <ol>    \n      <li>Boil {drinkers} cups of water.</li>\n      <li>Add {drinkers} spoons of tea and {0.5 * drinkers} spoons of spice.</li>\n      <li>Add {0.5 * drinkers} cups of milk to boil and sugar to taste.</li>\n    </ol>\n  );\n}\n\nexport default function App() {\n  return (\n    <section>\n      <h1>Spiced Chai Recipe</h1>\n      <h2>For two</h2>\n      <Recipe drinkers={2} />\n      <h2>For a gathering</h2>\n      <Recipe drinkers={4} />\n    </section>\n  );\n}\n\n\ndrinkers에 따라 Input이 같다면 출력되는 Ouput인 컴포넌트가 동일하다.\n\n테스트 용이성\n\n순수 컴포넌트는 외부 상태에 의존하지 않기 때문에 테스트하기 매우 쉽다. 특정 props를 전달하고 예상되는 출력을 확인하는 것만으로 충분하다.\n\n디버깅 간소화\n\n컴포넌트가 순수하다면, 버그가 발생했을 때 입력(props와 state)만 확인하면 된다. 외부 요인을 고려할 필요가 없어 디버깅 과정이 크게 단순화된다.\n\n\"(👨🏻‍🏫 : 디버깅이 쉬워진다는 것만으로도 순수함수는 사랑받을 자격이 있답니다! 밤새 버그 찾느라 고생해보신 분들은 공감하실 거예요. 😅)\"\n\n비순수 컴포넌트\nlet guest = 0;\n\nfunction Cup() {\n  // Bad: changing a preexisting variable!\n  guest = guest + 1;\n  return <h2>Tea cup for guest #{guest}</h2>;\n}\n\nexport default function TeaSet() {\n  return (\n    <>\n      <Cup />\n      <Cup />\n      <Cup />\n    </>\n  );\n}\n\n\n이를 랜더링 하면 다음과 같이 나온다. 같은 <Cup/> 이라는 컴포넌트를 랜더링해도, 컴포넌트는 다르게 나온다.\n\n\"(👨🏻‍🏫 : 변수도 매번 바뀌니까 이게 순수함수인가? 라는 헷갈린 점들이 조금은 해소 되셨나요? 예측 가능한 컴포넌트와 예측 불가능한 컴포넌트에 대해서는 동일한 prop 과 state를 넣었는데 동일한 Output이 나오나? 로 확인해볼 수 있습니다. )\"\n\n2. 리액트의 렌더링 프로세스와 순수성의 관계\n렌더 단계의 순수성\n\n리액트의 렌더링 프로세스는 크게 렌더 단계와 커밋 단계로 나뉜다. 렌더 단계에서 리액트는 컴포넌트를 순수 함수처럼 취급하며, 이전 렌더링과 결과를 비교한다. 이 때, Strict Mode 를 설정해두었다면, 리액트의 컴포넌트들이 순수함수임이 보장되어, 이 과정이 매끄럽게 진행된다.\n\n렌더링 최적화\n\n컴포넌트가 순수하다면, 리액트는 불필요한 렌더링을 건너뛸 수 있다. 같은 입력에 대해 항상 같은 출력이 나온다는 것을 알기 때문에, 입력이 변경되지 않았다면 이전 결과를 재사용할 수 있다.\n\nReact.memo를 사용한 최적화 예시는 다음과 같습니다:\n\n// 데이터 테이블의 행 컴포넌트 최적화\nconst DataRow = React.memo(\n  function DataRow({ data }) {\n    console.log(\"Row rendering\");\n    return <tr><td>{data.id}</td><td>{data.value}</td></tr>;\n  });\n\n// 사용자 목록 컴포넌트 최적화\nconst UserList = React.memo(\n  function UserList({ users, filterCriteria }) {\n    const filteredAndSortedUsers = React.useMemo(() => {\n      const filteredUsers = users.filter(user => user.age > filterCriteria.minAge);\n        return filteredUsers.sort((a, b) => a.age - b.age);\n  }, [users, filterCriteria]);\n  \n  return (\n    <div className=\"user-list\">\n      {filteredAndSortedUsers.map(user => (\n        <div key={user.id}>\n          <h4>{user.name}</h4>\n          <p>Age: {user.age}</p>\n        </div>\n      ))}\n    </div>\n  );\n});\n\n// Todo 리스트 컴포넌트 최적화\nconst Todo = React.memo(function Todo({ list }) {\n  console.log(\"Todo component rendered\");\n  return (\n    <ul>\n      {list.map((item) => (\n        <TodoItem key={item.id} item={item} />\n      ))}\n    </ul>\n  );\n});\n\n\n이러한 예시들은 React.memo를 사용하여 부모 컴포넌트가 리렌더링될 때 props가 변경되지 않은 자식 컴포넌트의 불필요한 리렌더링을 방지합니다. 특히 리스트 렌더링, 데이터 테이블, 필터링된 목록과 같이 데이터를 표시하는 컴포넌트에서 유용합니다.\n\n엄격 모드(Strict Mode)와 순수성\n\n리액트의 엄격 모드(Strict Mode)는 컴포넌트의 순수성을 검증하는 데 도움을 준다. 개발 모드에서 컴포넌트를 두 번 렌더링하여 부수 효과를 찾아내는 방식이다.\n\nimport { StrictMode } from 'react';\nimport { createRoot } from 'react-dom/client';\n\nconst root = createRoot(document.getElementById('root'));\nroot.render(\n  <StrictMode>\n    <App />\n  </StrictMode>\n);\n\n\"(👨🏻‍🏫 : 엄격 모드는 마치 엄한 부모처럼 여러분의 컴포넌트가 순수한지 철저히 검사한답니다. 덕분에 더 좋은 코드를 작성하게 되죠! 또한 React.memo는 오해할 수 있어서 말씀드리지만, 순수 컴포넌트를 정의하는 것이 아니라, 이미 순수한 컴포넌트의 성능을 최적화하는 데 사용됩니다. memo는 컴포넌트의 props가 변경되지 않았다면 리렌더링을 건너뛰게 해주는 고차 컴포넌트(HOC)입니다. 순수 컴포넌트는 memo 사용 여부와 관계없이, 동일한 입력(props)에 대해 항상 동일한 출력(JSX)을 반환하고 부수 효과가 없는 컴포넌트를 의미합니다.)\"\n\n3. 순수 컴포넌트가 애플리케이션 안정성에 미치는 영향\n예측 가능한 상태 관리\n\n순수 컴포넌트는 상태 변화가 예측 가능하게 이루어진다. 이는 복잡한 애플리케이션에서도 상태 관리를 용이하게 만든다.\n\n동시성 모드 지원\n\n리액트의 동시성 모드(Concurrent Mode)는 순수 컴포넌트를 기반으로 한다. 컴포넌트가 순수하다면, 리액트는 동시성 모드를 사용할 수 있는데, 이는 리액트가 렌더링 작업을 중단, 재개, 심지어 폐기할 수 있게 해주는 기능입니다. 이는 브라우저의 메인 스레드를 차단하지 않고 백그라운드에서 컴포넌트 트리의 여러 버전을 준비할 수 있게 해줍니다.\n\n버그 감소\n\n순수 컴포넌트는 부수 효과가 없기 때문에 예상치 못한 버그가 발생할 가능성이 크게 줄어든다. 이는 전체 애플리케이션의 안정성을 높인다.\n\n// 비순수 컴포넌트 예시 (피해야 함)\nfunction BadComponent() {\n  // 🚫 렌더링 중 직접 DOM 조작\n  document.title = 'Updated Page';\n  return Hello World;\n}\n\n// 순수한 접근 방식\nfunction GoodComponent() {\n  // ✅ 부수 효과를 useEffect로 분리 (다 다음 글에서 다뤄볼게요)\n  React.useEffect(() => {\n    document.title = 'Updated Page';\n  }, []);\n  return Hello World;\n}\n\n\"(👨🏻‍🏫 : 순수 컴포넌트는 마치 든든한 팀원과 같아요. 자기 일만 책임지고, 다른 사람의 일을 방해하지 않죠. 그런 팀원이 많을수록 프로젝트는 성공하기 마련이랍니다! 다음에는 함수형 컴포넌트가 순수성과 왜 더 가까운가? 에 대해서 배워볼게요)\"\n\n🙇🏻 글 내에 틀린 점, 오탈자, 비판, 공감 등 모두 적어주셔도 됩니다. 감사합니다..! 🙇🏻\n\n홍규진\n읽는 사람이 가장 이해하기 쉽게끔 적으려 노력합니다. 그 과정에서 스스로가 완전한 이해를 할 수 있다고 생각합니다. 그렇게 Taker 보다는 Giver이 되려 노력합니다. \n팔로우\n이전 포스트\n순수함수의 기본 개념\n다음 포스트\n리엑트는 왜 함수형 컴포넌트를 택했을까? (feat. 클래스형 컴포넌트)\n0개의 댓글\n댓글 작성\n관련 채용 정보\n여기어때컴퍼니\nFrontend Engineer [파트너서비스]\n여기어때는 숙박, 항공, 교통 등 다양한 서비스를 제공하는 종합 여행 플랫폼으로, 프론트엔드 엔지니어로서 혁신적인 UI/UX를 설계하고 개발할 기회를 제공합니다. React 및 Next.js 경험을 활용하며, 자율적인 근무환경과 풍부한 복지 혜택으로 나만의 라이프스타일을 실현할 수 있습니다.\n페이타랩(패스오더)\n웹 프론트엔드 개발자(JavaScript, React)\n대한민국 No.1 카페 주문 플랫폼인 패스오더에서 프론트엔드 개발자를 채용합니다! React와 TypeScript로 혁신적 서비스를 개발하며, 성장 중심의 문화를 통해 자신만의 커리어를 쌓아보세요!\n스터닝\n프론트엔드 개발자(신입)\n프론트엔드 개발자로서 국내 최대 크리에이티브 플랫폼 스터닝에서 UX/UI 협업 및 웹 서비스 개발을 통해 창작자의 가치를 실현하는 데 기여해보세요. React, Typescript, Next.js와 같은 기술을 활용하며 유연한 근무 환경에서 업무에 몰입할 수 있습니다.",
    "tags": [
      "JavaScript",
      "React"
    ],
    "commentCount": "0"
  },
  {
    "title": "유연한 자세 함께 기르기",
    "description": "요즘 개발자는 소프트스킬도 중요하다구요!? 당신만 특별히 알려드리는 겁니다. 이리와보세요(속닥속닥)",
    "link": "https://velog.io/@songsunkook/%EC%9C%A0%EC%97%B0%ED%95%9C-%EC%9E%90%EC%84%B8-%ED%95%A8%EA%BB%98-%EA%B8%B0%EB%A5%B4%EA%B8%B0",
    "author": "ssg.log",
    "date": "2025년 4월 3일",
    "comments": "0개의 댓글",
    "likes": null,
    "thumbnailUrl": "https://velog.velcdn.com/images/songsunkook/post/7d835049-5d00-45de-a409-ad096aee0c02/image.png",
    "content": "ssg.log\n로그인\nssg.log\n로그인\n유연한 자세 함께 기르기\n송선권·2025년 4월 3일\n팔로우\n9\n소프트스킬\n우아한테크코스 7기\n목록 보기\n1/2\n배경\n유연함의 힘\n\n어느날 우테코에서 소프트 스킬 과제로 \"유연함의 힘\" 책을 읽어오라는 과제를 내줬다. 당시에는 막연하게 아 우테코에서는 소프트스킬도 중요하게 생각하는구나! ...근데 미션하면서 이걸 언제 다 읽지 ㅠㅠ 정도로 생각했다.\n\n하지만 책을 읽으면서 많은 생각을 할 수 있었다. 책에서는 성과 증명 마인드셋과 학습 마인드셋을 중요하게 다룬다. 책을 읽으면서 가장 인상깊었던 부분이다. 많은 공감이 되었고, 앞으로 우테코에서 어떤 자세로 임할 것인지를 결정하는 데 큰 도움이 되었다. 여러분도 시간이 된다면 꼭 한번씩 읽어보기를 추천한다.\n\n성과 증명 마인드셋(Performance-Prove Mindset)과 학습 마인드셋(Learning Mindset)\n\n이름만 보면 성과 증명 마인드셋이 더 좋아보일 수 있다. 하지만 그렇지 않다!\n\n도전 상황을 마주했을 때 사람들은 보통 본인의 능력과 기술을 증명하려는 목표를 가지는 성과 증명 마인드셋을 취한다. 하지만 이 마인드셋은 실패를 피하고 성과를 증명하는 데에만 집중해서 학습과 성장을 해치고 나아가 성과까지 내지 못하도록 만든다.\n\n반면 학습 마인드셋을 가진 사람은 성장과 능력 향상에 초점을 맞춘다. 덕분에 실패를 두려워하지 않고 어제보다 더 나은 오늘의 내가 되기 위해 노력하고, 성과를 내는 데도 큰 도움이 된다.\n\n유연성 강화 목표와 실험 계획\n\n유연함의 기술을 연마하기 위해 책에서 추천하는 방법은 유연성 강화 목표를 정하는 것이다. 하지만 이것만으로는 부족하다. 유연성 강화 목표는 추상적으로 다가올 수 있기 때문에 이를 달성하기 위한 실험 계획을 세우고 실천하기 위해 지속적으로 인지하고 노력해야 한다. 그 과정에서 실험 계획은 얼마든지 수정될 수 있다. 중요한 것은 유연성 강화 목표를 달성하기 위해 꾸준히 인지하고 노력하는 것이다.\n\n오.. 좋은데?(책을 덮으며)\n\n유익한 내용이었고 읽으며 와닿는 부분이 많았지만, 단지 그뿐이었다. 이걸 실행에 옮길 동기가 마땅하지 않았고, 그냥 그렇구나~ 하고 말았다. 하지만 우아한테크코스에서는 이런 내 생각까지도 내다봤던 것 같다.\n\n유연성 강화 스터디\n\n우테코에서는 매주 유연성 강화 스터디(줄여서 유강스)를 진행하도록 시켰다. 혼자가 아니라 다른 조원들과 함께 말이다. 하지만 강제로 진행한다고 해서 어떤 의미가 있을까?\n\n목표 선정과 실험 계획 수립\n\n우테코에서는 평소 개선하고 싶었던 (개발 외적인)습관을 유연성 강화 목표로 세우라고 했다. 나는 편하게 다가가고 싶은 동료가 되자라는 목표를 세우고 실험 계획을 수립했다.\n\n1. 매일 데일리 미팅 전후로 한 명 이상의 동료에게 먼저 말을 걸어본다.\n2. 상대가 이야기할 때 적극적으로 리액션(고개 끄덕이기, 짧은 피드백, 긍정적인 반응)하기.\n3. 실수를 했을 때 변명하지 않고, 솔직하게 인정하고 해결 방법을 함께 논의한다.\n스스로 인지하기\n\n이후에는 우테코 생활을 하면서 실험 계획을 실천하기 위해 노력했다. 평소였다면 해보지 않았을 시도이기에 더욱 실험 계획에 대해 스스로 인지하는 습관이 필요했다. 인지하지 않았다면 실천하지도 않았을 것이지 않은가. 하지만 유강스를 진행한 덕분에 평소 실험 계획을 인지하면서 생활할 수 있었다.\n\n피드백 & 실험 계획 수정하기\n\n매주 스터디 시간이 되면 조원들과 모여 지난 일주일을 회고했다. 각자 일주일동안 유강스와 관련해 인상깊었던 경험을 공유하며 피드백을 주고받았다. 이 과정을 통해 내가 유연함 강화 목표에 다가가고 있다는 것을 객관적으로 알 수 있어서 좋았다. 항상 모두가 성공하기만 했던 것은 아니다. 오히려 실패함으로써 더 많은 성장을 얻어가는 크루들도 많았다. 유연함의 힘을 기르는 것이 목적이다보니 실험 계획에 너무 집착하는 것은 좋지 않은 것 같다.\n\n피드백을 받으면서 실험 계획을 수정하는 일도 있었다. 다음은 당시 나의 회고 중 일부와 변경한 실험 계획이다.\n\n실험 계획이 능동적으로 행위할 수 있는 게 아니다보니 적극적으로 인식하기가 힘든 것 같다. 실험 계획 수정이 필요해보인다.\n\n1. 매일 데일리 미팅 전후로 한 명 이상의 동료에게 먼저 말을 걸어보기\n2. 접점이 있던 크루에게는 마주치면 항상 인사하기.\n3. 일주일에 한 번 다른 사람들 토론하는 데 난입하기.\n4. 다른 강의장이나 라운지로 주 활동지를 옮겨보기\n회고\n\n혼자서만 유강스를 했다면 계획을 잘 지키고 있는지 점검하기 힘들었을 것이다. 하지만 매주 크루들과 피드백을 주고받으면서 \"내가 잘하고 있구나\"를 인지할 수 있었다. 크루들에게 칭찬과 응원, 격려를 받을 때마다 유강스 계획을 실천하고자 하는 동기가 부여되었다. 다른 크루들에게 피드백을 남길 때, 스스로를 개선하기 위해 열심히 노력하고 있는 모습들을 보고 대단하다는 생각이 들기도 했다.\n\n유강스를 하면서 주로 노력했던 것은 다른 크루들에게 먼저 다가가는 것이었다. 아직도 처음보는 크루에게 먼저 다가가는 것은 힘들지만, 접점이 있었던 크루에게 먼저 다가가는 것은 조금 익숙해진 것 같다.\n\n유강스 중, 모두에게 잘보일 필요는 없다는 피드백을 받았다. 오히려 모두와 친한 사람은 소심한 사람이 다가가는 데 부담이 될 수 있다는 말에 공감이 갔다. 그래서 모두와 친해지기보다는 자연스럽게 다가가기 위해 노력하고 있다.\n\n언제 한 번은 혼자 고민중인 크루에게 먼저 다가가서 이야기를 들어주기도 했는데, 여기에 대한 크루들의 피드백이 인상깊었다. 나는 항상 해결책을 제시해야만 도움을 줄 수 있다고 생각해왔다. 하지만 크루들은 문제를 해결해주는 것도 좋지만 단순히 이야기를 들어주는 것만으로도 상대방에게는 큰 도움이 될 수 있다는 피드백을 남겨주었다. 생각해보지 못한 관점이었지만 맞는 말이었고, 내가 잘하고 있음을 메타인지하면서 자신감을 불어넣을 수 있었다.\n\n돌이켜보면 유강스는 나의 우테코 자세를 긍정적으로 확립하는 데 큰 도움이 되었다. 소심한 성격이지만 유강스 덕분에 이런 성격을 안고서도 편하게 다가가고 싶은 동료가 될 수 있었다고 생각한다.\n\n다음 레벨부터는 유강스가 자율로 바뀌면서 유강스 진행을 맡는 유강스 이끄미를 선발한다고 한다. 나는 큰 고민없이 바로 신청을 넣었다. 유강스 경험이 매우 긍정적이었기 때문이다. 앞으로도, 우테코가 끝나고 나서도 유강스를 이어가고 싶다.\n\n유강스는 나의 소프트스킬 증진에 큰 도움이 되고 있다. 이 글을 읽는 사람들도 주변 친구들을 모아 유강스를 진행해보면 좋겠다.\n\n명언 타임\n\n끝내기 전에 마지막으로 명언 몇 개만 남기고 가겠다. 조원들이 유강스를 진행하며 느낀 점들을 한마디로 요약한 유익한 문장들이다.\n\n모코: 도움은 해답이 아니라 공감에서 시작된다.\n도기: 컴퓨터는 거짓말을 안하는데 정답이 없잖아.\n대니: 솔직함은 용기의 시작이고, 공감은 성장의 열쇠다.\n머랭: 내가 노력했는데도 불가능한건 어쩔 수 없잖아.\n레몬: 용기를 내어 말하는 순간, 나는 이미 어제의 나보다 더 나아가고 있다.\n\n참고 자료\n\n유연함의 힘\n유연함의 기술 적용 - javajigi\n\n송선권\n팔로우\n다음 포스트\n우아한테크코스 레벨 1 회고\n0개의 댓글\n댓글 작성\n관련 채용 정보\n타다(VCNC)\n웹 프론트엔드 개발\n타다와 함께 대한민국 모빌리티 시장을 혁신하며, 웹 프론트엔드 개발자로서 앱 내 화면을 개발할 기회를 잡으세요. React 및 TypeScript로 동작하는 유연한 개발 환경에서 동료들과 함께 문제를 해결하며 성장할 수 있는 기회가 기다립니다.\n현대오토에버\n[FE Engineering] 개발/운영 및 Governance 체계 수립 - Frontend Engineer\n현대오토에버에서 완성차 운영 서비스를 개발하며 프론트엔드 기술 거버넌스를 수립할 기회를 잡아보세요. JavaScript와 React 등의 전문성을 발휘할 수 있는 창의적인 환경이 여러분을 기다리고 있습니다.\n노벨라스튜디오\n[인턴] 프론트엔드 개발자\n노벨라스튜디오에서는 작가를 위한 All-in-one 저작 도구 ‘노벨라’의 프론트엔드 개발 인턴을 모십니다. React, Electron을 활용한 다양한 프로젝트에 참여해 실질적 경험을 쌓을 수 있으며, 유연한 출퇴근 제도로 워라밸을 지킬 수 있습니다.",
    "tags": [
      "소프트스킬"
    ],
    "commentCount": "0"
  }
]